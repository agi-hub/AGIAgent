#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGæ£€ç´¢åŠŸèƒ½å•å…ƒæµ‹è¯•
æµ‹è¯•å‘é‡æœç´¢ã€è¯­ä¹‰æ£€ç´¢ã€æ£€ç´¢å¢å¼ºç”Ÿæˆç­‰åŠŸèƒ½
"""

import pytest
import os
import sys
import json
import tempfile
import numpy as np
from unittest.mock import patch, Mock, MagicMock
from typing import List, Dict, Any

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../..'))

from tools.long_term_memory import LongTermMemory
# from utils.test_helpers import TestHelper

@pytest.mark.unit
class TestRAGRetrieval:
    """RAGæ£€ç´¢åŠŸèƒ½æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def rag_system(self, test_workspace):
        """åˆ›å»ºRAGç³»ç»Ÿå®ä¾‹"""
        return LongTermMemory(workspace_root=test_workspace)
    
    @pytest.fixture
    def sample_documents(self):
        """ç¤ºä¾‹æ–‡æ¡£æ•°æ®"""
        return [
            {
                "id": "doc1",
                "content": "AGI Botæ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªä¸»å®Œæˆå¤æ‚ä»»åŠ¡ã€‚",
                "metadata": {"type": "introduction", "category": "overview"}
            },
            {
                "id": "doc2", 
                "content": "å¤šæ™ºèƒ½ä½“åä½œæ˜¯AGI Botçš„æ ¸å¿ƒç‰¹æ€§ä¹‹ä¸€ï¼Œå…è®¸åˆ›å»ºä¸“ä¸šåŒ–çš„å­æ™ºèƒ½ä½“ã€‚",
                "metadata": {"type": "feature", "category": "multiagent"}
            },
            {
                "id": "doc3",
                "content": "å·¥å…·è°ƒç”¨èƒ½åŠ›ä½¿AGI Botèƒ½å¤Ÿæ‰§è¡Œæ–‡ä»¶æ“ä½œã€ç½‘ç»œæœç´¢ã€ä»£ç åˆ†æç­‰ä»»åŠ¡ã€‚",
                "metadata": {"type": "feature", "category": "tools"}
            },
            {
                "id": "doc4",
                "content": "é•¿æœŸè®°å¿†ç³»ç»Ÿå¸®åŠ©AGI Botä¿æŒå†å²ä¸Šä¸‹æ–‡å¹¶ä»è¿‡å¾€ç»éªŒä¸­å­¦ä¹ ã€‚",
                "metadata": {"type": "feature", "category": "memory"}
            },
            {
                "id": "doc5",
                "content": "MCPåè®®æ”¯æŒä½¿AGI Botèƒ½å¤Ÿé›†æˆç¬¬ä¸‰æ–¹æœåŠ¡å’Œå·¥å…·ã€‚",
                "metadata": {"type": "feature", "category": "integration"}
            }
        ]
    
    @pytest.fixture
    def sample_embeddings(self):
        """ç¤ºä¾‹å‘é‡åµŒå…¥æ•°æ®"""
        # æ¨¡æ‹Ÿ5ä¸ªæ–‡æ¡£çš„768ç»´å‘é‡åµŒå…¥
        return {
            "doc1": np.random.rand(768).tolist(),
            "doc2": np.random.rand(768).tolist(),
            "doc3": np.random.rand(768).tolist(),
            "doc4": np.random.rand(768).tolist(),
            "doc5": np.random.rand(768).tolist()
        }
    
    def test_initialization(self, rag_system):
        """æµ‹è¯•RAGç³»ç»Ÿåˆå§‹åŒ–"""
        assert rag_system is not None
        assert hasattr(rag_system, 'store_memory')
        assert hasattr(rag_system, 'search_memory')
    
    def test_document_storage(self, rag_system, sample_documents):
        """æµ‹è¯•æ–‡æ¡£å­˜å‚¨åŠŸèƒ½"""
        for doc in sample_documents:
            result = rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
            
            # éªŒè¯å­˜å‚¨æˆåŠŸ
            assert result is not None
            assert "error" not in result
    
    def test_basic_text_search(self, rag_system, sample_documents):
        """æµ‹è¯•åŸºæœ¬æ–‡æœ¬æœç´¢"""
        # å…ˆå­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æ‰§è¡Œæœç´¢
        results = rag_system.search_memory("æ™ºèƒ½ä»£ç†ç³»ç»Ÿ")
        
        # éªŒè¯æœç´¢ç»“æœ
        assert results is not None
        assert isinstance(results, (list, dict, str))
    
    @patch('tools.long_term_memory.EmbeddingClient')
    def test_vector_embedding_generation(self, mock_embedding_client, rag_system):
        """æµ‹è¯•å‘é‡åµŒå…¥ç”Ÿæˆ"""
        # æ¨¡æ‹ŸåµŒå…¥å®¢æˆ·ç«¯
        mock_client = Mock()
        mock_client.get_embedding.return_value = np.random.rand(768).tolist()
        mock_embedding_client.return_value = mock_client
        
        # æµ‹è¯•åµŒå…¥ç”Ÿæˆ
        test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºç”Ÿæˆå‘é‡åµŒå…¥ã€‚"
        result = rag_system.store_memory(test_text)
        
        # éªŒè¯åµŒå…¥ç”Ÿæˆ
        assert result is not None
    
    @patch('tools.long_term_memory.EmbeddingClient')
    def test_semantic_similarity_search(self, mock_embedding_client, rag_system, sample_documents, sample_embeddings):
        """æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢"""
        # æ¨¡æ‹ŸåµŒå…¥å®¢æˆ·ç«¯
        mock_client = Mock()
        
        def mock_get_embedding(text):
            # ä¸ºæŸ¥è¯¢è¿”å›ä¸æŸä¸ªæ–‡æ¡£ç›¸ä¼¼çš„å‘é‡
            if "å¤šæ™ºèƒ½ä½“" in text:
                return sample_embeddings["doc2"]
            return np.random.rand(768).tolist()
        
        mock_client.get_embedding.side_effect = mock_get_embedding
        mock_embedding_client.return_value = mock_client
        
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æ‰§è¡Œè¯­ä¹‰æœç´¢
        results = rag_system.search_memory("å¤šæ™ºèƒ½ä½“åä½œåŠŸèƒ½")
        
        # éªŒè¯è¯­ä¹‰æœç´¢ç»“æœ
        assert results is not None
    
    def test_similarity_threshold_filtering(self, rag_system, sample_documents):
        """æµ‹è¯•ç›¸ä¼¼åº¦é˜ˆå€¼è¿‡æ»¤"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æœç´¢éå¸¸ç‰¹å®šçš„æŸ¥è¯¢
        specific_results = rag_system.search_memory("AGI Botæ™ºèƒ½ä»£ç†", top_k=3)
        
        # æœç´¢ä¸ç›¸å…³çš„æŸ¥è¯¢
        irrelevant_results = rag_system.search_memory("å¤©æ°”é¢„æŠ¥è‚¡ç¥¨ä»·æ ¼", top_k=3)
        
        # éªŒè¯ç›¸ä¼¼åº¦è¿‡æ»¤
        assert specific_results is not None
        assert irrelevant_results is not None
    
    def test_metadata_filtering(self, rag_system, sample_documents):
        """æµ‹è¯•å…ƒæ•°æ®è¿‡æ»¤"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # åŸºäºç±»å‹è¿‡æ»¤æœç´¢
        feature_results = rag_system.search_memory(
            "æ™ºèƒ½ä½“åŠŸèƒ½", 
            metadata_filter={"type": "feature"}
        )
        
        # åŸºäºç±»åˆ«è¿‡æ»¤æœç´¢
        tool_results = rag_system.search_memory(
            "å·¥å…·è°ƒç”¨",
            metadata_filter={"category": "tools"}
        )
        
        # éªŒè¯å…ƒæ•°æ®è¿‡æ»¤
        assert feature_results is not None
        assert tool_results is not None
    
    def test_top_k_results_limiting(self, rag_system, sample_documents):
        """æµ‹è¯•TopKç»“æœé™åˆ¶"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æµ‹è¯•ä¸åŒçš„top_kå€¼
        for k in [1, 3, 5, 10]:
            results = rag_system.search_memory("AGI BotåŠŸèƒ½", top_k=k)
            
            # éªŒè¯ç»“æœæ•°é‡é™åˆ¶
            assert results is not None
            if isinstance(results, list):
                assert len(results) <= k
    
    def test_empty_query_handling(self, rag_system):
        """æµ‹è¯•ç©ºæŸ¥è¯¢å¤„ç†"""
        # æµ‹è¯•ç©ºå­—ç¬¦ä¸²æŸ¥è¯¢
        empty_result = rag_system.search_memory("")
        assert empty_result is not None
        
        # æµ‹è¯•NoneæŸ¥è¯¢
        none_result = rag_system.search_memory(None)
        assert none_result is not None
        
        # æµ‹è¯•ç©ºç™½å­—ç¬¦æŸ¥è¯¢
        whitespace_result = rag_system.search_memory("   ")
        assert whitespace_result is not None
    
    def test_large_document_handling(self, rag_system):
        """æµ‹è¯•å¤§æ–‡æ¡£å¤„ç†"""
        # åˆ›å»ºä¸€ä¸ªå¤§æ–‡æ¡£
        large_content = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æ¡£ã€‚" * 1000
        
        result = rag_system.store_memory(large_content)
        
        # éªŒè¯å¤§æ–‡æ¡£å­˜å‚¨
        assert result is not None
        assert "error" not in result
        
        # æœç´¢å¤§æ–‡æ¡£
        search_result = rag_system.search_memory("å¾ˆé•¿çš„æ–‡æ¡£")
        assert search_result is not None
    
    def test_unicode_content_handling(self, rag_system):
        """æµ‹è¯•Unicodeå†…å®¹å¤„ç†"""
        unicode_contents = [
            "è¿™æ˜¯ä¸­æ–‡å†…å®¹ï¼ŒåŒ…å«å„ç§å­—ç¬¦ï¼šä½ å¥½ä¸–ç•Œï¼",
            "English content with Ã©mojis: ğŸš€ğŸ¤–ğŸ”",
            "Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ°Ğ¼Ğ¸",
            "æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚ã“ã‚“ã«ã¡ã¯ï¼",
            "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"
        ]
        
        # å­˜å‚¨Unicodeå†…å®¹
        for content in unicode_contents:
            result = rag_system.store_memory(content)
            assert result is not None
            assert "error" not in result
        
        # æœç´¢Unicodeå†…å®¹
        search_result = rag_system.search_memory("ä¸­æ–‡å†…å®¹")
        assert search_result is not None
    
    def test_document_updating(self, rag_system):
        """æµ‹è¯•æ–‡æ¡£æ›´æ–°åŠŸèƒ½"""
        original_content = "è¿™æ˜¯åŸå§‹æ–‡æ¡£å†…å®¹ã€‚"
        updated_content = "è¿™æ˜¯æ›´æ–°åçš„æ–‡æ¡£å†…å®¹ã€‚"
        
        # å­˜å‚¨åŸå§‹æ–‡æ¡£
        doc_id = rag_system.store_memory(original_content)
        
        # æ›´æ–°æ–‡æ¡£ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(rag_system, 'update_memory'):
            update_result = rag_system.update_memory(doc_id, updated_content)
            assert update_result is not None
    
    def test_document_deletion(self, rag_system):
        """æµ‹è¯•æ–‡æ¡£åˆ é™¤åŠŸèƒ½"""
        content = "è¿™æ˜¯è¦åˆ é™¤çš„æ–‡æ¡£ã€‚"
        
        # å­˜å‚¨æ–‡æ¡£
        doc_id = rag_system.store_memory(content)
        
        # åˆ é™¤æ–‡æ¡£ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(rag_system, 'delete_memory'):
            delete_result = rag_system.delete_memory(doc_id)
            assert delete_result is not None
    
    @patch('tools.long_term_memory.EmbeddingClient')
    def test_embedding_error_handling(self, mock_embedding_client, rag_system):
        """æµ‹è¯•åµŒå…¥ç”Ÿæˆé”™è¯¯å¤„ç†"""
        # æ¨¡æ‹ŸåµŒå…¥ç”Ÿæˆå¤±è´¥
        mock_client = Mock()
        mock_client.get_embedding.side_effect = Exception("Embedding generation failed")
        mock_embedding_client.return_value = mock_client
        
        # å°è¯•å­˜å‚¨æ–‡æ¡£
        result = rag_system.store_memory("æµ‹è¯•å†…å®¹")
        
        # éªŒè¯é”™è¯¯å¤„ç†
        assert result is not None
    
    def test_batch_document_storage(self, rag_system, sample_documents):
        """æµ‹è¯•æ‰¹é‡æ–‡æ¡£å­˜å‚¨"""
        # æ‰¹é‡å­˜å‚¨æ–‡æ¡£ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(rag_system, 'store_memories_batch'):
            contents = [doc["content"] for doc in sample_documents]
            metadatas = [doc["metadata"] for doc in sample_documents]
            
            batch_result = rag_system.store_memories_batch(contents, metadatas)
            assert batch_result is not None
        else:
            # é€ä¸ªå­˜å‚¨æ–‡æ¡£
            for doc in sample_documents:
                result = rag_system.store_memory(
                    content=doc["content"],
                    metadata=doc["metadata"]
                )
                assert result is not None
    
    def test_search_result_ranking(self, rag_system, sample_documents):
        """æµ‹è¯•æœç´¢ç»“æœæ’åº"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æ‰§è¡Œæœç´¢
        results = rag_system.search_memory("AGI BotåŠŸèƒ½ç‰¹æ€§", top_k=5)
        
        # éªŒè¯ç»“æœæ’åºï¼ˆç»“æœåº”è¯¥æŒ‰ç›¸å…³æ€§æ’åºï¼‰
        assert results is not None
        if isinstance(results, list) and len(results) > 1:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³æ€§è¯„åˆ†
            for result in results:
                if isinstance(result, dict):
                    # å¦‚æœæœ‰è¯„åˆ†å­—æ®µï¼ŒéªŒè¯æ’åº
                    if 'score' in result or 'similarity' in result:
                        assert True  # æœ‰è¯„åˆ†ä¿¡æ¯
                        break
    
    def test_memory_persistence(self, rag_system, test_workspace):
        """æµ‹è¯•è®°å¿†æŒä¹…åŒ–"""
        content = "è¿™æ˜¯éœ€è¦æŒä¹…åŒ–çš„è®°å¿†å†…å®¹ã€‚"
        
        # å­˜å‚¨è®°å¿†
        result = rag_system.store_memory(content)
        assert result is not None
        
        # åˆ›å»ºæ–°çš„RAGç³»ç»Ÿå®ä¾‹
        new_rag_system = LongTermMemory(workspace_root=test_workspace)
        
        # æœç´¢ä¹‹å‰å­˜å‚¨çš„å†…å®¹
        search_result = new_rag_system.search_memory("æŒä¹…åŒ–çš„è®°å¿†")
        
        # éªŒè¯æŒä¹…åŒ–
        assert search_result is not None
    
    def test_concurrent_operations(self, rag_system):
        """æµ‹è¯•å¹¶å‘æ“ä½œ"""
        import threading
        import time
        
        results = []
        errors = []
        
        def store_operation(content_id):
            try:
                content = f"å¹¶å‘æµ‹è¯•å†…å®¹ {content_id}"
                result = rag_system.store_memory(content)
                results.append(result)
            except Exception as e:
                errors.append(e)
        
        def search_operation(query_id):
            try:
                result = rag_system.search_memory(f"æµ‹è¯•æŸ¥è¯¢ {query_id}")
                results.append(result)
            except Exception as e:
                errors.append(e)
        
        # åˆ›å»ºå¹¶å‘çº¿ç¨‹
        threads = []
        
        # æ·»åŠ å­˜å‚¨çº¿ç¨‹
        for i in range(5):
            thread = threading.Thread(target=store_operation, args=(i,))
            threads.append(thread)
        
        # æ·»åŠ æœç´¢çº¿ç¨‹
        for i in range(3):
            thread = threading.Thread(target=search_operation, args=(i,))
            threads.append(thread)
        
        # å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        for thread in threads:
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join(timeout=10)
        
        # éªŒè¯å¹¶å‘æ“ä½œ
        assert len(errors) == 0, f"Concurrent operation errors: {errors}"
        assert len(results) > 0
    
    def test_memory_statistics(self, rag_system, sample_documents):
        """æµ‹è¯•è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(rag_system, 'get_statistics'):
            stats = rag_system.get_statistics()
            assert stats is not None
            assert isinstance(stats, dict)
    
    def test_memory_export_import(self, rag_system, sample_documents, test_workspace):
        """æµ‹è¯•è®°å¿†å¯¼å‡ºå¯¼å…¥"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # å¯¼å‡ºè®°å¿†ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(rag_system, 'export_memories'):
            export_path = os.path.join(test_workspace, "memory_export.json")
            export_result = rag_system.export_memories(export_path)
            assert export_result is not None
            assert os.path.exists(export_path)
        
        # å¯¼å…¥è®°å¿†ï¼ˆå¦‚æœæ”¯æŒï¼‰
        if hasattr(rag_system, 'import_memories'):
            import_result = rag_system.import_memories(export_path)
            assert import_result is not None
    
    def test_query_expansion(self, rag_system, sample_documents):
        """æµ‹è¯•æŸ¥è¯¢æ‰©å±•åŠŸèƒ½"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æµ‹è¯•ç®€çŸ­æŸ¥è¯¢çš„æ‰©å±•
        short_query = "æ™ºèƒ½ä½“"
        results = rag_system.search_memory(short_query)
        
        # éªŒè¯æŸ¥è¯¢æ‰©å±•æ•ˆæœ
        assert results is not None
    
    def test_context_aware_search(self, rag_system, sample_documents):
        """æµ‹è¯•ä¸Šä¸‹æ–‡æ„ŸçŸ¥æœç´¢"""
        # å­˜å‚¨æ–‡æ¡£
        for doc in sample_documents:
            rag_system.store_memory(
                content=doc["content"],
                metadata=doc["metadata"]
            )
        
        # æä¾›ä¸Šä¸‹æ–‡çš„æœç´¢ï¼ˆå¦‚æœæ”¯æŒï¼‰
        context = "æˆ‘æƒ³äº†è§£AGI Botçš„ä¸»è¦åŠŸèƒ½"
        query = "åä½œåŠŸèƒ½"
        
        if hasattr(rag_system, 'search_with_context'):
            results = rag_system.search_with_context(query, context)
            assert results is not None
        else:
            # æ™®é€šæœç´¢
            results = rag_system.search_memory(query)
            assert results is not None 