#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Copyright (c) 2025 AGI Agent Research Group.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

from flask import Flask, render_template, request, jsonify, send_file, send_from_directory, after_this_request, abort, Response
from flask_socketio import SocketIO, emit, join_room, leave_room
import os
import sys
import threading
from datetime import datetime
import shutil
import zipfile
from werkzeug.utils import secure_filename
import multiprocessing
import queue
import re
import time
import json
import psutil
from collections import defaultdict
from threading import Lock, Semaphore
import argparse

# Note: We use the default multiprocessing start method
# 'fork' is faster but unsafe in multi-threaded environment (Flask/SocketIO)
# 'spawn' is slower but safer


# Determine template and static directories FIRST - always relative to this app.py file
# Get the directory where app.py is located (before any directory changes)
app_dir = os.path.dirname(os.path.abspath(__file__))
template_dir = os.path.join(app_dir, 'templates')
static_dir = os.path.join(app_dir, 'static')

# Add parent directory to path to import config_loader
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config_loader import get_language, get_gui_default_data_directory
from auth_manager import AuthenticationManager

# Import Mermaid processor

try:
    from src.tools.mermaid_processor import mermaid_processor
    MERMAID_PROCESSOR_AVAILABLE = True
except ImportError:
    MERMAID_PROCESSOR_AVAILABLE = False

# Import SVG optimizers
try:
    from src.utils.advanced_svg_optimizer import AdvancedSVGOptimizer, OptimizationLevel
    SVG_OPTIMIZER_AVAILABLE = True
except ImportError:
    #print("âš ï¸ Advanced SVG optimizer not available")
    SVG_OPTIMIZER_AVAILABLE = False

try:
    from src.utils.llm_svg_optimizer import create_llm_optimizer_from_env
    LLM_SVG_OPTIMIZER_AVAILABLE = True
except ImportError:
    #print("âš ï¸ LLM SVG optimizer not available")
    LLM_SVG_OPTIMIZER_AVAILABLE = False

# Import SVG to PNG converter
try:
    from src.tools.svg_to_png import EnhancedSVGToPNGConverter
    SVG_TO_PNG_CONVERTER_AVAILABLE = True
except ImportError:
    #print("âš ï¸ SVG to PNG converter not available")
    SVG_TO_PNG_CONVERTER_AVAILABLE = False

# Import agent status visualizer functions
try:
    # Import from same directory as app.py (GUI directory)
    from agent_status_visualizer import (
        find_status_files, load_status_file, find_message_files,
        find_tool_calls_from_logs, find_mermaid_figures_from_plan,
        find_status_updates, find_latest_output_dir
    )
    AGENT_VISUALIZER_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Agent status visualizer not available: {e}")
    AGENT_VISUALIZER_AVAILABLE = False

# Check current directory, switch to parent directory if in GUI directory
current_dir = os.getcwd()
current_dir_name = os.path.basename(current_dir)

if current_dir_name == 'GUI':
    parent_dir = os.path.dirname(current_dir)
    os.chdir(parent_dir)
else:
    pass

# Add parent directory to path to import main.py
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Application name macro definition
APP_NAME = "AGI Agent"

from src.main import AGIAgentMain




# Concurrency control and performance monitoring class
class ConcurrencyManager:
    """Concurrency Control and Performance Monitoring Manager"""
    
    def __init__(self, max_concurrent_tasks=16, max_connections=40, task_timeout=3600, gui_instance=None):  # 60 minute timeout (Expand by 1x)
        self.max_concurrent_tasks = max_concurrent_tasks
        self.max_connections = max_connections
        self.task_timeout = task_timeout  # ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆSecondsï¼‰
        self.gui_instance = gui_instance  # Reference to GUI instance for session cleanup
        
        # Concurrency control
        self.task_semaphore = Semaphore(max_concurrent_tasks)
        self.active_tasks = {}  # session_id -> task_info
        self.task_queue = queue.Queue()  # Task queuing
        self.connection_count = 0
        self.lock = Lock()
        

        
        # Performance monitoring
        self.metrics = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'avg_task_duration': 0.0,
            'active_connections': 0,
            'peak_memory_usage': 0.0,
            'last_updated': time.time()
        }
        
        # Unified resource and monitoring thread
        self.monitor_active = True
        self.monitor_thread = threading.Thread(target=self._unified_monitor, daemon=True)
        self.monitor_thread.start()
        

    
    def can_accept_connection(self):
        """Check if new connections can be accepted"""
        with self.lock:
            return self.connection_count < self.max_connections
    
    def add_connection(self):
        """Add connection"""
        with self.lock:
            if self.connection_count < self.max_connections:
                self.connection_count += 1
                self.metrics['active_connections'] = self.connection_count
                return True
            return False
    
    def remove_connection(self):
        """Remove connection"""
        with self.lock:
            if self.connection_count > 0:
                self.connection_count -= 1
                self.metrics['active_connections'] = self.connection_count
    
    def can_start_task(self, session_id):
        """Check if new tasks can be started"""
        # Non-blocking check semaphore
        acquired = self.task_semaphore.acquire(blocking=False)
        if acquired:
            with self.lock:
                self.active_tasks[session_id] = {
                    'start_time': time.time(),
                    'status': 'running'
                }
                self.metrics['total_tasks'] += 1
            return True
        return False
    
    def finish_task(self, session_id, success=True):
        """Complete task"""
        self.task_semaphore.release()
        
        with self.lock:
            if session_id in self.active_tasks:
                task_info = self.active_tasks.pop(session_id)
                duration = time.time() - task_info['start_time']
                
                if success:
                    self.metrics['completed_tasks'] += 1
                else:
                    self.metrics['failed_tasks'] += 1
                
                # Update average execution time
                total_completed = self.metrics['completed_tasks'] + self.metrics['failed_tasks']
                if total_completed > 0:
                    current_avg = self.metrics['avg_task_duration']
                    self.metrics['avg_task_duration'] = (current_avg * (total_completed - 1) + duration) / total_completed
    
    def get_metrics(self):
        """Get performance metrics"""
        with self.lock:
            metrics_copy = self.metrics.copy()
            metrics_copy['active_tasks'] = len(self.active_tasks)
            metrics_copy['queue_size'] = self.task_queue.qsize()
            return metrics_copy
    
    def _unified_monitor(self):
        """Unified resource and monitoring thread - handles resources, timeouts, and session cleanup"""
        resource_check_counter = 0
        timeout_check_counter = 0
        session_cleanup_counter = 0
        
        while self.monitor_active:
            try:
                # Check resources every 30 seconds (every 6 cycles of 5 seconds)
                resource_check_counter += 1
                if resource_check_counter >= 6:
                    resource_check_counter = 0
                    try:
                        process = psutil.Process()
                        memory_info = process.memory_info()
                        memory_mb = memory_info.rss / 1024 / 1024
                        
                        with self.lock:
                            if memory_mb > self.metrics['peak_memory_usage']:
                                self.metrics['peak_memory_usage'] = memory_mb
                            self.metrics['last_updated'] = time.time()
                    except Exception as e:
                        pass  # Ignore metrics error
                
                # Check timeouts every 60 seconds (every 12 cycles of 5 seconds)
                timeout_check_counter += 1
                if timeout_check_counter >= 12:
                    timeout_check_counter = 0
                    try:
                        current_time = time.time()
                        timeout_sessions = []
                        
                        with self.lock:
                            for session_id, task_info in self.active_tasks.items():
                                if current_time - task_info['start_time'] > self.task_timeout:
                                    timeout_sessions.append(session_id)
                        
                        # Handle timeout tasks
                        for session_id in timeout_sessions:
                            self._handle_task_timeout(session_id)
                    except Exception as e:
                        pass
                
                # Check idle sessions every 30 minutes (every 360 cycles of 5 seconds)
                session_cleanup_counter += 1
                if session_cleanup_counter >= 360:
                    session_cleanup_counter = 0
                    if self.gui_instance:
                        try:
                            self._cleanup_idle_sessions_for_gui()
                        except Exception as e:
                            pass
                
                # Sleep 5 seconds per cycle
                time.sleep(5)
                
            except Exception as e:
                time.sleep(10)
    
    def _cleanup_idle_sessions_for_gui(self):
        """Clean up idle sessions - integrated from GUI class"""
        if not self.gui_instance:
            return
            
        try:
            current_time = time.time()
            idle_sessions = []
            
            # Check idle sessions (no activity for over 2 hours)
            for session_id, user_session in self.gui_instance.user_sessions.items():
                # Check if authentication session is still valid
                session_info = self.gui_instance.auth_manager.validate_session(session_id)
                if not session_info:
                    idle_sessions.append(session_id)
                    continue
                
                # Check if there are running processes
                if user_session.current_process and user_session.current_process.is_alive():
                    continue  # æœ‰æ´»åŠ¨è¿›ç¨‹ï¼Œä¸æ¸…ç†
            
            # Clean up idle sessions
            for session_id in idle_sessions:
                try:
                    if hasattr(self.gui_instance, '_cleanup_session'):
                        self.gui_instance._cleanup_session(session_id)
                except Exception as e:
                    pass  # Silent cleanup
        except Exception as e:
            pass  # Cleanup error
    
    def _handle_task_timeout(self, session_id):
        """Handle task timeout"""
        # This method needs to set callback after GUI instance initialization
        if hasattr(self, '_timeout_callback') and self._timeout_callback:
            self._timeout_callback(session_id)
    
    def set_timeout_callback(self, callback):
        """Set timeout handling callback"""
        self._timeout_callback = callback
    

    
    def get_task_runtime(self, session_id):
        """Get task running time"""
        with self.lock:
            if session_id in self.active_tasks:
                return time.time() - self.active_tasks[session_id]['start_time']
            return 0
    

    
    def stop(self):
        """Stop monitoring"""
        self.monitor_active = False
        if hasattr(self, 'monitor_thread') and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=2)



app = Flask(__name__, template_folder=template_dir, static_folder=static_dir)
app.config['SECRET_KEY'] = f'{APP_NAME.lower().replace(" ", "_")}_gui_secret_key'
# è°ƒæ•´å¿ƒè·³é—´éš”ä¸º25ç§’ï¼Œç¡®ä¿å³ä½¿nginxçš„proxy_read_timeoutä¸º300ç§’ä¹Ÿèƒ½ä¿æŒè¿æ¥
# ping_timeoutè®¾ç½®ä¸ºping_intervalçš„3å€ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å®¹é”™æ—¶é—´
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading', 
                   ping_timeout=75, ping_interval=25)  


import logging
logging.getLogger('werkzeug').setLevel(logging.CRITICAL)

I18N_TEXTS = {
    'zh': {
        # Page title and basic information
        'page_title': f'{APP_NAME}',
        'app_title': f'{APP_NAME}',
        'app_subtitle': '',
        'connected': '',  # å·²åˆ é™¤è¿æ¥æˆåŠŸæ¶ˆæ¯
        
        # Button text
        'execute_direct': 'ç›´æ¥æ‰§è¡Œ',
        'execute_plan': 'è®¡åˆ’æ¨¡å¼', 
        'new_directory': 'æ–°å»ºç›®å½•',
        'stop_task': 'åœæ­¢ä»»åŠ¡',
        'refresh': 'åˆ·æ–°',
        'upload': 'ä¸Šä¼ ',
        'download': 'ä¸‹è½½',
        'rename': 'é‡å‘½å',
        'delete': 'åˆ é™¤',
        'confirm': 'ç¡®è®¤',
        'cancel': 'å–æ¶ˆ',
        'clear_chat': 'æ¸…æ‰«',
        
        # Button tooltips
        'direct_tooltip': 'ç›´æ¥æ‰§è¡Œ - ä¸è¿›è¡Œä»»åŠ¡åˆ†è§£',
        'plan_tooltip': 'è®¡åˆ’æ¨¡å¼ - å…ˆåˆ†è§£ä»»åŠ¡å†æ‰§è¡Œ',
        'new_tooltip': 'æ–°å»ºç›®å½• - åˆ›å»ºæ–°çš„å·¥ä½œç›®å½•',
        'refresh_tooltip': 'åˆ·æ–°ç›®å½•åˆ—è¡¨',
        'upload_tooltip': 'ä¸Šä¼ æ–‡ä»¶åˆ°Workspace',
        'download_tooltip': 'ä¸‹è½½ç›®å½•ä¸ºZIPï¼ˆæ’é™¤code_indexï¼‰',
        'rename_tooltip': 'é‡å‘½åç›®å½•',
        'delete_tooltip': 'åˆ é™¤ç›®å½•',
        'clear_chat_tooltip': 'æ¸…ç©ºæ—¥å¿—æ˜¾ç¤ºåŒºåŸŸå’Œå†å²å¯¹è¯',
        
        # Input boxes and placeholders
        'input_placeholder': 'è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚...',
        'rename_placeholder': 'è¯·è¾“å…¥æ–°çš„ç›®å½•åç§°',
        
        # Modal titles
        'upload_title': 'ä¸Šä¼ æ–‡ä»¶åˆ°Workspace',
        'rename_title': 'é‡å‘½åç›®å½•',
        'confirm_rename': 'ç¡®è®¤é‡å‘½å',
        
        # Status messages
        'task_running': 'ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­...',
        'no_task_running': 'å½“å‰æ²¡æœ‰ä»»åŠ¡åœ¨è¿è¡Œ',
        'task_stopped': 'ä»»åŠ¡å·²è¢«ç”¨æˆ·åœæ­¢',
        'task_completed': 'ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼',
        'task_completed_with_errors': 'ä»»åŠ¡è¾¾åˆ°æœ€å¤§è½®æ•°ï¼Œå¯èƒ½æœªå®Œå…¨å®Œæˆ',
        'task_failed': 'ä»»åŠ¡æ‰§è¡Œå¤±è´¥',
        'creating_directory': 'æ­£åœ¨è‡ªåŠ¨åˆ›å»ºæ–°å·¥ä½œç›®å½•...',
        'directory_created': 'å·²åˆ›å»ºæ–°å·¥ä½œç›®å½•',
        'directory_selected': 'å·²é€‰æ‹©ç›®å½•',
        'directory_renamed': 'ç›®å½•é‡å‘½åæˆåŠŸ',
        'directory_deleted': 'ç›®å½•åˆ é™¤æˆåŠŸ',
        'files_uploaded': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ',
        'refresh_success': 'ç›®å½•åˆ—è¡¨å·²åˆ·æ–°',
        'chat_cleared': 'æ—¥å¿—å’Œå†å²å¯¹è¯å·²æ¸…ç©º',
        'confirm_clear_chat': 'ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰æ—¥å¿—å’Œå†å²å¯¹è¯å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚',
        
        # Mode information
        'direct_mode_info': 'âš¡ ç›´æ¥æ‰§è¡Œæ¨¡å¼ï¼šä¸è¿›è¡Œä»»åŠ¡åˆ†è§£',
        'new_mode_info': 'æ–°å»ºç›®å½•æ¨¡å¼ - ç‚¹å‡»ç»¿è‰²æŒ‰é’®åˆ›å»ºæ–°å·¥ä½œç›®å½•ï¼Œæˆ–é€‰æ‹©ç°æœ‰ç›®å½•',
        'selected_dir_info': 'å·²é€‰æ‹©ç›®å½•',
        
        # Error messages
        'error_no_requirement': 'è¯·æä¾›æœ‰æ•ˆçš„éœ€æ±‚',
        'error_task_running': 'å·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ',
        'error_no_directory': 'è¯·å…ˆé€‰æ‹©ç›®å½•',
        'error_no_files': 'è¯·å…ˆé€‰æ‹©æ–‡ä»¶',
        'error_delete_confirm': 'ç¡®å®šè¦åˆ é™¤ç›®å½•',
        'error_delete_warning': 'æ­¤æ“ä½œä¸å¯æ’¤é”€ï¼Œå°†æ°¸ä¹…åˆ é™¤è¯¥ç›®å½•åŠå…¶æ‰€æœ‰å†…å®¹ã€‚',
        'error_rename_empty': 'æ–°åç§°ä¸èƒ½ä¸ºç©º',
        'error_rename_same': 'æ–°åç§°ä¸åŸåç§°ç›¸åŒæˆ–åŒ…å«æ— æ•ˆå­—ç¬¦',
        'error_directory_exists': 'ç›®æ ‡ç›®å½•å·²å­˜åœ¨',
        'error_directory_not_found': 'ç›®å½•ä¸å­˜åœ¨',
        'error_permission_denied': 'æƒé™ä¸è¶³',
        'error_file_too_large': 'æ–‡ä»¶è¿‡å¤§æ— æ³•æ˜¾ç¤º',
        'error_file_not_supported': 'ä¸æ”¯æŒé¢„è§ˆæ­¤æ–‡ä»¶ç±»å‹',
        
        # PDF preview
        'pdf_pages': 'å…± {pages} é¡µ',
        'pdf_pages_simple': 'å…± {pages} é¡µ (ç®€åŒ–æ¨¡å¼)',
        'download_pdf': 'ä¸‹è½½PDF',
        'pdf_loading': 'æ­£åœ¨åŠ è½½æ‰€æœ‰é¡µé¢...',
        'pdf_render_error': 'PDFé¡µé¢æ¸²æŸ“å¤±è´¥',
        
        # Delete warnings
        'delete_current_executing_warning': 'âš ï¸ è­¦å‘Šï¼šè¿™æ˜¯å½“å‰æ­£åœ¨æ‰§è¡Œçš„ç›®å½•ï¼',
        'delete_selected_warning': 'âš ï¸ è­¦å‘Šï¼šè¿™æ˜¯å½“å‰é€‰æ‹©çš„ç›®å½•ï¼',
        
        # File operations
        'file_size': 'æ–‡ä»¶å¤§å°',
        'download_file': 'ä¸‹è½½æ–‡ä»¶',
        'office_preview_note': 'Officeæ–‡æ¡£é¢„è§ˆ',
        'office_download_note': 'ä¸‹è½½æ–‡ä»¶: ä¸‹è½½åˆ°æœ¬åœ°ä½¿ç”¨Officeè½¯ä»¶æ‰“å¼€',
        'drag_unselected_dir_warning': 'è¯·å…ˆé€‰æ‹©æ­¤å·¥ä½œç›®å½•åå†æ‹–åŠ¨',
        
        # Tool execution status
        'tool_running': 'æ‰§è¡Œä¸­',
        'tool_success': 'æˆåŠŸ',
        'tool_error': 'é”™è¯¯',
        'function_calling': 'è°ƒç”¨ä¸­',
        'tool_call': 'å·¥å…·è°ƒç”¨',
        'json_output': 'JSONè¾“å‡º',
        'image': 'å›¾ç‰‡',
        'dimensions': 'å°ºå¯¸',
        'total_rows': 'æ€»è¡Œæ•°',
        'columns': 'åˆ—æ•°',
        
        # Configuration options
        'config_options': 'é…ç½®é€‰é¡¹',
        'show_config_options': 'æ˜¾ç¤ºé…ç½®é€‰é¡¹',
        'hide_config_options': 'éšè—é…ç½®é€‰é¡¹',
        'routine_file': 'ä»»åŠ¡ç±»å‹',
        'task_type': 'æ¨¡å¼é€‰æ‹©',
        'no_routine': 'è¯·é€‰æ‹©...',
        'enable_web_search': 'æœç´¢ç½‘ç»œ',
        'enable_multi_agent': 'å¯åŠ¨å¤šæ™ºèƒ½ä½“',
        'enable_long_term_memory': 'å¯åŠ¨é•¿æœŸè®°å¿†',
        'enable_mcp': 'MCPå·¥å…·é…ç½®',
        'enable_jieba': 'å¯ç”¨ä¸­æ–‡åˆ†è¯',
        'execution_mode': 'æ‰§è¡Œæ¨¡å¼',
        'agent_mode': 'Agentæ¨¡å¼',
        'plan_mode': 'Planæ¨¡å¼',
        'user_input_request': 'ç”¨æˆ·è¾“å…¥è¯·æ±‚',
        'enter_your_response': 'è¯·è¾“å…¥æ‚¨çš„å›å¤...',
        'submit': 'æäº¤',
        'append_task': 'è¿½åŠ ä»»åŠ¡',
        'append_task_empty': 'è¯·è¾“å…¥è¦è¿½åŠ çš„ä»»åŠ¡å†…å®¹',
        'append_task_success': 'ä»»åŠ¡å·²æˆåŠŸå‘é€ç»™æ™ºèƒ½ä½“',
        'append_task_sent': 'ä»»åŠ¡å·²è¿½åŠ åˆ°inbox',
        
        # Others
        'deleting': 'åˆ é™¤ä¸­...',
        'renaming': 'é‡å‘½åä¸­...',
        'uploading': 'ä¸Šä¼ ä¸­...',
        'edit_mermaid_placeholder': 'ç¼–è¾‘Mermaidå†…å®¹...',
        'convert_to_images': 'å°†mermaidè½¬æ¢ä¸ºPNGå’ŒSVGå›¾åƒ',
        'convert_to_images_short': 'è½¬æ¢ä¸ºå›¾åƒ',
        'loading': 'åŠ è½½ä¸­...',
        'system_message': 'ç³»ç»Ÿæ¶ˆæ¯',
        'welcome_message': f'æ¬¢è¿ä½¿ç”¨ {APP_NAME}ï¼è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„éœ€æ±‚ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ä¸ºæ‚¨å¤„ç†ä»»åŠ¡ã€‚',
        'workspace_title': 'å·¥ä½œç›®å½•',
        'file_preview': 'æ–‡ä»¶é¢„è§ˆ',
        'data_directory_info': 'æ•°æ®ç›®å½•',
        'disconnected': 'ä¸æœåŠ¡å™¨æ–­å¼€è¿æ¥',
        'drag_files': 'æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„æˆ–ç‚¹å‡»é€‰æ‹©æ–‡ä»¶',
        'upload_hint': 'æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼Œæ–‡ä»¶å°†ä¿å­˜åˆ°é€‰å®šç›®å½•çš„workspaceæ–‡ä»¶å¤¹ä¸­',
        'select_files': 'é€‰æ‹©æ–‡ä»¶',
        
        # Additional bilingual text
        'new_messages': 'æ¡æ–°æ¶ˆæ¯',
        'auto_scroll': 'è‡ªåŠ¨æ»šåŠ¨',
        'scroll_to_bottom': 'æ»šåŠ¨åˆ°åº•éƒ¨',
        'continue_mode_info': 'ç»§ç»­æ¨¡å¼ - å°†ä½¿ç”¨ä¸Šæ¬¡çš„å·¥ä½œç›®å½•',
        'create_or_select_directory': 'è¯·å…ˆç‚¹å‡»ç»¿è‰²æŒ‰é’®åˆ›å»ºæ–°å·¥ä½œç›®å½•ï¼Œæˆ–é€‰æ‹©å³ä¾§çš„ç°æœ‰ç›®å½•',
        'select_directory_first': 'è¯·å…ˆåˆ›å»ºæˆ–è€…é€‰æ‹©ä¸€ä¸ªå·¥ä½œç›®å½•ï¼Œé¼ æ ‡å•å‡»å·¥ä½œç›®å½•ä¸­çš„æŸä¸ªæ–‡ä»¶å¤¹ï¼Œç›´åˆ°å˜ä¸ºè“è‰²ä»£è¡¨é€‰ä¸­',
        'current_name': 'å½“å‰åç§°ï¼š',
        'new_name': 'æ–°åç§°ï¼š',
        'rename_info': 'å°†ä½¿ç”¨æ‚¨è¾“å…¥çš„åç§°ä½œä¸ºç›®å½•å',
        'paused': 'å·²æš‚åœ',
        'load_directory_failed': 'åŠ è½½ç›®å½•å¤±è´¥',
        'network_error': 'ç½‘ç»œé”™è¯¯',
        'upload_network_error': 'ç½‘ç»œé”™è¯¯ï¼Œä¸Šä¼ å¤±è´¥',
        'rename_failed': 'é‡å‘½åå¤±è´¥',
        'rename_error': 'é‡å‘½åå‡ºé”™',
        'refresh_failed': 'åˆ·æ–°å¤±è´¥',
        'attempt': 'å°è¯•',
        'create_directory_failed': 'åˆ›å»ºç›®å½•å¤±è´¥',
        'preview': 'é¢„è§ˆ',
        'page_info': 'ç¬¬ {0} é¡µï¼Œå…± {1} é¡µ',
        'upload_to': 'ä¸Šä¼ æ–‡ä»¶åˆ°',
        'workspace': '/workspace',
        'select_directory_error': 'è¯·å…ˆé€‰æ‹©ç›®å½•',
        'please_connect': 'è¯·å…ˆè¿æ¥æœåŠ¡å™¨',
        'uploading_files': 'æ­£åœ¨ä¸Šä¼  {0} ä¸ªæ–‡ä»¶',
        'upload_progress': 'ä¸Šä¼ è¿›åº¦: {0}%',
        'upload_completed': 'ä¸Šä¼ æ–‡æ¡£å·²å®Œæˆ',
        'upload_failed_http': 'ä¸Šä¼ å¤±è´¥: HTTP {0}',
        
        # Directory operations
        'directory_created_with_workspace': 'å·²åˆ›å»ºæ–°å·¥ä½œç›®å½•: {0} (åŒ…å«workspaceå­ç›®å½•)',
        'directory_list_refreshed': 'ç›®å½•åˆ—è¡¨å·²åˆ·æ–°',
        'no_files_selected': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶',
        'no_valid_files': 'æ²¡æœ‰é€‰æ‹©æœ‰æ•ˆæ–‡ä»¶',
        'target_directory_not_exist': 'ç›®æ ‡ç›®å½•ä¸å­˜åœ¨',
        'upload_success': 'æˆåŠŸä¸Šä¼  {0} ä¸ªæ–‡ä»¶',
        'new_name_empty': 'æ–°åç§°ä¸èƒ½ä¸ºç©º',
        
        # Multi-user support
        'api_key_label': 'API Key:',
        'api_key_placeholder': 'è¾“å…¥API Key (å¯é€‰)',
        'api_key_tooltip': 'è¾“å…¥æ‚¨çš„API Keyï¼Œç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤ç”¨æˆ·æ¨¡å¼',
        'connect_btn': 'è¿æ¥',
        'disconnect_btn': 'æ–­å¼€',
        'connecting': 'è¿æ¥ä¸­...',
        'user_connected': 'å·²è¿æ¥',
        'user_disconnected': 'æœªè¿æ¥',
        'user_connection_failed': 'è¿æ¥å¤±è´¥',
        'connection_error': 'è¿æ¥é”™è¯¯',
        'reconnecting': 'æ­£åœ¨å°è¯•é‡æ–°è¿æ¥...',
        'reconnect_attempt': 'æ­£åœ¨å°è¯•é‡æ–°è¿æ¥',
        'reconnect_success': 'å·²é‡æ–°è¿æ¥åˆ°æœåŠ¡å™¨',
        'reconnect_failed_cleanup': 'è‡ªåŠ¨é‡è¿å¤±è´¥ï¼Œå·²æ¸…ç©ºå·¥ä½œç›®å½•ï¼Œè¯·é‡æ–°è¿æ¥',
        'reconnect_error': 'è‡ªåŠ¨é‡è¿å‡ºé”™',
        'default_user': 'é»˜è®¤ç”¨æˆ·',
        'user_prefix': 'ç”¨æˆ·',
        'guest_user': 'è®¿å®¢ç”¨æˆ·',
        'temporary_connection': 'ä¸´æ—¶è¿æ¥',
        'auto_login_from_url': 'å·²é€šè¿‡URLå‚æ•°è‡ªåŠ¨ç™»å½•',
        'session_restored': 'å·²æ¢å¤ä¸Šæ¬¡ç™»å½•ä¼šè¯',
        
        # Model selection
        'model_label': 'æ¨¡å‹:',
        'model_tooltip': 'é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹',
        'model_claude_sonnet': 'claude-sonnet-4-0 (é«˜ç²¾åº¦)',
        'model_gpt_4': 'gpt-4.1 (é«˜æ•ˆç‡)',
        'config_error_title': 'é…ç½®é”™è¯¯',
        'config_error_invalid_key': 'API Keyé…ç½®æ— æ•ˆï¼Œè¯·æ£€æŸ¥config/config.txtæ–‡ä»¶ä¸­çš„GUI API configurationéƒ¨åˆ†',
        
        # Custom model config dialog
        'custom_config_title': 'è‡ªå®šä¹‰æ¨¡å‹é…ç½®',
        'custom_api_key_label': 'API Key:',
        'custom_api_base_label': 'API Base URL:',
        'custom_model_label': 'æ¨¡å‹åç§°:',
        'custom_max_tokens_label': 'Max Output Tokens:',
        'custom_api_key_placeholder': 'è¯·è¾“å…¥API Key',
        'custom_api_base_placeholder': 'è¯·è¾“å…¥API Base URLï¼ˆå¦‚ï¼šhttps://api.example.com/v1ï¼‰',
        'custom_model_placeholder': 'è¯·è¾“å…¥æ¨¡å‹åç§°ï¼ˆå¦‚ï¼šgpt-4ï¼‰',
        'custom_max_tokens_placeholder': 'è¯·è¾“å…¥æœ€å¤§è¾“å‡ºtokenæ•°é‡ï¼ˆé»˜è®¤ï¼š8192ï¼‰',
        'custom_config_save': 'ä¿å­˜é…ç½®',
        'custom_config_cancel': 'å–æ¶ˆ',
        'custom_config_required': 'æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…å¡«çš„',
        'save_to_config_confirm': 'å·²è®¾ç½®ä¸ºä¸´æ—¶é…ç½®ï¼Œæ˜¯å¦å°†æ­¤é…ç½®ä¿å­˜åˆ° config/config.txt ä½œä¸ºé•¿æœŸé…ç½®ï¼Ÿ\n\nè¿™å°†æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ¨¡å‹è®¾ç½®ã€‚',
        'save_to_config_success': 'é…ç½®å·²æˆåŠŸä¿å­˜åˆ° config.txt',
        'save_to_config_failed': 'ä¿å­˜åˆ° config.txt å¤±è´¥',
        'save_to_config_error': 'ä¿å­˜åˆ° config.txt æ—¶å‘ç”Ÿé”™è¯¯',
        
        # Additional UI elements
        'new_messages': 'æ¡æ–°æ¶ˆæ¯',
        'auto_scrolling': 'è‡ªåŠ¨æ»šåŠ¨',
        'uploading': 'ä¸Šä¼ ä¸­...',
        'running_input_placeholder': 'ä»»åŠ¡æ‰§è¡Œä¸­ï¼Œæ‚¨å¯ä»¥è¾“å…¥æ–°éœ€æ±‚ï¼ˆç­‰å¾…å½“å‰ä»»åŠ¡å®Œæˆåæ‰§è¡Œï¼‰...',
        'reload': 'é‡æ–°åŠ è½½',
        'save': 'ä¿å­˜',
        'type_label': 'ç±»å‹',
        'language': 'è¯­è¨€',
        'image': 'å›¾ç‰‡',
        'dimensions': 'å°ºå¯¸',
        'total_rows': 'æ€»è¡Œæ•°',
        'columns': 'åˆ—æ•°',
        'preview': 'é¢„è§ˆ',
        'office_preview_title': 'Officeæ–‡æ¡£é¢„è§ˆ',
        'office_download_instruction': 'Officeæ–‡æ¡£éœ€è¦ä¸‹è½½åˆ°æœ¬åœ°æŸ¥çœ‹ï¼š',
        'download_file': 'ä¸‹è½½æ–‡ä»¶',
        'usage_instructions': 'ä½¿ç”¨è¯´æ˜',
        'office_instruction_1': 'ç‚¹å‡»"ä¸‹è½½æ–‡ä»¶"æŒ‰é’®å°†æ–‡ä»¶ä¿å­˜åˆ°æœ¬åœ°',
        'office_instruction_2': 'ä½¿ç”¨Microsoft Officeã€WPSæˆ–å…¶ä»–å…¼å®¹è½¯ä»¶æ‰“å¼€',
        'office_instruction_3': '',
        'office_offline_note': 'ä¸ºäº†æ”¯æŒç¦»çº¿éƒ¨ç½²ï¼Œäº‘å­˜å‚¨é¢„è§ˆåŠŸèƒ½å·²è¢«ç§»é™¤ã€‚è¯·ä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°æŸ¥çœ‹ã€‚',
        'source_mode': 'æºç æ¨¡å¼',
        'preview_mode': 'é¢„è§ˆæ¨¡å¼',
        'save_markdown_title': 'ä¿å­˜å½“å‰Markdownæ–‡æœ¬',
        'save_mermaid_title': 'ä¿å­˜å½“å‰Mermaidæ–‡ä»¶',
        'toggle_to_preview_title': 'åˆ‡æ¢åˆ°é¢„è§ˆæ¨¡å¼',
        'toggle_to_source_title': 'åˆ‡æ¢åˆ°æºç æ¨¡å¼',
        
        # Mermaid conversion
        'mermaid_conversion_completed': 'Mermaidå›¾è¡¨è½¬æ¢å®Œæˆ',
        'mermaid_svg_png_format': 'ï¼ˆSVGå’ŒPNGæ ¼å¼ï¼‰',
        'mermaid_svg_only': 'ï¼ˆä»…SVGæ ¼å¼ï¼‰',
        'mermaid_png_only': 'ï¼ˆä»…PNGæ ¼å¼ï¼‰',
        
        # Configuration validation
        'config_missing': 'æ¨¡å‹é…ç½®ä¿¡æ¯ç¼ºå¤±',
        'config_incomplete': 'é…ç½®ä¿¡æ¯ä¸å®Œæ•´ï¼šç¼ºå°‘ API Keyã€API Base æˆ–æ¨¡å‹åç§°',
        'custom_label': 'è‡ªå®šä¹‰',
        'task_emitted': 'âœ… ä»»åŠ¡å·²å‘èµ·',
        'task_starting': 'ğŸš€ ä»»åŠ¡å¼€å§‹æ‰§è¡Œ...',
        
        # Directory status messages
        'no_workspace_directories': 'æš‚æ— å·¥ä½œç›®å½•ï¼ˆåŒ…å«workspaceå­ç›®å½•çš„ç›®å½•ï¼‰',
        'current_executing': 'å½“å‰æ‰§è¡Œ',
        'selected': 'å·²é€‰æ‹©',
        'last_used': 'ä¸Šæ¬¡ä½¿ç”¨',
        'expand_collapse': 'å±•å¼€/æ”¶èµ·',
        'upload_to_workspace': 'ä¸Šä¼ æ–‡ä»¶åˆ°Workspace',
        'download_as_zip': 'ä¸‹è½½ç›®å½•ä¸ºZIPï¼ˆæ’é™¤code_indexï¼‰',
        'rename_directory': 'é‡å‘½åç›®å½•',
        'delete_directory': 'åˆ é™¤ç›®å½•',
        'confirm_delete_directory': 'ç¡®å®šè¦åˆ é™¤ç›®å½•',
        'delete_warning': 'æ­¤æ“ä½œä¸å¯æ’¤é”€ï¼Œå°†æ°¸ä¹…åˆ é™¤è¯¥ç›®å½•åŠå…¶æ‰€æœ‰å†…å®¹ã€‚',
        'guest_cannot_execute': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•æ‰§è¡Œæ–°ä»»åŠ¡ã€‚',
        'guest_cannot_create': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•åˆ›å»ºæ–°ç›®å½•ã€‚',
        'guest_cannot_delete': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•åˆ é™¤ç›®å½•ã€‚',
        'guest_cannot_save': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•ä¿å­˜ã€‚',
        'guest_cannot_convert': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•è½¬æ¢å›¾è¡¨ã€‚',
        'guest_cannot_rename': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•é‡å‘½åç›®å½•ã€‚',
        'guest_cannot_upload': 'guestç”¨æˆ·ä¸ºæ¼”ç¤ºè´¦æˆ·ï¼Œæ— æ³•ä¸Šä¼ æ–‡ä»¶ã€‚',
        'select_valid_config': 'è¯·é€‰æ‹©æœ‰æ•ˆçš„æ¨¡å‹é…ç½®',
        'config_validation_failed': 'é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥',
        
        # SVG Editor buttons
        'edit_svg': 'ç¼–è¾‘',
        'ai_optimize_svg': 'AIæ¶¦è‰²',
        'restore_svg': 'æ¢å¤',
        'delete_svg': 'åˆ é™¤',
        'edit_svg_tooltip': 'ç¼–è¾‘SVGå›¾',
        'ai_optimize_svg_tooltip': 'AIæ™ºèƒ½é‡æ–°è®¾è®¡SVGå›¾',
        'restore_svg_tooltip': 'æ¢å¤åŸå›¾',
        'delete_svg_tooltip': 'åˆ é™¤SVGå›¾',
        
        # Markdown diagram reparse
        'reparse_diagrams': 'è§£æå›¾è¡¨',
        'reparse_diagrams_title': 'é‡æ–°è§£æMarkdownä¸­çš„Mermaidå›¾è¡¨å’ŒSVGä»£ç å—',
        
        # Document conversion messages
        'converting': 'è½¬æ¢ä¸­...',
        'mermaid_conversion_success': 'Mermaidå›¾è¡¨è½¬æ¢æˆåŠŸï¼',
        'conversion_failed': 'è½¬æ¢å¤±è´¥',
        'unknown_error': 'æœªçŸ¥é”™è¯¯',
        'word_conversion_success': 'Wordæ–‡æ¡£è½¬æ¢æˆåŠŸå¹¶å¼€å§‹ä¸‹è½½ï¼',
        'word_conversion_failed': 'Wordæ–‡æ¡£è½¬æ¢å¤±è´¥',
        'pdf_conversion_success': 'PDFæ–‡æ¡£è½¬æ¢æˆåŠŸå¹¶å¼€å§‹ä¸‹è½½ï¼',
        'pdf_conversion_failed': 'PDFæ–‡æ¡£è½¬æ¢å¤±è´¥',
        'latex_generation_success': 'LaTeXæºæ–‡ä»¶ç”ŸæˆæˆåŠŸå¹¶å¼€å§‹ä¸‹è½½ï¼',
        'latex_generation_failed': 'LaTeXæºæ–‡ä»¶ç”Ÿæˆå¤±è´¥',
        'generation_failed': 'ç”Ÿæˆå¤±è´¥',
        'file_label': 'æ–‡ä»¶',
        'size_label': 'å¤§å°',
        'svg_file': 'SVGæ–‡ä»¶',
        'png_file': 'PNGæ–‡ä»¶',
        
        # Dialog messages
        'confirm_delete_svg': 'ç¡®å®šè¦åˆ é™¤è¿™ä¸ªSVGå›¾å—ï¼Ÿ',
        'confirm_delete_image': 'ç¡®å®šè¦åˆ é™¤è¿™å¼ å›¾ç‰‡å—ï¼Ÿ',
        'delete_image_failed': 'åˆ é™¤å›¾ç‰‡å¤±è´¥',
        'no_markdown_to_save': 'æœªæ£€æµ‹åˆ°å¯ä¿å­˜çš„Markdownå†…å®¹',
        'cannot_determine_file_path': 'æ— æ³•ç¡®å®šå½“å‰Markdownæ–‡ä»¶è·¯å¾„',
        'confirm_delete_elements': 'ç¡®å®šè¦åˆ é™¤é€‰ä¸­çš„ {count} ä¸ªå…ƒç´ å—ï¼Ÿæ­¤æ“ä½œæ— æ³•æ’¤é”€ã€‚',
        'confirm_delete_elements_en': 'Are you sure you want to delete the selected {count} elements? This action cannot be undone.',
        
        # Console log messages (for debugging, but should be consistent)
        'edit_svg_file': 'ç¼–è¾‘SVGæ–‡ä»¶',
        'delete_image': 'åˆ é™¤å›¾ç‰‡',
        'image_deleted_auto_save': 'å›¾ç‰‡åˆ é™¤åå·²è‡ªåŠ¨ä¿å­˜markdownæ–‡ä»¶',
        'image_switched_auto_save': 'å›¾ç‰‡åˆ‡æ¢åå·²è‡ªåŠ¨ä¿å­˜markdownæ–‡ä»¶',
        'svg_deleted_auto_save': 'SVGåˆ é™¤åå·²è‡ªåŠ¨ä¿å­˜markdownæ–‡ä»¶',
        'auto_save_error': 'è‡ªåŠ¨ä¿å­˜æ—¶å‡ºé”™',
        'guest_skip_auto_save': 'Guestç”¨æˆ·è·³è¿‡è‡ªåŠ¨ä¿å­˜',
        'no_markdown_auto_save': 'æ— Markdownå†…å®¹å¯è‡ªåŠ¨ä¿å­˜',
        'cannot_determine_path_auto_save': 'æ— æ³•ç¡®å®šMarkdownæ–‡ä»¶è·¯å¾„ï¼Œè·³è¿‡è‡ªåŠ¨ä¿å­˜',
        'markdown_auto_saved': 'Markdownå·²è‡ªåŠ¨ä¿å­˜',
        'auto_save_failed': 'è‡ªåŠ¨ä¿å­˜å¤±è´¥',
        'auto_save_markdown_failed': 'è‡ªåŠ¨ä¿å­˜Markdownå¤±è´¥',
        
        # Additional error messages
        'cannot_get_svg_path': 'æ— æ³•è·å–SVGæ–‡ä»¶è·¯å¾„',
        'cannot_get_image_path': 'æ— æ³•è·å–å›¾ç‰‡æ–‡ä»¶è·¯å¾„',
        'cannot_get_file_path': 'æ— æ³•è·å–æ–‡ä»¶è·¯å¾„',
        'cannot_get_current_file_path': 'æ— æ³•è·å–å½“å‰æ–‡ä»¶è·¯å¾„',
        'cannot_determine_mermaid_path': 'æ— æ³•ç¡®å®šå½“å‰Mermaidæ–‡ä»¶è·¯å¾„',
        'cannot_determine_markdown_path': 'æ— æ³•ç¡®å®šå½“å‰Markdownæ–‡ä»¶è·¯å¾„',
        'delete_svg_failed': 'åˆ é™¤SVGå¤±è´¥',
        'conversion_request_failed': 'è½¬æ¢è¯·æ±‚å¤±è´¥',
        'conversion_error': 'è½¬æ¢é”™è¯¯',
        'error_during_conversion': 'è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯',
        'generation_error': 'ç”Ÿæˆé”™è¯¯',
        'error_during_generation': 'ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯',
    },
    'en': {
        # Page title and basic info
        'page_title': f'{APP_NAME}',
        'app_title': f'{APP_NAME}', 
        'app_subtitle': '',
        'connected': f'Connected to {APP_NAME}',
        
        # Button text
        'execute_direct': 'Execute',
        'execute_plan': 'Plan Mode',
        'new_directory': 'New Directory', 
        'stop_task': 'Stop Task',
        'refresh': 'Refresh',
        'upload': 'Upload',
        'download': 'Download',
        'rename': 'Rename',
        'delete': 'Delete',
        'confirm': 'Confirm',
        'cancel': 'Cancel',
        'clear_chat': 'Clean',
        
        # Button tooltips
        'direct_tooltip': 'Direct execution - no task decomposition',
        'plan_tooltip': 'Plan mode - decompose tasks before execution',
        'new_tooltip': 'New directory - create new workspace',
        'refresh_tooltip': 'Refresh directory list',
        'upload_tooltip': 'Upload files to Workspace',
        'download_tooltip': 'Download directory as ZIP (excluding code_index)',
        'rename_tooltip': 'Rename directory',
        'delete_tooltip': 'Delete directory',
        'clear_chat_tooltip': 'Clear chat log and conversation history',
        
        # Input and placeholders
        'input_placeholder': 'Enter your requirements...',
        'rename_placeholder': 'Enter new directory name',
        
        # Modal titles
        'upload_title': 'Upload Files to Workspace',
        'rename_title': 'Rename Directory',
        'confirm_rename': 'Confirm Rename',
        
        # Status messages
        'task_running': 'Task is running...',
        'no_task_running': 'No task is currently running',
        'task_stopped': 'Task stopped by user',
        'task_completed': 'Task completed successfully!',
        'task_completed_with_errors': 'Task reached maximum rounds, may not be fully completed',
        'task_failed': 'Task execution failed',
        'creating_directory': 'Creating new workspace directory...',
        'directory_created': 'New workspace directory created',
        'directory_selected': 'Directory selected',
        'directory_renamed': 'Directory renamed successfully',
        'directory_deleted': 'Directory deleted successfully',
        'files_uploaded': 'Files uploaded successfully',
        'refresh_success': 'Directory list refreshed',
        'chat_cleared': 'Chat log and conversation history cleared',
        'confirm_clear_chat': 'Are you sure you want to clear all chat logs and conversation history? This operation cannot be undone.',
        
        # Mode info
        'direct_mode_info': 'âš¡ Direct execution mode: No task decomposition',
        'new_mode_info': 'New directory mode - Click green button to create new workspace, or select existing directory',
        'selected_dir_info': 'Selected directory',
        
        # Error messages
        'error_no_requirement': 'Please provide a valid requirement',
        'error_task_running': 'A task is already running',
        'error_no_directory': 'Please select a directory first',
        'error_no_files': 'Please select files first',
        'error_delete_confirm': 'Are you sure you want to delete directory',
        'error_delete_warning': 'This operation cannot be undone and will permanently delete the directory and all its contents.',
        'error_rename_empty': 'New name cannot be empty',
        'error_rename_same': 'New name is the same as original or contains invalid characters',
        'error_directory_exists': 'Target directory already exists',
        'error_directory_not_found': 'Directory not found',
        'error_permission_denied': 'Permission denied',
        'error_file_too_large': 'File too large to display',
        'error_file_not_supported': 'File type not supported for preview',
        
        # PDF preview
        'pdf_pages': 'Total {pages} pages',
        'pdf_pages_simple': 'Total {pages} pages (Simple mode)',
        'download_pdf': 'Download PDF',
        'pdf_loading': 'Loading all pages...',
        'pdf_render_error': 'PDF page rendering failed',
        
        # Delete warnings
        'delete_current_executing_warning': 'âš ï¸ Warning: This is the currently executing directory!',
        'delete_selected_warning': 'âš ï¸ Warning: This is the currently selected directory!',
        
        # File operations
        'file_size': 'File Size',
        'download_file': 'Download File',
        'office_preview_note': 'Office Document Preview',
        'office_download_note': 'Download File: Download to local and open with Office software',
        'drag_unselected_dir_warning': 'Please select this workspace directory first before dragging',
        
        # Tool execution status
        'tool_running': 'Running',
        'tool_success': 'Success',
        'tool_error': 'Error',
        'function_calling': 'Calling',
        'tool_call': 'Tool Call',
        'json_output': 'JSON Output',
        'image': 'Image',
        'dimensions': 'Dimensions',
        'total_rows': 'Total Rows',
        'columns': 'Columns',
        
        # Configuration options
        'config_options': 'Configuration Options',
        'show_config_options': 'Show Configuration',
        'hide_config_options': 'Hide Configuration',
        'routine_file': 'Task Type',
        'task_type': 'Mode Selection',
        'no_routine': 'Please select...',
        'enable_web_search': 'Web Search',
        'enable_multi_agent': 'Multi-Agent',
        'enable_long_term_memory': 'Long-term Memory',
        'enable_mcp': 'Enable MCP',
        'enable_jieba': 'Chinese Segmentation',
        'execution_mode': 'Execution Mode',
        'agent_mode': 'Agent Mode',
        'plan_mode': 'Plan Mode',
        'user_input_request': 'User Input Request',
        'enter_your_response': 'Enter your response...',
        'submit': 'Submit',
        'append_task': 'Append Task',
        'append_task_empty': 'Please enter task content to append',
        'append_task_success': 'Task successfully sent to agent',
        'append_task_sent': 'Task appended to inbox',
        
        # Others
        'deleting': 'Deleting...',
        'renaming': 'Renaming...',
        'uploading': 'Uploading...',
        'edit_mermaid_placeholder': 'Edit Mermaid content...',
        'convert_to_images': 'Convert Mermaid to PNG and SVG images',
        'convert_to_images_short': 'Convert to Images',
        'loading': 'Loading...',
        'system_message': 'System Message',
        'welcome_message': f'Welcome to {APP_NAME}! Please enter your requirements below, and the system will automatically process tasks for you.',
        'workspace_title': 'Workspace',
        'file_preview': 'File Preview',
        'data_directory_info': 'Data Directory',
        'disconnected': 'Disconnected from server',
        'drag_files': 'Drag files here or click to select files',
        'upload_hint': 'Supports multiple file upload, files will be saved to the workspace folder of the selected directory',
        'select_files': 'Select Files',
        
        # Additional bilingual text
        'new_messages': 'new messages',
        'auto_scroll': 'Auto Scroll',
        'scroll_to_bottom': 'Scroll to Bottom',
        'continue_mode_info': 'Continue mode - Will use the previous workspace directory',
        'create_or_select_directory': 'Please click the green button to create a new workspace directory, or select an existing directory on the right',
        'select_directory_first': 'Please create or select a workspace directory, then click a folder in the workspace list until it turns blue to confirm the selection',
        'current_name': 'Current Name:',
        'new_name': 'New Name:',
        'rename_info': 'The name you enter will be used as the directory name',
        'paused': 'Paused',
        'load_directory_failed': 'Failed to load directories',
        'network_error': 'Network error',
        'upload_network_error': 'Network error, upload failed',
        'rename_failed': 'Rename failed',
        'rename_error': 'Rename error',
        'refresh_failed': 'Refresh failed',
        'please_connect': 'Please connect to server first',
        'attempt': 'attempt',
        'create_directory_failed': 'Failed to create directory',
        'preview': 'Preview',
        'page_info': 'Page {0} of {1}',
        'upload_to': 'Upload files to',
        'workspace': '/workspace',
        'select_directory_error': 'Please select a directory first',
        'uploading_files': 'Uploading {0} files',
        'upload_progress': 'Upload progress: {0}%',
        'upload_completed': 'Upload completed',
        'upload_failed_http': 'Upload failed: HTTP {0}',
        
        # Directory operations
        'directory_created_with_workspace': 'New workspace directory created: {0} (with workspace subdirectory)',
        'directory_list_refreshed': 'Directory list refreshed',
        'no_files_selected': 'No files selected',
        'no_valid_files': 'No valid files selected',
        'target_directory_not_exist': 'Target directory does not exist',
        'upload_success': 'Successfully uploaded {0} files',
        'new_name_empty': 'New name cannot be empty',
        
        # Multi-user support
        'api_key_label': 'API Key:',
        'api_key_placeholder': 'Enter API Key (optional)',
        'api_key_tooltip': 'Enter your API Key, leave empty for default user mode',
        'connect_btn': 'Connect',
        'disconnect_btn': 'Disconnect',
        'connecting': 'Connecting...',
        'user_connected': 'Connected',
        'user_disconnected': 'Disconnected',
        'user_connection_failed': 'Connection Failed',
        'connection_error': 'Connection error',
        'reconnecting': 'Attempting to reconnect...',
        'reconnect_attempt': 'Attempting to reconnect',
        'reconnect_success': 'Reconnected to server',
        'reconnect_failed_cleanup': 'Auto reconnection failed. Workspace has been cleared, please reconnect.',
        'reconnect_error': 'Auto reconnection error',
        'default_user': 'Default User',
        'user_prefix': 'User',
        'guest_user': 'Guest User',
        'temporary_connection': 'Temporary Connection',
        'auto_login_from_url': 'Auto-logged in via URL parameter',
        'session_restored': 'Previous login session restored',
        
        # Model selection
        'model_label': 'Model:',
        'model_tooltip': 'Select AI model to use',
        'model_claude_sonnet': 'claude-sonnet-4-0 (High Accuracy)',
        'model_gpt_4': 'gpt-4.1 (High Efficiency)',
        'config_error_title': 'Configuration Error',
        'config_error_invalid_key': 'Invalid API Key configuration, please check GUI API configuration in config/config.txt',
        
        # Custom model config dialog
        'custom_config_title': 'Custom Model Configuration',
        'custom_api_key_label': 'API Key:',
        'custom_api_base_label': 'API Base URL:',
        'custom_model_label': 'Model Name:',
        'custom_max_tokens_label': 'Max Output Tokens:',
        'custom_api_key_placeholder': 'Enter API Key',
        'custom_api_base_placeholder': 'Enter API Base URL (e.g., https://api.example.com/v1)',
        'custom_model_placeholder': 'Enter model name (e.g., gpt-4)',
        'custom_max_tokens_placeholder': 'Enter max output tokens (default: 8192)',
        'custom_config_save': 'Save Configuration',
        'custom_config_cancel': 'Cancel',
        'custom_config_required': 'All fields are required',
        'save_to_config_confirm': 'Already configured for temporary setting. Would you like to save this configuration to config/config.txt as a long-term configuration?\n\nThis will update the default model settings in the config file.',
        'save_to_config_success': 'Configuration successfully saved to config.txt',
        'save_to_config_failed': 'Failed to save to config.txt',
        'save_to_config_error': 'An error occurred while saving to config.txt',
        
        # Additional UI elements
        'new_messages': 'new messages',
        'auto_scrolling': 'Auto Scroll',
        'uploading': 'Uploading...',
        'running_input_placeholder': 'Task is running. You can type a new request (will execute after current task)...',
        'reload': 'Reload',
        'save': 'Save',
        'type_label': 'Type',
        'language': 'Language',
        'image': 'Image',
        'dimensions': 'Dimensions',
        'total_rows': 'Total Rows',
        'columns': 'Columns',
        'preview': 'Preview',
        'office_preview_title': 'Office Document Preview',
        'office_download_instruction': 'Office documents need to be downloaded for local viewing:',
        'download_file': 'Download File',
        'usage_instructions': 'Usage Instructions',
        'office_instruction_1': 'Click the "Download File" button to save the file locally',
        'office_instruction_2': 'Open with Microsoft Office, WPS, or other compatible software',
        'office_instruction_3': '',
        'office_offline_note': 'To support offline deployment, cloud storage preview functionality has been removed. Please download files for local viewing.',
        'source_mode': 'Source Mode',
        'preview_mode': 'Preview Mode',
        'save_markdown_title': 'Save current Markdown text',
        'save_mermaid_title': 'Save current Mermaid file',
        'toggle_to_preview_title': 'Switch to preview mode',
        'toggle_to_source_title': 'Switch to source mode',
        
        # Mermaid conversion
        'mermaid_conversion_completed': 'Mermaid chart conversion completed',
        'mermaid_svg_png_format': ' (SVG and PNG formats)',
        'mermaid_svg_only': ' (SVG format only)',
        'mermaid_png_only': ' (PNG format only)',
        
        # Configuration validation
        'config_missing': 'Model configuration information missing',
        'config_incomplete': 'Incomplete configuration: missing API Key, API Base, or model name',
        'custom_label': 'Custom',
        'task_emitted': 'âœ… Task Emitted',
        'task_starting': 'ğŸš€ Task starting...',
        
        # Directory status messages
        'no_workspace_directories': 'No workspace directories (directories containing workspace subdirectories)',
        'current_executing': 'Currently Executing',
        'selected': 'Selected',
        'last_used': 'Last Used',
        'expand_collapse': 'Expand/Collapse',
        'upload_to_workspace': 'Upload Files to Workspace',
        'download_as_zip': 'Download Directory as ZIP (excluding code_index)',
        'rename_directory': 'Rename Directory',
        'delete_directory': 'Delete Directory',
        'confirm_delete_directory': 'Are you sure you want to delete directory',
        'delete_warning': 'This operation cannot be undone and will permanently delete the directory and all its contents.',
        'guest_cannot_execute': 'Guest user is a demo account and cannot execute new tasks.',
        'guest_cannot_create': 'Guest user is a demo account and cannot create new directories.',
        'guest_cannot_delete': 'Guest user is a demo account and cannot delete directories.',
        'guest_cannot_save': 'Guest user is a demo account and cannot save.',
        'guest_cannot_convert': 'Guest user is a demo account and cannot convert charts.',
        'guest_cannot_rename': 'Guest user is a demo account and cannot rename directories.',
        'guest_cannot_upload': 'Guest user is a demo account and cannot upload files.',
        'select_valid_config': 'Please select a valid model configuration',
        'config_validation_failed': 'Configuration validation failed, please check network connection',
        
        # SVG Editor buttons
        'edit_svg': 'Edit',
        'ai_optimize_svg': 'AI Polish',
        'restore_svg': 'Restore',
        'delete_svg': 'Delete',
        'edit_svg_tooltip': 'Edit SVG image',
        'ai_optimize_svg_tooltip': 'AI intelligent redesign SVG image',
        'restore_svg_tooltip': 'Restore original image',
        'delete_svg_tooltip': 'Delete SVG image',
        
        # Markdown diagram reparse
        'reparse_diagrams': 'Parse Diagrams',
        'reparse_diagrams_title': 'Reparse Mermaid charts and SVG code blocks in Markdown',
        
        # Document conversion messages
        'converting': 'Converting...',
        'mermaid_conversion_success': 'Mermaid chart conversion successful!',
        'conversion_failed': 'Conversion failed',
        'unknown_error': 'Unknown error',
        'word_conversion_success': 'Word document conversion successful and download started!',
        'word_conversion_failed': 'Word document conversion failed',
        'pdf_conversion_success': 'PDF document conversion successful and download started!',
        'pdf_conversion_failed': 'PDF document conversion failed',
        'latex_generation_success': 'LaTeX source file generation successful and download started!',
        'latex_generation_failed': 'LaTeX source file generation failed',
        'generation_failed': 'Generation failed',
        'file_label': 'File',
        'size_label': 'Size',
        'svg_file': 'SVG file',
        'png_file': 'PNG file',
        
        # Dialog messages
        'confirm_delete_svg': 'Are you sure you want to delete this SVG image?',
        'confirm_delete_image': 'Are you sure you want to delete this image?',
        'delete_image_failed': 'Failed to delete image',
        'no_markdown_to_save': 'No Markdown content detected to save',
        'cannot_determine_file_path': 'Cannot determine current Markdown file path',
        'confirm_delete_elements': 'Are you sure you want to delete the selected {count} elements? This action cannot be undone.',
        'confirm_delete_elements_en': 'Are you sure you want to delete the selected {count} elements? This action cannot be undone.',
        
        # Console log messages (for debugging, but should be consistent)
        'edit_svg_file': 'Edit SVG file',
        'delete_image': 'Delete image',
        'image_deleted_auto_save': 'Markdown file auto-saved after image deletion',
        'image_switched_auto_save': 'Markdown file auto-saved after image switch',
        'svg_deleted_auto_save': 'Markdown file auto-saved after SVG deletion',
        'auto_save_error': 'Auto-save error',
        'guest_skip_auto_save': 'Guest user skips auto-save',
        'no_markdown_auto_save': 'No Markdown content to auto-save',
        'cannot_determine_path_auto_save': 'Cannot determine Markdown file path, skip auto-save',
        'markdown_auto_saved': 'Markdown auto-saved',
        'auto_save_failed': 'Auto-save failed',
        'auto_save_markdown_failed': 'Auto-save Markdown failed',
        
        # Additional error messages
        'cannot_get_svg_path': 'Cannot get SVG file path',
        'cannot_get_image_path': 'Cannot get image file path',
        'cannot_get_file_path': 'Cannot get file path',
        'cannot_get_current_file_path': 'Cannot get current file path',
        'cannot_determine_mermaid_path': 'Cannot determine current Mermaid file path',
        'cannot_determine_markdown_path': 'Cannot determine current Markdown file path',
        'delete_svg_failed': 'Failed to delete SVG',
        'conversion_request_failed': 'Conversion request failed',
        'conversion_error': 'Conversion error',
        'error_during_conversion': 'Error occurred during conversion',
        'generation_error': 'Generation error',
        'error_during_generation': 'Error occurred during generation',
    }
}

def get_i18n_texts():
    """Get internationalization text for current language"""
    current_lang = get_language()
    return I18N_TEXTS.get(current_lang, I18N_TEXTS['en'])

def execute_agia_task_process_target(user_requirement, output_queue, input_queue, out_dir=None, continue_mode=False, plan_mode=False, gui_config=None, session_id=None, detailed_requirement=None, user_id=None, attached_files=None):
    """
    This function runs in a separate process.
    It cannot use the `socketio` object directly.
    It communicates back to the main process via the queue.
    User input is received via input_queue in GUI mode.
    """
    # Store input_queue in a way that talk_to_user can access it
    import sys
    import __main__
    __main__._agia_gui_input_queue = input_queue
    
    try:

        # Get i18n texts for this process (after sending initial message)
        i18n = get_i18n_texts()
        
        if not out_dir:
            # Get GUI default data directory from config for new directories
            from src.config_loader import get_gui_default_data_directory
            config_data_dir = get_gui_default_data_directory()
            if config_data_dir:
                base_dir = config_data_dir
            else:
                base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            out_dir = os.path.join(base_dir, f"output_{timestamp}")
        
        # Process GUI configuration options
        if gui_config is None:
            gui_config = {}
        
        # Set default values based on user requirements
        enable_web_search = gui_config.get('enable_web_search', True)
        enable_multi_agent = gui_config.get('enable_multi_agent', False)
        enable_long_term_memory = gui_config.get('enable_long_term_memory', True)  # Default selection
        enable_mcp = gui_config.get('enable_mcp', False)
        enable_jieba = gui_config.get('enable_jieba', True)  # Default selection
        
        # Execution rounds configuration from GUI
        execution_rounds = gui_config.get('execution_rounds', 50)  # Default to 50 if not provided
        
        # Routine file configuration from GUI
        routine_file = gui_config.get('routine_file')
        if routine_file:
            # æ£€æŸ¥æ˜¯å¦æ˜¯workspaceæ–‡ä»¶ï¼ˆä»¥routine_å¼€å¤´ï¼‰
            if routine_file.startswith('routine_'):
                # ç›´æ¥ä½¿ç”¨workspaceæ ¹ç›®å½•ä¸‹çš„æ–‡ä»¶
                routine_file = os.path.join(os.getcwd(), routine_file)
            else:
                # æ ¹æ®è¯­è¨€é…ç½®é€‰æ‹©routineæ–‡ä»¶å¤¹
                current_lang = get_language()
                if current_lang == 'zh':
                    routine_file = os.path.join(os.getcwd(), 'routine_zh', routine_file)
                else:
                    routine_file = os.path.join(os.getcwd(), 'routine', routine_file)
            
            if not os.path.exists(routine_file):
                output_queue.put({'event': 'output', 'data': {'message': f"Warning: Routine file not found: {routine_file}", 'type': 'warning'}})
                routine_file = None

        # Model configuration from GUI
        selected_model = gui_config.get('selected_model')
        model_api_key = gui_config.get('model_api_key')
        model_api_base = gui_config.get('model_api_base')
        
        # å¦‚æœå‰ç«¯æ²¡æœ‰æä¾› api_key å’Œ api_baseï¼ˆå†…ç½®é…ç½®ï¼‰ï¼Œä»æœåŠ¡å™¨ç«¯è¯»å–
        # å¯¹äºå†…ç½®é…ç½®ï¼Œå‰ç«¯ä¸ä¼šå‘é€ api_key å’Œ api_baseï¼Œéœ€è¦ä»æœåŠ¡å™¨ç«¯è¯»å–
        if not model_api_key or not model_api_base:
            from src.config_loader import get_gui_config
            gui_config_from_server = get_gui_config()
            
            # å¦‚æœæœåŠ¡å™¨ç«¯æœ‰é…ç½®ï¼Œå°±ä½¿ç”¨å®ƒ
            if gui_config_from_server.get('api_key') and gui_config_from_server.get('api_base'):
                if not model_api_key:
                    model_api_key = gui_config_from_server.get('api_key')
                if not model_api_base:
                    model_api_base = gui_config_from_server.get('api_base')
                # å¦‚æœ selected_model ä¸ºç©ºã€Noneã€ç©ºå­—ç¬¦ä¸²æˆ–ä¸ºé»˜è®¤å€¼ï¼Œä½¿ç”¨æœåŠ¡å™¨ç«¯çš„æ¨¡å‹åç§°
                if not selected_model or selected_model == '' or selected_model == 'claude-sonnet-4':
                    selected_model = gui_config_from_server.get('model', selected_model or 'claude-sonnet-4')
        
        # éªŒè¯é…ç½®æ˜¯å¦å®Œæ•´
        if not model_api_key or not model_api_base or not selected_model:
            missing_items = []
            if not model_api_key:
                missing_items.append('API Key')
            if not model_api_base:
                missing_items.append('API Base')
            if not selected_model:
                missing_items.append('æ¨¡å‹åç§°')
            error_msg = f"é…ç½®ä¿¡æ¯ä¸å®Œæ•´ï¼šç¼ºå°‘ {', '.join(missing_items)}ã€‚è¯·æ£€æŸ¥ config/config.txt ä¸­çš„ GUI API é…ç½®éƒ¨åˆ†ã€‚"
            output_queue.put({'event': 'error', 'data': {'message': error_msg}})
            return
        
        # Create a temporary configuration that overrides config.txt for GUI mode
        # We'll use environment variables to pass these settings to the AGIAgent system
        original_env = {}
        
        # Model configuration: GUI setting overrides config.txt
        if model_api_key:
            original_env['AGIBOT_API_KEY'] = os.environ.get('AGIBOT_API_KEY', '')
            os.environ['AGIBOT_API_KEY'] = model_api_key
        if model_api_base:
            original_env['AGIBOT_API_BASE'] = os.environ.get('AGIBOT_API_BASE', '')
            os.environ['AGIBOT_API_BASE'] = model_api_base
        if selected_model:
            original_env['AGIBOT_MODEL'] = os.environ.get('AGIBOT_MODEL', '')
            os.environ['AGIBOT_MODEL'] = selected_model
        
        # Web search: only set if GUI enables it
        if enable_web_search:
            original_env['AGIBOT_WEB_SEARCH'] = os.environ.get('AGIBOT_WEB_SEARCH', '')
            os.environ['AGIBOT_WEB_SEARCH'] = 'true'
        
        # Multi-agent: GUI setting overrides config.txt (set environment variable explicitly)
        original_env['AGIBOT_MULTI_AGENT'] = os.environ.get('AGIBOT_MULTI_AGENT', '')
        if enable_multi_agent:
            os.environ['AGIBOT_MULTI_AGENT'] = 'true'
        else:
            os.environ['AGIBOT_MULTI_AGENT'] = 'false'
        
        # Jieba: GUI setting overrides config.txt (set environment variable explicitly)
        original_env['AGIBOT_ENABLE_JIEBA'] = os.environ.get('AGIBOT_ENABLE_JIEBA', '')
        if enable_jieba:
            os.environ['AGIBOT_ENABLE_JIEBA'] = 'true'
        else:
            os.environ['AGIBOT_ENABLE_JIEBA'] = 'false'
        
        # Long-term memory: GUI setting overrides config.txt (set environment variable explicitly)
        original_env['AGIBOT_LONG_TERM_MEMORY'] = os.environ.get('AGIBOT_LONG_TERM_MEMORY', '')
        if enable_long_term_memory:
            os.environ['AGIBOT_LONG_TERM_MEMORY'] = 'true'
        else:
            os.environ['AGIBOT_LONG_TERM_MEMORY'] = 'false'
        
        # Set parameters based on mode
        # In plan mode, we still use single_task_mode=True, but plan_mode will be handled separately in run()
        single_task_mode = True   # Default mode executes directly
        
        # Determine MCP config file based on GUI setting
        mcp_config_file = None
        if enable_mcp:
            # Get selected MCP servers from GUI config
            selected_mcp_servers = gui_config.get('selected_mcp_servers', [])

            if selected_mcp_servers:
                # Generate custom MCP config file based on selected servers
                mcp_config_file = generate_custom_mcp_config(selected_mcp_servers, out_dir)
            else:
                # Use default MCP config if no servers selected
                mcp_config_file = "config/mcp_servers.json"
        
        # Set environment variable for GUI mode detection
        os.environ['AGIA_GUI_MODE'] = 'true'
        
        agia = AGIAgentMain(
            out_dir=out_dir,
            debug_mode=False,
            detailed_summary=True,
            single_task_mode=single_task_mode,  # Set based on plan_mode
            interactive_mode=False,  # Disable interactive mode
            continue_mode=False,  # Always use False for GUI mode to avoid shared .agia_last_output.json
            MCP_config_file=mcp_config_file,  # Set based on GUI MCP option
            user_id=user_id,  # Pass user ID for MCP knowledge base tools
            routine_file=routine_file,  # Pass routine file to main application
            plan_mode=plan_mode  # Pass plan_mode to AGIAgentMain
        )
        
        # Use detailed_requirement if provided (contains conversation history)
        base_requirement = detailed_requirement if detailed_requirement else user_requirement
        
        # Process attached files - add file path references instead of content
        if attached_files:
            file_references = []
            for file_info in attached_files:
                file_path = file_info.get('path', '')
                file_name = file_info.get('name', '')
                reference = file_info.get('reference', '')
                if file_path and file_name:
                    file_references.append(f"\n\n--- æ–‡ä»¶å¼•ç”¨: {file_name} ---\næ–‡ä»¶è·¯å¾„: {file_path}\n--- æ–‡ä»¶å¼•ç”¨ç»“æŸ: {file_name} ---\n")
            
            if file_references:
                base_requirement = base_requirement + ''.join(file_references)
        
        # Helper function to format file size
        def format_size(size_bytes):
            """Format file size"""
            if size_bytes == 0:
                return "0 B"
            size_names = ["B", "KB", "MB", "GB", "TB"]
            i = 0
            while size_bytes >= 1024.0 and i < len(size_names) - 1:
                size_bytes /= 1024.0
                i += 1
            return f"{size_bytes:.1f} {size_names[i]}"
        
        # Add workspace path information to the prompt
        workspace_info = ""
        if out_dir:
            # Display user-selected directory path
            workspace_info = f"\n\nCurrently selected directory: {out_dir}"
            
            # Check workspace subdirectory
            workspace_dir = os.path.join(out_dir, "workspace")
            if os.path.exists(workspace_dir):
                workspace_info += f"\nworkspace subdirectory path: {workspace_dir}\nworkspace subdirectory content:"
                try:
                    # List workspace contents for context (limit to first 50 files for performance)
                    workspace_files = []
                    md_files = []
                    max_files = 50  # Limit to avoid long delays with large directories
                    file_count = 0
                    
                    for root, dirs, files in os.walk(workspace_dir):
                        # Skip hidden directories and common large directories
                        dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', '__pycache__', 'venv', '.git']]
                        
                        for file in files:
                            if file_count >= max_files:
                                break
                            
                            file_path = os.path.join(root, file)
                            rel_path = os.path.relpath(file_path, workspace_dir)
                            file_size = os.path.getsize(file_path)
                            
                            if file.endswith('.md'):
                                md_files.append(f"  - {rel_path} ({format_size(file_size)})")
                            else:
                                workspace_files.append(f"  - {rel_path} ({format_size(file_size)})")
                            
                            file_count += 1
                        
                        if file_count >= max_files:
                            break
                    
                    # Prioritize displaying MD files
                    if md_files:
                        workspace_info += "\nMD files:"
                        workspace_info += "\n" + "\n".join(md_files)
                    
                    if workspace_files:
                        workspace_info += "\nOther files:"
                        workspace_info += "\n" + "\n".join(workspace_files)
                    
                    if file_count >= max_files:
                        workspace_info += f"\n  ... (showing first {max_files} files, more files exist)"
                    
                    if not md_files and not workspace_files:
                        workspace_info += "\n  (Empty directory)"
                        
                except Exception as e:
                    workspace_info += f"\n  (Cannot read directory content: {str(e)})"
            else:
                workspace_info += f"\nNote: workspace subdirectory does not exist"
        
        # Add search configuration hints to the prompt based on GUI settings
        search_hints = []
        if not enable_web_search:
            search_hints.append("[Don't search network]")
        
        # Combine base requirement with workspace info and search hints
        requirement_parts = []
        if search_hints:
            requirement_parts.append(' '.join(search_hints))
        requirement_parts.append(base_requirement)
        if workspace_info:
            requirement_parts.append(workspace_info)
        
        final_requirement = ' '.join(requirement_parts)
        
        # Send user requirement as separate message
        output_queue.put({'event': 'output', 'data': {'message': f"User requirement: {user_requirement}", 'type': 'user'}})
        
        class QueueSocketHandler:
            def __init__(self, q, socket_type='info'):
                self.q = q
                self.socket_type = socket_type
                self.buffer = ""
                # ä¿å­˜åŸå§‹çš„stderrå¼•ç”¨ï¼Œç”¨äºè°ƒè¯•è¾“å‡ºï¼ˆé¿å…é€’å½’ï¼‰
                self._original_stderr = sys.__stderr__
            
            def filter_code_edit_content(self, line):
                """Filter code_edit content in tool execution parameters for GUI display"""
                # Check if line contains Parameters with code_edit field
                if "Parameters:" in line and "'code_edit':" in line:
                    # Find the start of code_edit content
                    code_edit_start = line.find("'code_edit': '")
                    if code_edit_start != -1:
                        # Find the position after 'code_edit': '
                        content_start = code_edit_start + len("'code_edit': '")
                        
                        # Find the next ', which should end the code_edit field
                        # We need to be careful about escaped quotes
                        content_end = content_start
                        quote_count = 0
                        while content_end < len(line):
                            if line[content_end] == "'":
                                # Check if it's escaped
                                if content_end > 0 and line[content_end-1] != "\\":
                                    quote_count += 1
                                    if quote_count == 1:  # Found the closing quote
                                        break
                            content_end += 1
                        
                        if content_end < len(line):
                            # Extract the content between quotes
                            content = line[content_start:content_end]
                            
                            # If content is longer than 10 characters, truncate it
                            if len(content) > 10:
                                truncated_content = content[:10] + "..."
                                filtered_line = line[:content_start] + truncated_content + line[content_end:]
                                return filtered_line
                
                return line
            
            def should_filter_message(self, line):
                """Filter out redundant system messages that are already displayed in GUI"""
                # IMPORTANT: Don't filter GUI_USER_INPUT_REQUEST, QUERY, and TIMEOUT messages here!
                # These messages need to enter the queue so queue_reader_thread can detect them.
                # They will be filtered later in queue_reader_thread before emitting to frontend.
                # if 'ğŸ”” GUI_USER_INPUT_REQUEST' in line or line.startswith('QUERY: ') or line.startswith('TIMEOUT: '):
                #     return True
                
                # Don't filter error messages, warnings, or important notifications
                line_lower = line.lower()
                if any(keyword in line_lower for keyword in ['error', 'warning', 'failed', 'exception', 'traceback']):
                    return False
                
                # List of message patterns to filter out (only redundant status messages)
                filter_patterns = [
                    "Received user requirement:",
                    "Currently selected directory:",
                    "workspace subdirectory path:",
                    "workspace subdirectory content:",
                    "Note: workspace subdirectory does not exist",
                    "With conversation context included",
                    "(Empty directory)",
                    "(Cannot read directory content:",
                    "MD files:",
                    "Other files:"
                ]
                
                # Check if line matches any filter pattern
                for pattern in filter_patterns:
                    if pattern in line:
                        return True
                
                # Filter file list items that start with "  - " but only if they look like file paths
                if line.strip().startswith("- ") and ("(" in line and ")" in line):
                    return True
                
                # Also filter empty lines and lines with only whitespace/special chars
                if not line.strip() or line.strip() in ['', '---', '===', '***']:
                    return True
                    
                return False
            
            def write(self, message):
                self.buffer += message
                
                # Check if buffer contains \r (carriage return) indicating progress bar update
                has_carriage_return = '\r' in self.buffer
                
                if '\n' in self.buffer:
                    *lines, self.buffer = self.buffer.split('\n')
                    for line in lines:
                        if line.strip():
                            # Filter code_edit content for GUI display (preserve leading spaces)
                            line_rstrip = line.rstrip()  # Only remove trailing spaces, preserve leading spaces
                            filtered_line = self.filter_code_edit_content(line_rstrip)
                            
                            # Filter out redundant system messages that are already displayed in GUI
                            if self.should_filter_message(filtered_line):
                                continue
                            
                            # Check if it's warning or progress info, if so display as normal info instead of error
                            line_lower = filtered_line.lower()
                            if ('warning' in line_lower or
                                'progress' in line_lower or
                                'processing files' in line_lower or
                                filtered_line.startswith('Processing files:') or
                                'userwarning' in line_lower or
                                'warnings.warn' in line_lower or
                                'âš ï¸' in filtered_line or  # ä¸­æ–‡è­¦å‘Šç¬¦å·
                                filtered_line.startswith('W: ') or  # apt warning format
                                'W: ' in filtered_line):  # apt warning format
                                message_type = 'info'
                            else:
                                message_type = self.socket_type
                            
                            # Detect if this is a progress bar update (contains \r)
                            is_update = '\r' in line
                            # Remove \r from the message for display
                            filtered_line = filtered_line.replace('\r', '')
                            
                            # Display warning and progress info as normal info
                            self.q.put({'event': 'output', 'data': {'message': filtered_line, 'type': message_type, 'is_update': is_update}})
                elif has_carriage_return and self.buffer:
                    # Handle progress bar update without newline (buffer ends with \r)
                    # Clean the buffer: remove \r and trailing whitespace
                    buffer_clean = self.buffer.replace('\r', '').rstrip()
                    if buffer_clean:
                        # Filter code_edit content
                        filtered_line = self.filter_code_edit_content(buffer_clean)
                        
                        # Filter out redundant system messages
                        if not self.should_filter_message(filtered_line):
                            # Check if it's warning or progress info
                            line_lower = filtered_line.lower()
                            if ('warning' in line_lower or
                                'progress' in line_lower or
                                'processing files' in line_lower or
                                filtered_line.startswith('Processing files:') or
                                'userwarning' in line_lower or
                                'warnings.warn' in line_lower or
                                'âš ï¸' in filtered_line or
                                filtered_line.startswith('W: ') or
                                'W: ' in filtered_line):
                                message_type = 'info'
                            else:
                                message_type = self.socket_type
                            
                            # This is definitely an update (has \r)
                            self.q.put({'event': 'output', 'data': {'message': filtered_line, 'type': message_type, 'is_update': True}})
                        # Clear buffer after processing update
                        self.buffer = ""
                # ä¿®å¤ä¸¢å­—é—®é¢˜ï¼šå¦‚æœbufferä¸­æ²¡æœ‰\nä¹Ÿæ²¡æœ‰\rï¼Œä½†bufferé•¿åº¦è¶…è¿‡é˜ˆå€¼ï¼ˆæ¯”å¦‚1024å­—ç¬¦ï¼‰ï¼Œä¹Ÿåº”è¯¥flush
                # è¿™æ ·å¯ä»¥é¿å…é•¿æ¶ˆæ¯è¢«åˆ†æˆå¤šä¸ªchunkæ—¶ï¼Œæœ€åä¸€éƒ¨åˆ†æ²¡æœ‰æ¢è¡Œç¬¦å¯¼è‡´ä¸¢å¤±
                elif len(self.buffer) > 1024:
                    # Bufferå¤ªé•¿ä½†æ²¡æœ‰æ¢è¡Œç¬¦ï¼Œå¼ºåˆ¶flushä»¥é¿å…ä¸¢å¤±
                    buffer_rstrip = self.buffer.rstrip()
                    if buffer_rstrip:
                        filtered_line = self.filter_code_edit_content(buffer_rstrip)
                        if not self.should_filter_message(filtered_line):
                            line_lower = filtered_line.lower()
                            if ('warning' in line_lower or
                                'progress' in line_lower or
                                'processing files' in line_lower or
                                filtered_line.startswith('Processing files:') or
                                'userwarning' in line_lower or
                                'warnings.warn' in line_lower or
                                'âš ï¸' in filtered_line or
                                filtered_line.startswith('W: ') or
                                'W: ' in filtered_line):
                                message_type = 'info'
                            else:
                                message_type = self.socket_type
                            
                            self.q.put({'event': 'output', 'data': {'message': filtered_line, 'type': message_type, 'is_update': False}})
                    self.buffer = ""

            def flush(self):
                # Flush buffer to queue if it contains content
                # This ensures that messages are sent immediately when flush() is called
                # ä¿®å¤ä¸¢å­—é—®é¢˜ï¼šå³ä½¿bufferä¸­æ²¡æœ‰æ¢è¡Œç¬¦ï¼Œä¹Ÿåº”è¯¥å‘é€bufferä¸­çš„å†…å®¹
                if self.buffer:
                    # å¤„ç†bufferä¸­çš„æ‰€æœ‰å†…å®¹ï¼Œå³ä½¿æ²¡æœ‰æ¢è¡Œç¬¦
                    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„è¡Œï¼ˆä»¥\nç»“å°¾ï¼‰
                    if '\n' in self.buffer:
                        # æœ‰å®Œæ•´çš„è¡Œï¼ŒæŒ‰è¡Œå¤„ç†
                        *lines, remaining = self.buffer.split('\n')
                        for line in lines:
                            if line.strip():
                                line_rstrip = line.rstrip()
                                filtered_line = self.filter_code_edit_content(line_rstrip)
                                if not self.should_filter_message(filtered_line):
                                    line_lower = filtered_line.lower()
                                    if ('warning' in line_lower or
                                        'progress' in line_lower or
                                        'processing files' in line_lower or
                                        filtered_line.startswith('Processing files:') or
                                        'userwarning' in line_lower or
                                        'warnings.warn' in line_lower or
                                        'âš ï¸' in filtered_line or
                                        filtered_line.startswith('W: ') or
                                        'W: ' in filtered_line):
                                        message_type = 'info'
                                    else:
                                        message_type = self.socket_type
                                    
                                    is_update = '\r' in line
                                    buffer_clean = filtered_line.replace('\r', '')
                                    self.q.put({'event': 'output', 'data': {'message': buffer_clean, 'type': message_type, 'is_update': is_update}})
                        # ä¿ç•™å‰©ä½™éƒ¨åˆ†ï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
                        self.buffer = remaining
                    else:
                        # æ²¡æœ‰æ¢è¡Œç¬¦ï¼Œç›´æ¥å¤„ç†æ•´ä¸ªbuffer
                        buffer_rstrip = self.buffer.rstrip()
                        if buffer_rstrip:
                            filtered_line = self.filter_code_edit_content(buffer_rstrip)
                            if not self.should_filter_message(filtered_line):
                                line_lower = filtered_line.lower()
                                if ('warning' in line_lower or
                                    'progress' in line_lower or
                                    'processing files' in line_lower or
                                    filtered_line.startswith('Processing files:') or
                                    'userwarning' in line_lower or
                                    'warnings.warn' in line_lower or
                                    'âš ï¸' in filtered_line or
                                    filtered_line.startswith('W: ') or
                                    'W: ' in filtered_line):
                                    message_type = 'info'
                                else:
                                    message_type = self.socket_type
                                
                                is_update = '\r' in self.buffer
                                buffer_clean = filtered_line.replace('\r', '')
                                self.q.put({'event': 'output', 'data': {'message': buffer_clean, 'type': message_type, 'is_update': is_update}})
                        # æ¸…ç©ºbufferï¼Œå› ä¸ºå·²ç»å¤„ç†äº†æ‰€æœ‰å†…å®¹
                        self.buffer = ""
            
            def final_flush(self):
                if self.buffer.strip():
                    # Filter out redundant system messages (preserve leading spaces)
                    buffer_rstrip = self.buffer.rstrip()  # Only remove trailing spaces, preserve leading spaces
                    if self.should_filter_message(buffer_rstrip):
                        self.buffer = ""
                        return
                    
                    # Check if it's warning or progress info, if so display as normal info instead of error
                    buffer_lower = self.buffer.lower()
                    if ('warning' in buffer_lower or
                        'progress' in buffer_lower or
                        'processing files' in buffer_lower or
                        self.buffer.strip().startswith('Processing files:') or
                        'userwarning' in buffer_lower or
                        'warnings.warn' in buffer_lower or
                        'âš ï¸' in self.buffer or  
                        self.buffer.strip().startswith('W: ') or  # apt warning format
                        'W: ' in self.buffer):  # apt warning format
                        message_type = 'info'
                    else:
                        message_type = self.socket_type
                    
                    # Detect if this is a progress bar update (contains \r)
                    is_update = '\r' in self.buffer
                    # Remove \r from the message for display
                    buffer_rstrip = buffer_rstrip.replace('\r', '')
                    
                    # Display warning and progress info as normal info
                    self.q.put({'event': 'output', 'data': {'message': buffer_rstrip, 'type': message_type, 'is_update': is_update}})
                    self.buffer = ""

        original_stdout = sys.stdout
        original_stderr = sys.stderr
        
        stdout_handler = QueueSocketHandler(output_queue, 'info')
        stderr_handler = QueueSocketHandler(output_queue, 'error')

        try:
            sys.stdout = stdout_handler
            sys.stderr = stderr_handler
            
            success = agia.run(user_requirement=final_requirement, loops=execution_rounds)
            
            # Ensure important completion information is displayed
            workspace_dir = os.path.join(out_dir, "workspace")
            output_queue.put({'event': 'output', 'data': {'message': f"ğŸ“ All files saved at: {os.path.abspath(out_dir)}", 'type': 'success'}})
            
            # Extract directory name for GUI display (relative to GUI data directory)
            dir_name = os.path.basename(out_dir)
            
            if success:
                output_queue.put({'event': 'task_completed', 'data': {'message': i18n['task_completed'], 'output_dir': dir_name, 'success': True}})
            else:
                output_queue.put({'event': 'task_completed', 'data': {'message': i18n['task_completed_with_errors'], 'output_dir': dir_name, 'success': False}})
        finally:
            stdout_handler.final_flush()
            stderr_handler.final_flush()
            sys.stdout = original_stdout
            sys.stderr = original_stderr
            
    except Exception as e:
        import traceback
        tb_str = traceback.format_exc()
        output_queue.put({'event': 'error', 'data': {'message': f'Task execution failed in process: {str(e)}\\n{tb_str}'}})
    finally:
        output_queue.put({'event': 'STOP'})

class AGIAgentGUI:
    def __init__(self):
        # User session management
        self.user_sessions = {}  # session_id -> UserSession
        
        # Initialize authentication manager
        self.auth_manager = AuthenticationManager()
        
        # Initialize concurrency manager with reference to this GUI instance
        self.concurrency_manager = ConcurrencyManager(
            max_concurrent_tasks=16,  # Maximum concurrent tasks (Expand by 1x)
            max_connections=40,       # æœ€å¤§Connectæ•° (Expand by 1x)
            gui_instance=self         # Pass GUI instance for unified monitoring
        )
        
        # Get GUI default data directory from config, fallback to current directory
        config_data_dir = get_gui_default_data_directory()
        if config_data_dir:
            self.base_data_dir = config_data_dir
        else:
            self.base_data_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        
        # Ensure base directory exists
        os.makedirs(self.base_data_dir, exist_ok=True)
        
        # Don't create default userdata directory until needed
        self.default_user_dir = os.path.join(self.base_data_dir, 'userdata')
        
        # Session cleanup is now handled by ConcurrencyManager unified monitor
        # No separate thread needed
        
        # Set timeout handling callback
        self.concurrency_manager.set_timeout_callback(self._handle_user_task_timeout)
        

    
    def get_user_session(self, session_id, api_key=None):
        """Get or create user session with authentication"""
        # Convert empty string to None for guest access
        if api_key == "":
            api_key = None
            
        # Always authenticate (including guest access)
        auth_result = self.auth_manager.authenticate_api_key(api_key)
        if not auth_result["authenticated"]:
            pass  # Authentication failed
            return None
        
        # Store guest status and user info
        is_guest = auth_result.get("is_guest", False)
        user_info = auth_result["user_info"]
        
        if session_id not in self.user_sessions:
            # Create authenticated session
            if self.auth_manager.create_session(api_key, session_id):
                self.user_sessions[session_id] = UserSession(session_id, api_key, user_info)
                session_type = "guest" if is_guest else "authenticated"
            else:
                return None
        else:
            # Update API key if it has changed
            existing_session = self.user_sessions[session_id]
            if existing_session.api_key != api_key:
                # Re-authenticate and update session
                if self.auth_manager.create_session(api_key, session_id):
                    self.user_sessions[session_id] = UserSession(session_id, api_key, user_info)
                else:
                    return None
        
        return self.user_sessions[session_id]
    
    def _cleanup_session(self, session_id):
        """Clean up specified session"""
        try:
            if session_id in self.user_sessions:
                user_session = self.user_sessions[session_id]
                
                # Clean up running processes
                if user_session.current_process and user_session.current_process.is_alive():
                    user_session.current_process.terminate()
                    user_session.current_process.join(timeout=5)
                
                # Clean up queue
                if user_session.output_queue:
                    try:
                        while not user_session.output_queue.empty():
                            user_session.output_queue.get_nowait()
                    except:
                        pass
                
                # Clean up session history (keep last 5)
                if len(user_session.conversation_history) > 5:
                    user_session.conversation_history = user_session.conversation_history[-5:]
                
                # Destroy authentication session
                self.auth_manager.destroy_session(session_id)
                
                # Remove user session
                del self.user_sessions[session_id]
                
        except Exception as e:
                pass  # Session cleanup error
    
    def _handle_user_task_timeout(self, session_id):
        """Handle user task timeout"""
        try:
            if session_id in self.user_sessions:
                user_session = self.user_sessions[session_id]

                # Terminate process
                if user_session.current_process and user_session.current_process.is_alive():
                    user_session.current_process.terminate()
                    user_session.current_process.join(timeout=10)

                    # Send timeout message to user
                    from flask_socketio import emit
                    emit('task_timeout', {
                        'message': f'Task execution timeout ({self.concurrency_manager.task_timeout}seconds)'
                    }, room=session_id)

                # Release task resources - call finish_task to clean up active_tasks
                self.concurrency_manager.finish_task(session_id, success=False)
        except Exception as e:
            pass
    

    
    def get_output_directories(self, user_session):
        """Get all directories containing workspace subdirectory for specific user"""
        result = []
        
        # Get user's directory
        user_output_dir = user_session.get_user_directory(self.base_data_dir)
        os.makedirs(user_output_dir, exist_ok=True)
        
        try:
            # Traverse all subdirectories in user's directory
            for item in os.listdir(user_output_dir):
                item_path = os.path.join(user_output_dir, item)
                
                # Check if it's a directory
                if os.path.isdir(item_path):
                    # Check if it contains workspace subdirectory
                    workspace_path = os.path.join(item_path, 'workspace')
                    if os.path.exists(workspace_path) and os.path.isdir(workspace_path):
                        # Get directory information
                        stat = os.stat(item_path)
                        size = self.get_directory_size(item_path)
                        
                        result.append({
                            'name': item,
                            'path': item_path,
                            'size': self.format_size(size),
                            'modified_time': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                            'files': self.get_directory_structure(item_path),
                            'is_current': item == user_session.current_output_dir,  # Mark if it's current directory
                            'is_selected': item == user_session.selected_output_dir,  # Mark if it's selected directory
                            'is_last': item == user_session.last_output_dir  # Mark if it's last used directory
                        })
        except (OSError, PermissionError) as e:
            pass
        
        # Sort by modification time
        result.sort(key=lambda x: os.path.getmtime(x['path']), reverse=True)
        return result
    
    def get_directory_size(self, directory):
        """Calculate directory size"""
        total_size = 0
        try:
            for dirpath, dirnames, filenames in os.walk(directory):
                for filename in filenames:
                    filepath = os.path.join(dirpath, filename)
                    if os.path.exists(filepath):
                        total_size += os.path.getsize(filepath)
        except (OSError, IOError):
            pass
        return total_size
    
    def format_size(self, size_bytes):
        """Format file size"""
        if size_bytes == 0:
            return "0 B"
        size_names = ["B", "KB", "MB", "GB", "TB"]
        i = 0
        while size_bytes >= 1024.0 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1
        return f"{size_bytes:.1f} {size_names[i]}"
    
    def get_directory_structure(self, directory, max_depth=10, current_depth=0, base_dir=None):
        """Get directory structure"""
        if current_depth > max_depth:
            return []
        
        # If first call, set base_dir to parent directory of current directory
        if base_dir is None:
            base_dir = os.path.dirname(directory)
        
        items = []
        try:
            for item in os.listdir(directory):
                item_path = os.path.join(directory, item)
                # Calculate relative path to base_dir
                relative_path = os.path.relpath(item_path, base_dir)
                # Convert Windows path separators to Unix style
                relative_path = relative_path.replace('\\', '/')
                
                if os.path.isdir(item_path):
                    children = self.get_directory_structure(item_path, max_depth, current_depth + 1, base_dir)
                    items.append({
                        'name': item,
                        'type': 'directory',
                        'path': relative_path,
                        'children': children
                    })
                else:
                    items.append({
                        'name': item,
                        'type': 'file',
                        'path': relative_path,
                        'size': self.format_size(os.path.getsize(item_path))
                    })
        except (OSError, PermissionError):
            pass
        
        return sorted(items, key=lambda x: (x['type'] == 'file', x['name']))

class UserSession:
    def __init__(self, session_id, api_key=None, user_info=None):
        self.session_id = session_id
        self.api_key = api_key
        self.user_info = user_info or {}
        self.current_process = None
        self.output_queue = None
        self.input_queue = None  # Queue for user input in GUI mode
        self.current_output_dir = None  # Track current execution output directory
        self.last_output_dir = None     # Track last used output directory
        self.selected_output_dir = None # Track user selected output directory
        self.conversation_history = []  # Store conversation history for this user
        
        # Determine user directory based on user info
        if user_info and user_info.get("is_guest", False):
            # Guest user gets a special directory
            self.user_dir_name = "guest"
        elif user_info and user_info.get("name"):
            # Use username as directory name, sanitize for filesystem safety
            import re
            username = user_info.get("name")
            # Remove or replace characters that are not safe for directory names
            safe_username = re.sub(r'[<>:"/\\|?*]', '_', username)
            # Remove leading/trailing spaces and dots
            safe_username = safe_username.strip(' .')
            # Ensure it's not empty after sanitization
            if not safe_username:
                safe_username = "user"
            self.user_dir_name = safe_username
        elif api_key:
            # Fallback: Use API key hash as directory name for security
            import hashlib
            api_key_hash = hashlib.sha256(api_key.encode()).hexdigest()[:16]
            self.user_dir_name = f"user_{api_key_hash}"
        else:
            self.user_dir_name = "userdata"
    
    def get_user_directory(self, base_dir):
        """Get the user's base directory path"""
        return os.path.join(base_dir, self.user_dir_name)
    
    def add_to_conversation_history(self, user_input, result_summary=None):
        """Add a conversation turn to history"""
        conversation_entry = {
            'timestamp': datetime.now().isoformat(),
            'user_input': user_input,
            'result_summary': result_summary or "Task executed",
            'output_dir': self.current_output_dir
        }
        self.conversation_history.append(conversation_entry)
        
        # Keep only last 10 conversations to avoid memory issues
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]
    
    def get_summarized_requirements(self):
        """Summarize conversation history into a comprehensive requirement"""
        if not self.conversation_history:
            return None
        
        # Create a summary of all previous requests
        history_summary = []
        for entry in self.conversation_history:
            history_summary.append(f"User requested: {entry['user_input']}")
        
        # Combine into a comprehensive requirement
        summarized_req = "\n".join(history_summary[-5:])  # Last 5 entries
        return summarized_req

gui_instance = AGIAgentGUI()

def create_temp_session_id(request, api_key=None):
    """Create a temporary session ID for API calls with user isolation"""
    import hashlib
    api_key_hash = hashlib.sha256((api_key or "default").encode()).hexdigest()[:8]
    # Use consistent session ID based on IP and API key, not request ID
    return f"api_{request.remote_addr}_{api_key_hash}"

def queue_reader_thread(session_id):
    """Reads from the queue and emits messages to the client via SocketIO."""
    
    def safe_emit(event, data=None, room=None):
        """å®‰å…¨åœ°å‘é€æ¶ˆæ¯ï¼Œæ•è·æ‰€æœ‰å¼‚å¸¸ä»¥é¿å…çº¿ç¨‹å´©æºƒ"""
        try:
            if data is None:
                socketio.emit(event, room=room or session_id)
            else:
                socketio.emit(event, data, room=room or session_id)
        except Exception as emit_error:
            # å¦‚æœå‘é€å¤±è´¥ï¼ˆé€šå¸¸æ˜¯å®¢æˆ·ç«¯å·²æ–­å¼€ï¼‰ï¼Œé™é»˜å¤„ç†
            # å¦‚æœæ˜¯å› ä¸ºå®¢æˆ·ç«¯æ–­å¼€ï¼Œåº”è¯¥é€€å‡ºçº¿ç¨‹
            if 'disconnected' in str(emit_error).lower() or 'not connected' in str(emit_error).lower():
                return False
        return True
    
    if session_id not in gui_instance.user_sessions:
        return
    
    user_session = gui_instance.user_sessions[session_id]
    
    while True:
        try:
            if user_session.current_process and not user_session.current_process.is_alive() and user_session.output_queue.empty():
                break

            message = user_session.output_queue.get(timeout=1)
            
            if message.get('event') == 'STOP':
                break
            
            # Check for GUI_USER_INPUT_REQUEST marker in output messages
            # Also check for QUERY: and TIMEOUT: messages that might arrive out of order
            if message.get('event') == 'output':
                data = message.get('data', {})
                msg_text = data.get('message', '')
                
                # Check if this is a QUERY: message (might arrive before GUI_USER_INPUT_REQUEST)
                if msg_text.startswith('QUERY: '):
                    # Store query for later use
                    if not hasattr(user_session, '_pending_user_query'):
                        user_session._pending_user_query = {}
                    user_session._pending_user_query['query'] = msg_text[7:]  # Remove 'QUERY: ' prefix
                    # Don't emit this system message to frontend - it's only for internal processing
                    continue
                
                # Check if this is a TIMEOUT: message
                elif msg_text.startswith('TIMEOUT: '):
                    # Store timeout for later use
                    if not hasattr(user_session, '_pending_user_query'):
                        user_session._pending_user_query = {}
                    timeout_str = msg_text[9:]  # Remove 'TIMEOUT: ' prefix
                    try:
                        user_session._pending_user_query['timeout'] = int(timeout_str)
                    except:
                        user_session._pending_user_query['timeout'] = 10
                    # Don't emit this system message to frontend - it's only for internal processing
                    continue
                
                # Check for GUI_USER_INPUT_REQUEST marker
                elif 'ğŸ”” GUI_USER_INPUT_REQUEST' in msg_text:
                    # Extract query and timeout from subsequent messages or use stored values
                    query = None
                    timeout = 10
                    timeout_found = False
                    
                    # Check if we already have stored query/timeout from previous messages
                    if hasattr(user_session, '_pending_user_query'):
                        query = user_session._pending_user_query.get('query')
                        stored_timeout = user_session._pending_user_query.get('timeout')
                        if stored_timeout is not None:
                            timeout = stored_timeout
                            timeout_found = True
                        # Clear stored values
                        delattr(user_session, '_pending_user_query')
                    
                    # Store messages that are not QUERY/TIMEOUT for later emission
                    pending_messages = []
                    # Read more messages to get query and timeout (increased from 15 to 30)
                    # Also increase timeout per message to handle slow message delivery
                    for _ in range(30):  # Read up to 30 more messages to ensure we get QUERY and TIMEOUT
                        try:
                            next_msg = user_session.output_queue.get(timeout=2.0)  # Increased timeout from 1.0 to 2.0
                            if next_msg.get('event') == 'output':
                                next_data = next_msg.get('data', {})
                                next_text = next_data.get('message', '')
                                if next_text.startswith('QUERY: '):
                                    query = next_text[7:]  # Remove 'QUERY: ' prefix
                                elif next_text.startswith('TIMEOUT: '):
                                    timeout_str = next_text[9:]  # Remove 'TIMEOUT: ' prefix
                                    try:
                                        timeout = int(timeout_str)
                                        timeout_found = True
                                    except:
                                        timeout = 10
                                else:
                                    # Store other messages to emit later
                                    pending_messages.append(next_msg)
                            else:
                                # Store non-output messages to emit later
                                pending_messages.append(next_msg)
                            
                            # If we found both query and timeout, we can break
                            if query and timeout_found:
                                break
                        except queue.Empty:
                            # If queue is empty, wait a bit more and try to read remaining messages
                            # This handles the case where messages are still being written
                            import time
                            time.sleep(0.1)  # Small delay to allow messages to arrive
                            # Try one more time with shorter timeout
                            try:
                                next_msg = user_session.output_queue.get(timeout=0.5)
                                if next_msg.get('event') == 'output':
                                    next_data = next_msg.get('data', {})
                                    next_text = next_data.get('message', '')
                                    if next_text.startswith('QUERY: '):
                                        query = next_text[7:]
                                    elif next_text.startswith('TIMEOUT: '):
                                        timeout_str = next_text[9:]
                                        try:
                                            timeout = int(timeout_str)
                                            timeout_found = True
                                        except:
                                            timeout = 10
                                    else:
                                        pending_messages.append(next_msg)
                                else:
                                    pending_messages.append(next_msg)
                                if query and timeout_found:
                                    break
                            except queue.Empty:
                                break
                    
                    # If we found query (either from stored value or from queue), send the request
                    if query:
                        # Send user_input_request event to GUI
                        if not safe_emit('user_input_request', {
                            'query': query,
                            'timeout': timeout
                        }):
                            break
                        # Emit pending messages that were read while looking for QUERY/TIMEOUT
                        for pending_msg in pending_messages:
                            if not safe_emit(pending_msg['event'], pending_msg.get('data', {})):
                                break
                        continue  # Don't emit the marker message itself
                    else:
                        # If query not found after all attempts, emit all pending messages
                        # Emit all pending messages including the marker
                        for pending_msg in pending_messages:
                            if not safe_emit(pending_msg['event'], pending_msg.get('data', {})):
                                break
                        # Still emit the original marker message so user can see something happened
                        if not safe_emit(message['event'], message.get('data', {})):
                            break
            
            # If task completion message, save last used directory and clear current directory mark
            if message.get('event') in ['task_completed', 'error']:
                # Release task resources
                task_success = message.get('event') == 'task_completed'
                gui_instance.concurrency_manager.finish_task(session_id, success=task_success)
                
                # Get updated metrics
                metrics = gui_instance.concurrency_manager.get_metrics()
                status_msg = "Complete" if task_success else "Failed"
                
                if user_session.current_output_dir:
                    user_session.last_output_dir = user_session.current_output_dir
                    # If current directory is the selected directory, keep the selection
                    # This ensures user can continue in the same directory
                    if user_session.selected_output_dir == user_session.current_output_dir:
                        pass
                    else:
                        # If different directories, clear selection to avoid confusion
                        user_session.selected_output_dir = None
                
                # Add to conversation history if we have context from last executed task
                if hasattr(user_session, '_current_task_requirement'):
                    result_summary = "Task completed successfully" if task_success else "Task failed or had errors"
                    user_session.add_to_conversation_history(user_session._current_task_requirement, result_summary)
                    delattr(user_session, '_current_task_requirement')
                
                user_session.current_output_dir = None
            
            # Emit to user's specific room (but filter out system markers)
            if message.get('event') == 'output':
                data = message.get('data', {})
                msg_text = data.get('message', '')
                # Don't emit system markers to frontend (they're handled internally)
                if 'ğŸ”” GUI_USER_INPUT_REQUEST' in msg_text or msg_text.startswith('QUERY: ') or msg_text.startswith('TIMEOUT: '):
                    continue  # Skip emitting these system messages
            
            if not safe_emit(message['event'], message.get('data', {})):
                break  # å®¢æˆ·ç«¯å·²æ–­å¼€ï¼Œé€€å‡ºçº¿ç¨‹
        except queue.Empty:
            continue
        except Exception as e:
            # é™é»˜å¤„ç†å¼‚å¸¸ï¼Œé¿å…çº¿ç¨‹å´©æºƒ
            break
    
    if user_session.current_process and hasattr(user_session.current_process, '_popen') and user_session.current_process._popen is not None:
        try:
            user_session.current_process.join(timeout=1)
        except Exception as e:
            pass
    user_session.current_process = None
    user_session.output_queue = None
    if user_session.current_output_dir:
        user_session.last_output_dir = user_session.current_output_dir
    user_session.current_output_dir = None  # Clear current directory mark

@app.route('/')
def index():
    """Main page"""
    # Support language switching via URL parameter
    lang_param = request.args.get('lang')
    if lang_param and lang_param in ('zh', 'en'):
        current_lang = lang_param
    else:
        current_lang = get_language()
    
    i18n = get_i18n_texts()
    # Override i18n if language is specified via URL
    if lang_param and lang_param in ('zh', 'en'):
        i18n = I18N_TEXTS.get(lang_param, I18N_TEXTS['en'])
    
    mcp_servers = get_mcp_servers_config()
    return render_template('index.html', i18n=i18n, lang=current_lang, mcp_servers=mcp_servers)

@app.route('/register')
def register():
    """User registration page"""
    i18n = get_i18n_texts()
    current_lang = get_language()
    return render_template('register.html', i18n=i18n, lang=current_lang)

@app.route('/api/register', methods=['POST'])
def api_register():
    """API endpoint for user registration"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è¯·æ±‚æ•°æ®'}), 400

        username = data.get('username', '').strip()
        phone_number = data.get('phone_number', '').strip()

        if not username or not phone_number:
            return jsonify({'success': False, 'error': 'ç”¨æˆ·åå’Œæ‰‹æœºå·ä¸ºå¿…å¡«é¡¹'}), 400

        # Register user
        result = gui_instance.auth_manager.register_user(username, phone_number)

        if result['success']:
            return jsonify({
                'success': True,
                'api_key': result['api_key'],
                'user_info': result['user_info'],
                'message': 'æ³¨å†ŒæˆåŠŸï¼è¯·å¦¥å–„ä¿å­˜æ‚¨çš„APIå¯†é’¥ã€‚'
            })
        else:
            return jsonify({'success': False, 'error': result['error']}), 400

    except Exception as e:
        return jsonify({'success': False, 'error': 'æ³¨å†Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯'}), 500

@app.route('/test_toggle_simple.html')
def test_toggle_simple():
    """Expand/collapse functionality test page"""
    return send_from_directory('.', 'test_toggle_simple.html')

@app.route('/simple_test.html')
def simple_test():
    """Simple test page"""
    return send_from_directory('.', 'simple_test.html')

@app.route('/api/output-dirs')
def get_output_dirs():
    """Get output directory list"""
    try:
        # Get API key from query parameters
        api_key = request.args.get('api_key')
        
        # Create a temporary session for API calls (since no socket connection)
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        
        if not user_session:
            return jsonify({'success': False, 'error': 'Authentication failed'}), 401
        
        dirs = gui_instance.get_output_directories(user_session)
        return jsonify({'success': True, 'directories': dirs})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/download/<path:dir_name>')
def download_directory(dir_name):
    """Download directory as zip file (excluding code_index directory)"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Security check: normalize path and prevent path traversal
        # Don't use secure_filename as it destroys Chinese characters
        normalized_dir_name = os.path.normpath(dir_name)
        if '..' in normalized_dir_name or normalized_dir_name.startswith('/'):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        dir_path = os.path.join(user_base_dir, normalized_dir_name)
        
        # Security check: ensure directory is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_dir_path = os.path.realpath(dir_path)
        if not real_dir_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        if not os.path.exists(dir_path) or not os.path.isdir(dir_path):
            return jsonify({'success': False, 'error': 'Directory not found'})
        
        # Create temporary zip file in a more reliable location
        import tempfile
        temp_dir = tempfile.gettempdir()
        temp_file = os.path.join(temp_dir, f"{dir_name}_{os.getpid()}_{int(datetime.now().timestamp())}.zip")
        
        try:
            with zipfile.ZipFile(temp_file, 'w', zipfile.ZIP_DEFLATED, compresslevel=6) as zipf:
                for root, dirs, files in os.walk(dir_path):
                    # Exclude code_index directory and other unwanted directories
                    dirs_to_exclude = {'code_index', '__pycache__', '.git', '.vscode', 'node_modules'}
                    if any(excluded in root for excluded in dirs_to_exclude):
                        continue
                    
                    for file in files:
                        # Skip unwanted files
                        if file.startswith('.') and file not in {'.gitignore', '.env.example'}:
                            continue
                        if file.endswith(('.pyc', '.pyo', '.DS_Store', 'Thumbs.db')):
                            continue
                            
                        file_path = os.path.join(root, file)
                        try:
                            # Calculate relative path for archive
                            rel_path = os.path.relpath(file_path, dir_path)
                            arcname = os.path.join(dir_name, rel_path).replace('\\', '/')
                            zipf.write(file_path, arcname)
                        except (OSError, IOError) as file_error:
                            continue
            
            # Verify that the zip file was created and is not empty
            if not os.path.exists(temp_file) or os.path.getsize(temp_file) == 0:
                return jsonify({'success': False, 'error': 'Failed to create zip file or zip file is empty'})
            
            
            # Schedule cleanup after the request is complete
            @after_this_request
            def remove_temp_file(response):
                try:
                    if os.path.exists(temp_file):
                        os.remove(temp_file)
                except Exception as cleanup_error:
                    pass
                return response
            
            # Return the file with proper headers
            return send_file(
                temp_file, 
                as_attachment=True, 
                download_name=f"{dir_name}.zip",
                mimetype='application/zip'
            )
            
        except Exception as zip_error:
            # Clean up temporary file on error
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
            raise zip_error
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/list-directory', methods=['POST'])
def list_directory():
    """List directory contents (single level). Used by Markdown image switcher."""
    try:
        data = request.get_json() or {}
        rel_path = data.get('path', '')

        # Auth
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)

        full_path = os.path.join(user_base_dir, rel_path)
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        if not os.path.exists(full_path) or not os.path.isdir(full_path):
            return jsonify({'success': False, 'error': f'Directory not found: {rel_path}'})

        items = []
        for name in os.listdir(full_path):
            item_path = os.path.join(full_path, name)
            if os.path.isfile(item_path):
                try:
                    size = os.path.getsize(item_path)
                except Exception:
                    size = 0
                items.append({'name': name, 'type': 'file', 'size': size})
            else:
                items.append({'name': name, 'type': 'directory'})

        items.sort(key=lambda x: (x.get('type') == 'file', x['name']))
        return jsonify({'success': True, 'files': items})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/file/<path:file_path>')
def get_file_content(file_path):
    """Get file content"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly, don't use secure_filename as we need to maintain path structure
        full_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            return jsonify({'success': False, 'error': f'File not found: {file_path}'})
        
        # Check file size to avoid reading oversized files
        file_size = os.path.getsize(full_path)
        if file_size > 50 * 1024 * 1024:  # 50MB
            return jsonify({'success': False, 'error': 'File too large to display'})
        
        # Get file extension
        _, ext = os.path.splitext(full_path.lower())
        
        # Decide how to handle based on file type
        if ext in ['.html', '.htm']:
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            return jsonify({
                'success': True, 
                'content': content, 
                'type': 'html',
                'file_path': file_path,  # Add file path for HTML preview
                'size': gui_instance.format_size(file_size)
            })
        elif ext in ['.md', '.markdown']:
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            return jsonify({
                'success': True, 
                'content': content, 
                'type': 'markdown',
                'size': gui_instance.format_size(file_size)
            })
        elif ext == '.pdf':
            # PDF files directly return file path
            return jsonify({
                'success': True, 
                'type': 'pdf',
                'file_path': file_path,
                'size': gui_instance.format_size(file_size)
            })
        elif ext in ['.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx']:
            # Office document preview
            return jsonify({
                'success': True, 
                'type': 'office',
                'file_path': file_path,
                'file_ext': ext,
                'size': gui_instance.format_size(file_size)
            })
        elif ext == '.tex':
            # LaTeX file - treat as code file
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            return jsonify({
                'success': True, 
                'content': content, 
                'type': 'code',
                'language': 'latex',
                'size': gui_instance.format_size(file_size)
            })
        elif ext in ['.py', '.js', '.jsx', '.ts', '.tsx', '.css', '.json', '.txt', '.log', '.yaml', '.yml', 
                     '.c', '.cpp', '.cc', '.cxx', '.h', '.hpp', '.java', '.go', '.rs', '.php', '.rb', 
                     '.sh', '.bash', '.zsh', '.fish', '.ps1', '.bat', '.cmd', '.xml', '.sql', '.r', 
                     '.scala', '.kt', '.swift', '.dart', '.lua', '.perl', '.pl', '.vim', '.dockerfile', 
                     '.makefile', '.cmake', '.gradle', '.properties', '.ini', '.cfg', '.conf', '.toml', '.mmd', '.out']:
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # Language mapping for syntax highlighting
            language_map = {
                '.py': 'python',
                '.js': 'javascript', 
                '.jsx': 'javascript',
                '.ts': 'typescript',
                '.tsx': 'typescript',
                '.css': 'css',
                '.json': 'json',
                '.c': 'c',
                '.cpp': 'cpp',
                '.cc': 'cpp',
                '.cxx': 'cpp',
                '.h': 'c',
                '.hpp': 'cpp',
                '.java': 'java',
                '.go': 'go',
                '.rs': 'rust',
                '.php': 'php',
                '.rb': 'ruby',
                '.sh': 'bash',
                '.bash': 'bash',
                '.zsh': 'bash',
                '.fish': 'bash',
                '.ps1': 'powershell',
                '.bat': 'batch',
                '.cmd': 'batch',
                '.xml': 'xml',
                '.sql': 'sql',
                '.r': 'r',
                '.scala': 'scala',
                '.kt': 'kotlin',
                '.swift': 'swift',
                '.dart': 'dart',
                '.lua': 'lua',
                '.perl': 'perl',
                '.pl': 'perl',
                '.vim': 'vim',
                '.dockerfile': 'dockerfile',
                '.makefile': 'makefile',
                '.cmake': 'cmake',
                '.gradle': 'gradle',
                '.yaml': 'yaml',
                '.yml': 'yaml',
                '.toml': 'toml',
                '.txt': 'text',
                '.log': 'text',
                '.mmd': 'mermaid',
                '.out': 'text'
            }
            
            language = language_map.get(ext, ext[1:])  # Default to remove dot
            
            return jsonify({
                'success': True, 
                'content': content, 
                'type': 'code',
                'language': language,
                'size': gui_instance.format_size(file_size)
            })
        elif ext == '.csv':
            # CSV file table preview
            import csv
            import io
            
            try:
                # Read CSV file
                with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # Parse CSV content
                csv_reader = csv.reader(io.StringIO(content))
                rows = list(csv_reader)
                
                if not rows:
                    return jsonify({'success': False, 'error': 'CSV file is empty'})
                
                # Get header (first row)
                headers = rows[0] if rows else []
                data_rows = rows[1:] if len(rows) > 1 else []
                
                # Limit displayed rows to avoid frontend lag
                max_rows = 1000
                if len(data_rows) > max_rows:
                    data_rows = data_rows[:max_rows]
                    truncated = True
                    total_rows = len(rows) - 1  # Subtract header
                else:
                    truncated = False
                    total_rows = len(data_rows)
                
                return jsonify({
                    'success': True,
                    'type': 'csv',
                    'headers': headers,
                    'data': data_rows,
                    'total_rows': total_rows,
                    'displayed_rows': len(data_rows),
                    'truncated': truncated,
                    'size': gui_instance.format_size(file_size)
                })
                
            except UnicodeDecodeError:
                # Try other encodings
                try:
                    with open(full_path, 'r', encoding='gbk', errors='ignore') as f:
                        content = f.read()
                    
                    csv_reader = csv.reader(io.StringIO(content))
                    rows = list(csv_reader)
                    
                    if not rows:
                        return jsonify({'success': False, 'error': 'CSV file is empty'})
                    
                    headers = rows[0] if rows else []
                    data_rows = rows[1:] if len(rows) > 1 else []
                    
                    max_rows = 1000
                    if len(data_rows) > max_rows:
                        data_rows = data_rows[:max_rows]
                        truncated = True
                        total_rows = len(rows) - 1
                    else:
                        truncated = False
                        total_rows = len(data_rows)
                    
                    return jsonify({
                        'success': True,
                        'type': 'csv',
                        'headers': headers,
                        'data': data_rows,
                        'total_rows': total_rows,
                        'displayed_rows': len(data_rows),
                        'truncated': truncated,
                        'encoding': 'gbk',
                        'size': gui_instance.format_size(file_size)
                    })
                except Exception:
                    return jsonify({'success': False, 'error': 'CSV file encoding not supported, please try UTF-8 or GBK encoding'})
            
            except Exception as e:
                return jsonify({'success': False, 'error': f'CSV file parsing failed: {str(e)}'})
        elif ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.bmp', '.webp', '.ico']:
            # Image file handling
            import base64
            
            try:
                # Check if request wants raw image data (from img tag) or JSON (from preview)
                accept_header = request.headers.get('Accept', '')
                wants_raw_image = (
                    'image/' in accept_header or 
                    request.args.get('raw') == 'true' or
                    'text/html' in accept_header  # img tags typically send this
                )
                
                # Determine MIME type
                mime_types = {
                    '.png': 'image/png',
                    '.jpg': 'image/jpeg', 
                    '.jpeg': 'image/jpeg',
                    '.gif': 'image/gif',
                    '.svg': 'image/svg+xml',
                    '.bmp': 'image/bmp',
                    '.webp': 'image/webp',
                    '.ico': 'image/x-icon'
                }
                mime_type = mime_types.get(ext, 'image/jpeg')
                
                if wants_raw_image:
                    # Return raw image data for img tags
                    with open(full_path, 'rb') as f:
                        image_data = f.read()
                    
                    return Response(
                        image_data,
                        mimetype=mime_type,
                        headers={
                            'Content-Length': len(image_data),
                            'Cache-Control': 'no-cache, no-store, must-revalidate'  # Disable caching for immediate updates
                        }
                    )
                else:
                    # Return JSON for preview functionality
                    with open(full_path, 'rb') as f:
                        image_data = f.read()
                    
                    # Convert to base64 for embedding in response
                    image_base64 = base64.b64encode(image_data).decode('utf-8')
                    
                    # Get image dimensions if possible
                    image_info = {}
                    try:
                        from PIL import Image
                        with Image.open(full_path) as img:
                            image_info = {
                                'width': img.width,
                                'height': img.height,
                                'format': img.format
                            }
                    except (ImportError, Exception):
                        # PIL not available or image cannot be processed
                        image_info = {'width': 'Unknown', 'height': 'Unknown', 'format': ext[1:].upper()}
                    
                    return jsonify({
                        'success': True,
                        'type': 'image',
                        'data': f"data:{mime_type};base64,{image_base64}",
                        'file_path': file_path,
                        'image_info': image_info,
                        'size': gui_instance.format_size(file_size)
                    })
                
            except Exception as e:
                return jsonify({'success': False, 'error': f'Failed to load image: {str(e)}'})
        else:
            return jsonify({'success': False, 'error': 'File type not supported for preview'})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/pdf/<path:file_path>')
def serve_pdf(file_path):
    """Serve PDF file directly"""
    try:
        pass
        
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly, don't use secure_filename as we need to maintain path structure
        full_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            return jsonify({'success': False, 'error': f'File not found: {file_path}'})
        
        # Check if it's a PDF file
        if not full_path.lower().endswith('.pdf'):
            return jsonify({'success': False, 'error': 'Not a PDF file'})
        
        # Verify PDF file structure
        try:
            with open(full_path, 'rb') as f:
                header = f.read(8)
                if not header.startswith(b'%PDF-'):
                    return jsonify({'success': False, 'error': 'Invalid PDF file structure'})
        except Exception as pdf_check_error:
            return jsonify({'success': False, 'error': f'PDF validation failed: {str(pdf_check_error)}'})
        
        response = send_file(full_path, mimetype='application/pdf')
        
        # Add CORS headers
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'X-API-Key, Content-Type'
        
        return response
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/static-file/<path:file_path>')
def serve_static_file(file_path):
    """Serve static files for HTML preview (JS, CSS, images, etc.)"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly, don't use secure_filename as we need to maintain path structure
        full_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            abort(403)
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            abort(404)
        
        # Get file extension and determine mimetype
        _, ext = os.path.splitext(full_path.lower())
        
        # Define mimetypes for different file types
        mimetype_map = {
            '.js': 'application/javascript',
            '.css': 'text/css',
            '.html': 'text/html',
            '.htm': 'text/html',
            '.json': 'application/json',
            '.xml': 'application/xml',
            '.txt': 'text/plain',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml',
            '.webp': 'image/webp',
            '.ico': 'image/x-icon',
            '.bmp': 'image/bmp',
            '.woff': 'font/woff',
            '.woff2': 'font/woff2',
            '.ttf': 'font/ttf',
            '.eot': 'application/vnd.ms-fontobject',
            '.otf': 'font/otf',
            '.mp3': 'audio/mpeg',
            '.wav': 'audio/wav',
            '.ogg': 'audio/ogg',
            '.mp4': 'video/mp4',
            '.webm': 'video/webm',
            '.avi': 'video/x-msvideo',
            '.mov': 'video/quicktime'
        }
        
        mimetype = mimetype_map.get(ext, 'application/octet-stream')
        
        # For text-based files, try to read with UTF-8 encoding
        if ext in ['.js', '.css', '.html', '.htm', '.json', '.svg', '.xml', '.txt']:
            try:
                with open(full_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                return Response(content, mimetype=mimetype, headers={
                    'Cache-Control': 'no-cache',
                    'Access-Control-Allow-Origin': '*'
                })
            except UnicodeDecodeError:
                # Fallback to binary mode if UTF-8 fails
                pass
        
        # For binary files or if UTF-8 failed, serve as binary
        return send_file(full_path, mimetype=mimetype, as_attachment=False)
        
    except Exception as e:
        print(f"Error serving static file {file_path}: {str(e)}")
        import traceback
        traceback.print_exc()
        abort(500)

@app.route('/api/html-preview/<path:file_path>')
def serve_html_preview(file_path):
    """Serve HTML file with proper base URL for relative resource loading"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly, don't use secure_filename as we need to maintain path structure
        full_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            abort(403)
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            abort(404)
        
        # Read HTML content
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            html_content = f.read()
        
        # Get the directory of the HTML file for base URL
        file_dir = os.path.dirname(file_path)
        
        # Inject base tag to handle relative paths
        if file_dir:
            # Ensure the base URL ends with a slash for proper relative path resolution
            base_url = f"/api/static-file/{file_dir}/"
        else:
            base_url = "/api/static-file/"
        
        # Don't add API key to base URL as it doesn't work properly with relative paths
        # Instead, we'll modify the HTML content to include API key in script/link tags
        
        # Process HTML content to add API key to relative resource URLs
        import re
        
        # Function to add API key to relative URLs
        def add_api_key_to_url(url):
            if url.startswith(('http://', 'https://', '//', 'data:', 'javascript:', 'mailto:')):
                return url  # Don't modify absolute URLs or special schemes
            if url.startswith('/'):
                return url  # Don't modify root-relative URLs
            
            # Add API key to relative URLs
            separator = '&' if '?' in url else '?'
            if api_key and api_key != 'default':
                return f"{base_url}{url}{separator}api_key={api_key}"
            else:
                return f"{base_url}{url}"
        
        # Replace src attributes in script tags
        html_content = re.sub(
            r'(<script[^>]+src=")([^"]+)(")',
            lambda m: m.group(1) + add_api_key_to_url(m.group(2)) + m.group(3),
            html_content,
            flags=re.IGNORECASE
        )
        
        # Replace href attributes in link tags (CSS, etc.)
        html_content = re.sub(
            r'(<link[^>]+href=")([^"]+)(")',
            lambda m: m.group(1) + add_api_key_to_url(m.group(2)) + m.group(3),
            html_content,
            flags=re.IGNORECASE
        )
        
        # Replace src attributes in img tags
        html_content = re.sub(
            r'(<img[^>]+src=")([^"]+)(")',
            lambda m: m.group(1) + add_api_key_to_url(m.group(2)) + m.group(3),
            html_content,
            flags=re.IGNORECASE
        )
        
        # Also handle single quotes
        html_content = re.sub(
            r"(<script[^>]+src=')([^']+)(')",
            lambda m: m.group(1) + add_api_key_to_url(m.group(2)) + m.group(3),
            html_content,
            flags=re.IGNORECASE
        )
        
        html_content = re.sub(
            r"(<link[^>]+href=')([^']+)(')",
            lambda m: m.group(1) + add_api_key_to_url(m.group(2)) + m.group(3),
            html_content,
            flags=re.IGNORECASE
        )
        
        html_content = re.sub(
            r"(<img[^>]+src=')([^']+)(')",
            lambda m: m.group(1) + add_api_key_to_url(m.group(2)) + m.group(3),
            html_content,
            flags=re.IGNORECASE
        )
        
        return Response(html_content, mimetype='text/html')
        
    except Exception as e:
        print(f"Error serving HTML preview {file_path}: {str(e)}")
        import traceback
        traceback.print_exc()
        abort(500)

@app.route('/api/download-file/<path:file_path>')
def download_file(file_path):
    """Download file directly"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly, don't use secure_filename as we need to maintain path structure
        full_path = os.path.join(user_base_dir, file_path)
        

        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            return jsonify({'success': False, 'error': f'File not found: {file_path}'})
        
        # Get file extension and set appropriate mimetype
        _, ext = os.path.splitext(full_path.lower())
        
        # Define mimetypes for different file types
        mimetype_map = {
            '.pdf': 'application/pdf',
            '.doc': 'application/msword',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.xls': 'application/vnd.ms-excel',
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.ppt': 'application/vnd.ms-powerpoint',
            '.pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            '.txt': 'text/plain',
            '.html': 'text/html',
            '.css': 'text/css',
            '.js': 'application/javascript',
            '.json': 'application/json',
            '.xml': 'application/xml',
            '.zip': 'application/zip',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.jpeg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml'
        }
        
        # Get mimetype or use default
        mimetype = mimetype_map.get(ext, 'application/octet-stream')
        
        # Get filename for download
        filename = os.path.basename(full_path)
        
        return send_file(full_path, 
                        mimetype=mimetype, 
                        as_attachment=True, 
                        download_name=filename)
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

# Cloud upload functionality has been removed for offline deployment

def convert_markdown_to_latex_only(full_path, file_path, user_base_dir):
    """Convert Markdown to LaTeX only"""
    import subprocess
    from pathlib import Path
    
    try:
        md_path = Path(full_path)
        base_name = md_path.stem
        output_dir = md_path.parent
        latex_file = output_dir / f"{base_name}.tex"
        
        # Use trans_md_to_pdf.py script to convert to LaTeX
        trans_script = Path(__file__).parent.parent / "src" / "utils" / "trans_md_to_pdf.py"
        
        if trans_script.exists():
            cmd = [
                sys.executable,  # Use current Python executable instead of hardcoded 'python3'
                str(trans_script),
                md_path.name,  # Use filename instead of full path
                latex_file.name,  # Use filename instead of full path
                '--latex'  # Add LaTeX flag
            ]
            
            # Execute command in markdown file directory
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', cwd=str(output_dir))
            
            if latex_file.exists():
                file_size = latex_file.stat().st_size
                return {
                    'status': 'success',
                    'markdown_file': file_path,
                    'conversions': {
                        'latex': {
                            'status': 'success',
                            'file': str(latex_file.relative_to(user_base_dir)),
                            'size': file_size,
                            'size_kb': f"{file_size / 1024:.1f} KB"
                        }
                    }
                }
            else:
                # Try direct pandoc conversion as fallback
                cmd = [
                    'pandoc',
                    md_path.name,
                    '-o', latex_file.name,
                    '--to', 'latex'
                ]
                
                # Add common options for LaTeX
                cmd.extend([
                    '-V', 'fontsize=12pt',
                    '-V', 'geometry:margin=2.5cm',
                    '-V', 'geometry:a4paper',
                    '-V', 'linestretch=2.0',
                    '--highlight-style=tango',
                    '-V', 'colorlinks=true',
                    '-V', 'linkcolor=blue',
                    '-V', 'urlcolor=blue',
                    '--toc',
                    '--wrap=preserve'
                ])
                
                result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8', errors='ignore', cwd=str(output_dir))
                
                if latex_file.exists():
                    file_size = latex_file.stat().st_size
                    return {
                        'status': 'success',
                        'markdown_file': file_path,
                        'conversions': {
                            'latex': {
                                'status': 'success',
                                'file': str(latex_file.relative_to(user_base_dir)),
                                'size': file_size,
                                'size_kb': f"{file_size / 1024:.1f} KB",
                                'method': 'direct_pandoc'
                            }
                        }
                    }
                else:
                    return {
                        'status': 'failed',
                        'markdown_file': file_path,
                        'error': f'LaTeX conversion failed: {result.stderr if result.stderr else "Unknown error"}'
                    }
        else:
            return {
                'status': 'failed',
                'markdown_file': file_path,
                'error': 'trans_md_to_pdf.py script not found'
            }
            
    except Exception as e:
        return {
            'status': 'failed',
            'markdown_file': file_path,
            'error': f'LaTeX conversion exception: {str(e)}'
        }


@app.route('/api/convert-markdown', methods=['POST'])
def convert_markdown():
    """Convert Markdown files to Word and PDF formats"""
    try:
        data = request.get_json()
        file_path = data.get('file_path')
        format_type = data.get('format', 'both')  # 'word', 'pdf', 'latex', or 'both'
        
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        if not file_path:
            return jsonify({'success': False, 'error': 'File path cannot be empty'})
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly
        full_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            return jsonify({'success': False, 'error': f'File does not exist: {file_path}'})
        
        # Check if it's a markdown file
        _, ext = os.path.splitext(full_path.lower())
        if ext not in ['.md', '.markdown']:
            return jsonify({'success': False, 'error': 'Only supports Markdown file conversion'})
        
        # Create Tools instance directly to access FileSystemTools
        from src.tools import Tools
        tools = Tools(
            workspace_root=user_base_dir,
            out_dir=user_base_dir
        )
        
        # Call the conversion method from FileSystemTools
        
        # Handle LaTeX conversion separately if requested
        if format_type == 'latex':
            conversion_result = convert_markdown_to_latex_only(full_path, file_path, user_base_dir)
        else:
            conversion_result = tools._convert_markdown_to_formats(full_path, file_path, format_type)
        
        
        if conversion_result.get('status') == 'success':
            # Check for partial success (some conversions failed)
            conversions = conversion_result.get('conversions', {})
            failed_conversions = [k for k, v in conversions.items() if v.get('status') == 'failed']
            
            response_data = {
                'success': True,
                'message': 'Conversion completed',
                'conversions': conversions,
                'converted_files': []
            }
            
            # Add warnings for failed conversions
            if failed_conversions:
                warnings = []
                for conv_type in failed_conversions:
                    conv_error = conversions[conv_type].get('error', 'Unknown error')
                    if 'Cannot load file' in conv_error or 'Invalid' in conv_error:
                        warnings.append(f'{conv_type.upper()} conversion failed due to image format issues. Consider converting WebP/TIFF images to PNG/JPEG.')
                    elif 'Cannot determine size' in conv_error or 'BoundingBox' in conv_error:
                        warnings.append(f'{conv_type.upper()} conversion failed due to image size/boundary issues.')
                    elif 'PDF engines' in conv_error:
                        warnings.append(f'{conv_type.upper()} conversion failed: No PDF engines available. Install xelatex, lualatex, pdflatex, wkhtmltopdf, or weasyprint.')
                    else:
                        warnings.append(f'{conv_type.upper()} conversion failed: {conv_error}')
                
                response_data['warnings'] = warnings
                response_data['partial_success'] = True
            
            return jsonify(response_data)
        else:
            error_msg = conversion_result.get('error', 'Conversion failed')
            user_friendly_error = error_msg
            suggestions = []
            
            # Provide user-friendly error messages and suggestions
            if 'Cannot load file' in error_msg or 'Invalid' in error_msg:
                user_friendly_error = 'Image format compatibility issues detected'
                suggestions.append('Convert WebP, TIFF, or other incompatible images to PNG or JPEG format')
                suggestions.append('Remove or replace problematic images')
            elif 'Cannot determine size' in error_msg or 'BoundingBox' in error_msg:
                user_friendly_error = 'Image size or boundary issues detected'
                suggestions.append('Ensure images have valid dimensions and formats')
                suggestions.append('Try resaving images in a standard format like PNG')
            elif 'PDF engines' in error_msg:
                user_friendly_error = 'PDF conversion engines not available'
                suggestions.append('Install LaTeX (xelatex, lualatex, pdflatex) for high-quality PDF output')
                suggestions.append('Install wkhtmltopdf or weasyprint as alternatives')
                suggestions.append('Word document conversion may still work as a fallback')
            
            return jsonify({
                'success': False,
                'error': user_friendly_error,
                'original_error': error_msg,
                'suggestions': suggestions,
                'message': conversion_result.get('message', 'Conversion failed')
            })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'Error occurred during conversion: {str(e)}'})

@app.route('/api/convert-mermaid-to-images', methods=['POST'])
def convert_mermaid_to_images():
    """Convert Mermaid chart to SVG and PNG images"""
    try:
        data = request.get_json()
        file_path = data.get('file_path')
        mermaid_content = data.get('mermaid_content')
        
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        if not file_path:
            return jsonify({'success': False, 'error': 'File path cannot be empty'})
        
        if not mermaid_content:
            return jsonify({'success': False, 'error': 'Mermaid content cannot be empty'})
        
        if not MERMAID_PROCESSOR_AVAILABLE:
            return jsonify({'success': False, 'error': 'Mermaid processor not available'})
        
        # URL decode the file path to handle Chinese characters
        import urllib.parse
        file_path = urllib.parse.unquote(file_path)
        
        # Use the passed path directly
        full_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure path is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        
        if not os.path.exists(full_path) or not os.path.isfile(full_path):
            return jsonify({'success': False, 'error': f'File does not exist: {file_path}'})
        
        # Check if it's a mermaid file
        _, ext = os.path.splitext(full_path.lower())
        if ext not in ['.mmd']:
            return jsonify({'success': False, 'error': 'Only supports .mmd file conversion'})
        
        # Generate base filename from original file (without extension)
        base_name = os.path.splitext(os.path.basename(full_path))[0]
        file_dir = os.path.dirname(full_path)

        # Check if we're already in an images directory
        # If so, use the current directory to avoid nested images folders
        if os.path.basename(file_dir).lower() == 'images':
            images_dir = file_dir
        else:
            # Create images directory if it doesn't exist
            images_dir = os.path.join(file_dir, 'images')
            os.makedirs(images_dir, exist_ok=True)
        
        # Generate output paths
        svg_path = os.path.join(images_dir, f"{base_name}.svg")
        png_path = os.path.join(images_dir, f"{base_name}.png")
        
        
        # Use mermaid processor to generate images
        from pathlib import Path
        svg_success, png_success = mermaid_processor._generate_mermaid_image(
            mermaid_content, 
            Path(svg_path), 
            Path(png_path)
        )
        
        if svg_success or png_success:
            i18n = get_i18n_texts()
            result = {
                'success': True,
                'message': i18n['mermaid_conversion_completed']
            }
            
            if svg_success:
                rel_svg_path = os.path.relpath(svg_path, user_base_dir)
                result['svg_path'] = rel_svg_path
                result['svg_full_path'] = svg_path
            
            if png_success:
                rel_png_path = os.path.relpath(png_path, user_base_dir)
                result['png_path'] = rel_png_path
                result['png_full_path'] = png_path
                
            if svg_success and png_success:
                result['message'] += i18n['mermaid_svg_png_format']
            elif svg_success:
                result['message'] += i18n['mermaid_svg_only']
            elif png_success:
                result['message'] += i18n['mermaid_png_only']
            
            return jsonify(result)
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to generate images from Mermaid chart'
            })
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'Error occurred during conversion: {str(e)}'})

@app.route('/api/metrics')
def get_performance_metrics():
    """Get current performance metrics"""
    try:
        metrics = gui_instance.concurrency_manager.get_metrics()
        
        # Add system resource information
        import psutil
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        
        system_metrics = {
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'memory_used_mb': memory.used / 1024 / 1024,
            'memory_total_mb': memory.total / 1024 / 1024
        }
        
        return jsonify({
            'success': True,
            'metrics': metrics,
            'system': system_metrics,
            'timestamp': time.time()
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@socketio.on('connect')
def handle_connect(auth):
    """WebSocket connection processing with authentication"""
    i18n = get_i18n_texts()
    session_id = request.sid
    
    # Check if new connections can be accepted
    if not gui_instance.concurrency_manager.can_accept_connection():
        emit('connection_rejected', {
            'message': 'Server connection limit reached'
        }, room=session_id)
        return False
    
    # Get user authentication info
    api_key = None
    if auth and 'api_key' in auth:
        api_key = auth['api_key']
    
    # Create or get user session with authentication
    user_session = gui_instance.get_user_session(session_id, api_key)
    
    if not user_session:
        # Authentication failed
        emit('auth_failed', {'message': 'Authentication failed. Please check your API key.'}, room=session_id)
        return False
    
    # Add connection to concurrency manager
    if not gui_instance.concurrency_manager.add_connection():
        emit('connection_rejected', {
            'message': 'Server connection limit reached'
        }, room=session_id)
        return False
    
    # Create user directory if not exists
    user_dir = user_session.get_user_directory(gui_instance.base_data_dir)
    os.makedirs(user_dir, exist_ok=True)
    
    # Join user to their own room for isolated communication
    join_room(session_id)
    
    # Send connection status with user info
    is_guest = user_session.user_info.get("is_guest", False)
    user_name = user_session.user_info.get("name", "unknown")
    
    # Get current performance metrics
    metrics = gui_instance.concurrency_manager.get_metrics()
    
    
    # Send status with guest indicator and performance info
    connection_data = {
        'message': i18n['connected'],
        'is_guest': is_guest,
        'user_name': user_name,
        'user_info': user_session.user_info,
        'server_metrics': {
            'active_connections': metrics['active_connections'],
            'active_tasks': metrics['active_tasks'],
            'queue_size': metrics['queue_size']
        }
    }
    
    emit('status', connection_data, room=session_id)

@socketio.on('disconnect')
def handle_disconnect():
    """Handle user disconnection"""
    session_id = request.sid

    # Remove connection from concurrency manager
    gui_instance.concurrency_manager.remove_connection()

    if session_id in gui_instance.user_sessions:
        user_session = gui_instance.user_sessions[session_id]

        # Leave room and clean up session immediately
        try:
            leave_room(session_id)
        except Exception:
            pass

        # Terminate any running processes
        if user_session.current_process and user_session.current_process.is_alive():
            try:
                user_session.current_process.terminate()
                user_session.current_process.join(timeout=5)
            except Exception:
                pass

        # Clean up active task if exists
        try:
            gui_instance.concurrency_manager.finish_task(session_id, success=False)
        except Exception:
            pass

        # Clean up session
        try:
            gui_instance.auth_manager.destroy_session(session_id)
            del gui_instance.user_sessions[session_id]
        except Exception:
            pass

        # Get updated metrics
        try:
            metrics = gui_instance.concurrency_manager.get_metrics()
        except Exception:
            pass
    else:
        pass

@socketio.on('heartbeat')
def handle_heartbeat(data):
    """Handle heartbeat from client to keep connection alive"""
    session_id = request.sid
    # æ›´æ–°ä¼šè¯çš„æœ€åè®¿é—®æ—¶é—´ï¼Œé˜²æ­¢ä¼šè¯è¶…æ—¶
    if session_id in gui_instance.user_sessions:
        # éªŒè¯å¹¶æ›´æ–°ä¼šè¯ï¼Œè¿™ä¼šæ›´æ–°last_accessedæ—¶é—´
        gui_instance.auth_manager.validate_session(session_id)
    # å‘é€å¿ƒè·³å“åº”ï¼Œç¡®è®¤è¿æ¥æ­£å¸¸
    emit('heartbeat_ack', {'timestamp': data.get('timestamp', 0), 'server_time': time.time()}, room=session_id)

@socketio.on('execute_task')
def handle_execute_task(data):
    """Handle task execution request"""
    # Get language from gui_config if available, otherwise use default
    gui_config = data.get('gui_config', {})
    user_lang = gui_config.get('language', get_language())
    i18n = I18N_TEXTS.get(user_lang, I18N_TEXTS['en'])
    session_id = request.sid
    
    # Get user session
    if session_id not in gui_instance.user_sessions:
        emit('error', {'message': 'User session not found'}, room=session_id)
        return
    
    user_session = gui_instance.user_sessions[session_id]
    
    if user_session.current_process and user_session.current_process.is_alive():
        emit('error', {'message': i18n['error_task_running']}, room=session_id)
        return

    user_requirement = data.get('requirement', '')
    # Allow empty requirement to start the program
    
    task_type = data.get('type', 'continue')  # 'new', 'continue', 'selected'
    # Ensure plan_mode is boolean (handle string 'true'/'false' from frontend)
    plan_mode_raw = data.get('plan_mode', False)
    if isinstance(plan_mode_raw, str):
        plan_mode = plan_mode_raw.lower() in ('true', '1', 'yes')
    else:
        plan_mode = bool(plan_mode_raw)
    selected_directory = data.get('selected_directory')  # Directory name from frontend
    gui_config = data.get('gui_config', {})  # GUI configuration options
    attached_files = data.get('attached_files', [])  # Attached file information
    
    # Generate detailed requirement with conversation history for continuing tasks
    detailed_requirement = None
    if task_type in ['continue', 'selected'] and user_session.conversation_history:
        # For continue/selected tasks, include conversation context
        history_context = user_session.get_summarized_requirements()
        if history_context:
            # ğŸ”§ Fix: adjust prompt order - current first
            detailed_requirement = f"Current request: {user_requirement}\n\nPrevious conversation context:\n{history_context}"
    
    # Get user's base directory
    user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
    

    
    if task_type == 'new':
        # New task: create new output directory
        out_dir = None
        continue_mode = False
    elif task_type == 'selected':
        # Use selected directory - prioritize frontend passed directory name
        target_dir_name = selected_directory or user_session.selected_output_dir
        if target_dir_name:
            out_dir = os.path.join(user_base_dir, target_dir_name)
            # Update backend state to match frontend
            user_session.selected_output_dir = target_dir_name
        else:
            # ğŸ”§ Fix: if user selected selected mode but didn't specify directory
            emit('error', {'message': i18n['select_directory_first']}, room=session_id)
            return
        # Check if selected directory is newly created (not in last_output_dir)
        # If it's a new directory, should use continue_mode=False
        if target_dir_name != user_session.last_output_dir:
            continue_mode = False  # New directory, don't continue previous work
        else:
            continue_mode = True   # Existing directory, continue previous work
    else:
        # Continue mode: use last output directory - convert to absolute path
        if user_session.last_output_dir:
            out_dir = os.path.join(user_base_dir, user_session.last_output_dir)
        else:
            out_dir = None
        continue_mode = True
        
        # ğŸ”§ Fix: if user didn't select directory and there's no last used directory
        if not out_dir and not user_session.selected_output_dir:
            emit('error', {'message': i18n['select_directory_first']}, room=session_id)
            return
    
    # Check if new tasks can be started
    if not gui_instance.concurrency_manager.can_start_task(session_id):
        emit('task_queued', {
            'message': 'Current server tasks are busy...',
            'queue_position': gui_instance.concurrency_manager.task_queue.qsize() + 1
        }, room=session_id)
        return
    
    user_session.output_queue = multiprocessing.Queue()
    user_session.input_queue = multiprocessing.Queue()  # Queue for user input in GUI mode
    
    # Get user ID (sha256_hash) for MCP knowledge base tools
    user_id = None
    if user_session.api_key:
        import hashlib
        user_id = hashlib.sha256(user_session.api_key.encode()).hexdigest()
    
    # ğŸ¯ Send immediate feedback to user
    emit('output', {
        'message': i18n.get('task_emitted', 'âœ… Task Emitted'),
        'type': 'system'
    }, room=session_id)
    
    try:
        # ğŸš€ Create and start process with highest priority (minimize delay)
        user_session.current_process = multiprocessing.Process(
            target=execute_agia_task_process_target,
            args=(user_requirement, user_session.output_queue, user_session.input_queue, out_dir, continue_mode, plan_mode, gui_config, session_id, detailed_requirement, user_id, attached_files)
        )
        user_session.current_process.daemon = True
        user_session.current_process.start()
        
        # Get current performance metrics
        metrics = gui_instance.concurrency_manager.get_metrics()
        
        # Start queue reader thread after process is confirmed started
        # Messages will be buffered in queue, so slight delay is fine
        threading.Thread(target=queue_reader_thread, args=(session_id,), daemon=True).start()
        
    except Exception as e:
        # If process startup fails
        gui_instance.concurrency_manager.finish_task(session_id, success=False)
        emit('error', {'message': f'Task startup failed: {str(e)}'}, room=session_id)
        return
    
    # Set current output directory name (extract from absolute path if needed)
    if out_dir:
        user_session.current_output_dir = os.path.basename(out_dir)
    else:
        user_session.current_output_dir = None
    
    # Store current task for conversation history
    user_session._current_task_requirement = user_requirement

@socketio.on('user_input_response')
def handle_user_input_response(data):
    """Handle user input response from GUI"""
    session_id = request.sid
    
    if session_id not in gui_instance.user_sessions:
        return
    
    user_session = gui_instance.user_sessions[session_id]
    user_input = data.get('input', '')
    
    # Put user input into the input queue
    if user_session.input_queue:
        try:
            user_session.input_queue.put(user_input)
        except Exception as e:
            emit('error', {'message': f'Failed to send user input: {str(e)}'}, room=session_id)

@socketio.on('select_directory')
def handle_select_directory(data):
    """Handle directory selection request"""
    session_id = request.sid
    if session_id not in gui_instance.user_sessions:
        return
    
    user_session = gui_instance.user_sessions[session_id]
    dir_name = data.get('dir_name', '')
    if dir_name:
        user_session.selected_output_dir = dir_name
        emit('directory_selected', {'dir_name': dir_name}, room=session_id)
    else:
        user_session.selected_output_dir = None
        emit('directory_selected', {'dir_name': None}, room=session_id)

@socketio.on('append_task')
def handle_append_task(data):
    """Handle append task request - add user request to manager inbox (multi-agent mode only)"""
    session_id = request.sid
    if session_id not in gui_instance.user_sessions:
        emit('error', {'message': 'Session not found'}, room=session_id)
        return
    
    user_session = gui_instance.user_sessions[session_id]
    content = data.get('content', '').strip()
    
    if not content:
        emit('error', {'message': 'Task content cannot be empty'}, room=session_id)
        return
    
    try:
        # Get current output directory
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        output_dir = None
        
        if user_session.current_output_dir:
            output_dir = os.path.join(user_base_dir, user_session.current_output_dir)
        elif user_session.selected_output_dir:
            output_dir = os.path.join(user_base_dir, user_session.selected_output_dir)
        elif user_session.last_output_dir:
            output_dir = os.path.join(user_base_dir, user_session.last_output_dir)
        
        if not output_dir or not os.path.exists(output_dir):
            emit('error', {'message': 'No valid output directory found. Please start a task first.'}, room=session_id)
            return
        
        # Import functions from add_user_request.py
        import re
        from datetime import datetime
        
        # Find next extmsg ID
        inbox_dir = os.path.join(output_dir, "mailboxes", "manager", "inbox")
        os.makedirs(inbox_dir, exist_ok=True)
        
        max_id = 0
        pattern = re.compile(r'extmsg_(\d+)\.json')
        
        if os.path.exists(inbox_dir):
            for filename in os.listdir(inbox_dir):
                match = pattern.match(filename)
                if match:
                    msg_id = int(match.group(1))
                    max_id = max(max_id, msg_id)
        
        next_id = max_id + 1
        message_id = f"extmsg_{next_id:06d}"
        
        # Create message object
        message = {
            "message_id": message_id,
            "sender_id": "user",
            "receiver_id": "manager",
            "message_type": "collaboration",
            "content": {
                "text": content
            },
            "priority": 2,
            "requires_response": False,
            "timestamp": datetime.now().isoformat(),
            "delivered": False,
            "read": False
        }
        
        # Write message file
        file_path = os.path.join(inbox_dir, f"{message_id}.json")
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(message, f, indent=2, ensure_ascii=False)
        
        emit('append_task_success', {
            'message': f'Task appended successfully',
            'message_id': message_id,
            'file_path': file_path
        }, room=session_id)
        
    except Exception as e:
        emit('error', {'message': f'Failed to append task: {str(e)}'}, room=session_id)

@socketio.on('get_metrics')
def handle_get_metrics():
    """Handle real-time metrics request"""
    session_id = request.sid
    try:
        metrics = gui_instance.concurrency_manager.get_metrics()
        
        # Add current user's task running time
        runtime = gui_instance.concurrency_manager.get_task_runtime(session_id)
        
        # Add system resource information (lightweight)
        import psutil
        cpu_percent = psutil.cpu_percent(interval=0)  # Don't wait
        memory = psutil.virtual_memory()
        
        response_data = {
            'metrics': metrics,
            'system': {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent
            },
            'user_task_runtime': runtime,
            'timestamp': time.time()
        }
        
        emit('metrics_update', response_data, room=session_id)
    except Exception as e:
        emit('error', {'message': f'Failed to get performance metrics: {str(e)}'}, room=session_id)

@socketio.on('stop_task')
def handle_stop_task(data=None):
    """Handle stop task request with force option"""
    i18n = get_i18n_texts()
    session_id = request.sid
    
    if session_id not in gui_instance.user_sessions:
        return
    
    user_session = gui_instance.user_sessions[session_id]
    
    # Check if force stop is requested
    force_stop = False
    if data and isinstance(data, dict):
        force_stop = data.get('force', False)
    
    if user_session.current_process and user_session.current_process.is_alive():
        # ğŸ”§ Fix: save current conversation to history when stopping task
        if hasattr(user_session, '_current_task_requirement'):
            user_session.add_to_conversation_history(
                user_session._current_task_requirement,
                "Task stopped by user"
            )
            delattr(user_session, '_current_task_requirement')

        try:
            if force_stop:
                # Force kill the process immediately
                user_session.current_process.kill()
                emit('output', {'message': 'ğŸ›‘ å¼ºåˆ¶åœæ­¢ä»»åŠ¡ä¸­...', 'type': 'warning'}, room=session_id)
            else:
                # Try graceful termination first
                user_session.current_process.terminate()
                emit('output', {'message': 'â¹ï¸ æ­£åœ¨åœæ­¢ä»»åŠ¡...', 'type': 'info'}, room=session_id)
                
                # Wait a short time for graceful termination
                import time
                time.sleep(0.5)
                
                # If still alive after 0.5 seconds, force kill
                if user_session.current_process and user_session.current_process.is_alive():
                    user_session.current_process.kill()
                    emit('output', {'message': 'ğŸ›‘ ä»»åŠ¡æœªå“åº”ï¼Œå·²å¼ºåˆ¶åœæ­¢', 'type': 'warning'}, room=session_id)
        except Exception as e:
            # If terminate/kill fails, try to find and kill child processes
            try:
                import psutil
                import os
                if user_session.current_process and hasattr(user_session.current_process, 'pid'):
                    parent = psutil.Process(user_session.current_process.pid)
                    for child in parent.children(recursive=True):
                        try:
                            child.kill()
                        except:
                            pass
                    try:
                        parent.kill()
                    except:
                        pass
            except:
                pass
            
            emit('output', {'message': f'âš ï¸ åœæ­¢ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}', 'type': 'error'}, room=session_id)
        
        user_session.current_output_dir = None  # Clear current directory mark

        # ğŸ”§ Fix: Clean up active task to prevent timeout detection
        if hasattr(gui_instance, 'finish_task'):
            gui_instance.finish_task(session_id, success=False)

        emit('task_stopped', {'message': i18n['task_stopped'], 'type': 'error'}, room=session_id)
    else:
        emit('output', {'message': i18n['no_task_running'], 'type': 'info'}, room=session_id)

@socketio.on('create_new_directory')
def handle_create_new_directory(data=None):
    """Handle create new directory request"""
    session_id = request.sid
    
    try:
        # Check if session exists
        if session_id not in gui_instance.user_sessions:
            # Get language from data if available, otherwise use default
            user_lang = data.get('language', get_language()) if data else get_language()
            i18n = I18N_TEXTS.get(user_lang, I18N_TEXTS['en'])
            emit('directory_created', {
                'success': False,
                'error': i18n.get('session_not_found', 'Session not found. Please reconnect.')
            }, room=session_id)
            return
        
        user_session = gui_instance.user_sessions[session_id]
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Get language from data if available, otherwise use default
        user_lang = data.get('language', get_language()) if data else get_language()
        i18n = I18N_TEXTS.get(user_lang, I18N_TEXTS['en'])
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        new_dir_name = f"output_{timestamp}"
        new_dir_path = os.path.join(user_base_dir, new_dir_name)
        
        # Create main directory
        os.makedirs(new_dir_path, exist_ok=True)
        
        # Create workspace subdirectory
        workspace_dir = os.path.join(new_dir_path, 'workspace')
        os.makedirs(workspace_dir, exist_ok=True)
        
        # Set as currently selected directory
        user_session.selected_output_dir = new_dir_name
        
        # Clear conversation history when creating new workspace
        user_session.conversation_history.clear()
        
        emit('directory_created', {
            'dir_name': new_dir_name,
            'success': True,
            'message': i18n['directory_created_with_workspace'].format(new_dir_name)
        }, room=session_id)
        
    except Exception as e:
        # Get language from data if available, otherwise use default
        user_lang = data.get('language', get_language()) if data else get_language()
        i18n = I18N_TEXTS.get(user_lang, I18N_TEXTS['en'])
        emit('directory_created', {
            'success': False,
            'error': str(e)
        }, room=session_id)

@socketio.on('clear_chat')
def handle_clear_chat():
    """Handle clear chat request"""
    session_id = request.sid
    if session_id not in gui_instance.user_sessions:
        return
    
    try:
        i18n = get_i18n_texts()
        
        # Clear server-side conversation history
        user_session = gui_instance.user_sessions[session_id]
        user_session.conversation_history.clear()
        
        emit('chat_cleared', {
            'success': True,
            'message': i18n['chat_cleared']
        }, room=session_id)
        
    except Exception as e:
        emit('chat_cleared', {
            'success': False,
            'error': str(e)
        }, room=session_id)

@app.route('/api/refresh-dirs', methods=['POST'])
def refresh_directories():
    """Manually refresh directory list"""
    try:
        i18n = get_i18n_texts()
        
        # Get API key from JSON data, query parameters or headers
        api_key = None
        if request.json:
            api_key = request.json.get('api_key')
        if not api_key:
            api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        
        # Use existing method to get directory list for this user
        directories = gui_instance.get_output_directories(user_session)
        return jsonify({
            'success': True,
            'directories': directories,
            'message': i18n['directory_list_refreshed']
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/file-count/<path:dir_name>', methods=['GET'])
def get_file_count(dir_name):
    """Get file count in specified directory's workspace folder"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Security check: normalize path and prevent path traversal
        # Don't use secure_filename as it destroys Chinese characters
        normalized_dir_name = os.path.normpath(dir_name)
        if '..' in normalized_dir_name or normalized_dir_name.startswith('/'):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'}), 403
        
        # Target directory path
        target_dir = os.path.join(user_base_dir, normalized_dir_name)
        
        # Security check: ensure directory is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_target_dir = os.path.realpath(target_dir)
        if not real_target_dir.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'}), 403
        
        if not os.path.exists(target_dir):
            return jsonify({
                'success': False,
                'error': 'Directory not found'
            }), 404
        
        # workspace directory path
        workspace_dir = os.path.join(target_dir, 'workspace')
        if not os.path.exists(workspace_dir):
            return jsonify({
                'success': True,
                'file_count': 0
            })
        
        # Count files recursively in workspace directory
        file_count = 0
        for root, dirs, files in os.walk(workspace_dir):
            file_count += len(files)
        
        return jsonify({
            'success': True,
            'file_count': file_count
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# File upload functionality
@app.route('/agent-status-visualizer')
def agent_status_visualizer():
    """Serve agent status visualizer page"""
    if not AGENT_VISUALIZER_AVAILABLE:
        return "Agent status visualizer is not available", 404
    
    # Get API key from query parameters or headers
    api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
    temp_session_id = create_temp_session_id(request, api_key)
    user_session = gui_instance.get_user_session(temp_session_id, api_key)
    if not user_session:
        return "Authentication failed. Please provide a valid API key.", 401
    user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
    
    # Get directory from query parameter (selected directory)
    dir_name = request.args.get('dir')
    
    # Try to find the output directory
    output_dir = None
    if dir_name:
        # Use the selected directory from query parameter
        # Ensure dir_name doesn't already contain user directory path
        # If it does, extract just the directory name
        if os.path.sep in dir_name or '/' in dir_name:
            # dir_name might contain user directory, extract just the basename
            dir_name = os.path.basename(dir_name)
        output_dir = os.path.join(user_base_dir, dir_name)
        if not os.path.exists(output_dir):
            return f"Directory not found: {dir_name} (searched in: {user_base_dir})", 404
    elif user_session.current_output_dir:
        output_dir = os.path.join(user_base_dir, user_session.current_output_dir)
    elif user_session.last_output_dir:
        output_dir = os.path.join(user_base_dir, user_session.last_output_dir)
    else:
        # Try to find latest output directory
        latest_dir = find_latest_output_dir(user_base_dir)
        if latest_dir:
            output_dir = latest_dir
    
    # Read agent_status_visualizer.html from templates directory
    html_path = os.path.join(template_dir, 'agent_status_visualizer.html')
    
    if not os.path.exists(html_path):
        return f"Agent status visualizer HTML not found at {html_path}", 404
    
    try:
        with open(html_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # Replace API endpoints to use new routes
        # Use regex to replace more accurately
        html_content = re.sub(r"'/api/status'", "'/api/agent-status'", html_content)
        html_content = re.sub(r'"/api/status"', '"/api/agent-status"', html_content)
        html_content = re.sub(r"'/api/reload'", "'/api/agent-status-reload'", html_content)
        html_content = re.sub(r'"/api/reload"', '"/api/agent-status-reload"', html_content)
        html_content = re.sub(r"'/api/files/", "'/api/agent-status-files/", html_content)
        html_content = re.sub(r'"/api/files/', '"/api/agent-status-files/', html_content)
        
        # Inject JavaScript to get dir and api_key parameters from URL and pass them to API calls
        dir_param = dir_name if dir_name else ''
        api_key_param = api_key if api_key else ''
        inject_script = f"""
        <script>
            // Get directory and API key parameters from URL
            const urlParams = new URLSearchParams(window.location.search);
            const dirParam = urlParams.get('dir') || '{dir_param}';
            const apiKeyParam = urlParams.get('api_key') || '{api_key_param}';
            
            // Override fetch to automatically add dir and api_key parameters to API calls
            const originalFetch = window.fetch;
            window.fetch = function(url, options) {{
                if (typeof url === 'string') {{
                    // Handle agent-status related API calls
                    if (url.includes('/api/agent-status') || url.includes('/api/reload') || url.includes('/api/files/')) {{
                        const urlObj = new URL(url, window.location.origin);
                        if (dirParam && !urlObj.searchParams.has('dir')) {{
                            urlObj.searchParams.set('dir', dirParam);
                        }}
                        if (apiKeyParam && !urlObj.searchParams.has('api_key')) {{
                            urlObj.searchParams.set('api_key', apiKeyParam);
                        }}
                        url = urlObj.toString();
                    }}
                }}
                return originalFetch.call(this, url, options);
            }};
        </script>
        """
        
        # Insert the script before closing </head> tag
        html_content = html_content.replace('</head>', inject_script + '</head>')
        
        return html_content, 200, {'Content-Type': 'text/html; charset=utf-8'}
    except Exception as e:
        return f"Error loading agent status visualizer: {str(e)}", 500

@app.route('/api/agent-status')
def agent_status_api():
    """API endpoint to get current agent statuses and messages"""
    if not AGENT_VISUALIZER_AVAILABLE:
        return jsonify({'error': 'Agent status visualizer not available'}), 404
    
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        if not user_session:
            return jsonify({'error': 'Authentication failed. Please provide a valid API key.'}), 401
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Get directory from query parameter (selected directory)
        dir_name = request.args.get('dir')
        
        # Try to find the output directory
        output_dir = None
        if dir_name:
            # Use the selected directory from query parameter
            # Ensure dir_name doesn't already contain user directory path
            # If it does, extract just the directory name
            if os.path.sep in dir_name or '/' in dir_name:
                # dir_name might contain user directory, extract just the basename
                dir_name = os.path.basename(dir_name)
            output_dir = os.path.join(user_base_dir, dir_name)
            if not os.path.exists(output_dir):
                return jsonify({'error': f'Directory not found: {dir_name} (searched in: {user_base_dir})'}), 404
        elif user_session.current_output_dir:
            output_dir = os.path.join(user_base_dir, user_session.current_output_dir)
        elif user_session.last_output_dir:
            output_dir = os.path.join(user_base_dir, user_session.last_output_dir)
        else:
            # Try to find latest output directory
            latest_dir = find_latest_output_dir(user_base_dir)
            if latest_dir:
                output_dir = latest_dir
        
        if not output_dir or not os.path.exists(output_dir):
            return jsonify({
                'error': 'Output directory not found',
                'agents': {},
                'messages': [],
                'agent_ids': [],
                'output_directory': output_dir or 'æœªè®¾ç½®',
                'timestamp': datetime.now().isoformat()
            }), 404
        
        # Load all agent statuses
        status_files = find_status_files(output_dir)
        agent_statuses = {}
        
        for status_file in status_files:
            status_data = load_status_file(status_file)
            if status_data:
                agent_id = status_data.get('agent_id', 'unknown')
                agent_statuses[agent_id] = status_data
        
        # Also add manager if not present
        if 'manager' not in agent_statuses:
            agent_statuses['manager'] = {
                'agent_id': 'manager',
                'status': 'running',
                'current_loop': 0
            }
        
        # Load all messages
        messages = find_message_files(output_dir)
        sorted_messages = sorted(messages, key=lambda x: x.get('timestamp', '') or '')
        
        # Load tool calls from log files
        tool_calls = find_tool_calls_from_logs(output_dir)
        
        # Load mermaid figures from plan.md
        mermaid_figures = find_mermaid_figures_from_plan(output_dir)
        
        # Load status updates from status files
        status_updates = find_status_updates(output_dir)
        
        # Get all unique agent IDs
        agent_ids = set(agent_statuses.keys())
        for msg in messages:
            agent_ids.add(msg.get('sender_id', ''))
            agent_ids.add(msg.get('receiver_id', ''))
        agent_ids = sorted([aid for aid in agent_ids if aid])
        
        return jsonify({
            'agents': agent_statuses,
            'messages': sorted_messages,
            'tool_calls': tool_calls,
            'status_updates': status_updates,
            'mermaid_figures': mermaid_figures,
            'agent_ids': agent_ids,
            'output_directory': output_dir,
            'timestamp': datetime.now().isoformat(),
            'message_count': len(sorted_messages)
        })
    except Exception as e:
        import traceback
        error_msg = str(e)
        traceback.print_exc()
        return jsonify({
            'error': f'Error loading status: {error_msg}',
            'agents': {},
            'messages': [],
            'agent_ids': [],
            'output_directory': 'Error',
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/api/agent-status-reload', methods=['POST'])
def agent_status_reload():
    """API endpoint to reload and find the latest output directory"""
    if not AGENT_VISUALIZER_AVAILABLE:
        return jsonify({'success': False, 'message': 'Agent status visualizer not available'}), 404
    
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        if not user_session:
            return jsonify({'error': 'Authentication failed. Please provide a valid API key.'}), 401
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Get directory from query parameter (selected directory)
        dir_name = request.args.get('dir')
        
        # If dir parameter is provided, use it; otherwise find latest
        if dir_name:
            # Ensure dir_name doesn't already contain user directory path
            # If it does, extract just the directory name
            if os.path.sep in dir_name or '/' in dir_name:
                # dir_name might contain user directory, extract just the basename
                dir_name = os.path.basename(dir_name)
            new_output_dir = os.path.join(user_base_dir, dir_name)
            if not os.path.exists(new_output_dir):
                return jsonify({
                    'success': False,
                    'message': f'Directory not found: {dir_name} (searched in: {user_base_dir})',
                    'output_directory': 'Not set'
                }), 404
        else:
            # Find latest output directory
            new_output_dir = find_latest_output_dir(user_base_dir)
        
        if new_output_dir and os.path.exists(new_output_dir):
            # Update user session's last output dir
            rel_path = os.path.relpath(new_output_dir, user_base_dir)
            user_session.last_output_dir = rel_path
            
            return jsonify({
                'success': True,
                'output_directory': new_output_dir,
                'message': f'Reloaded: {os.path.basename(new_output_dir)}'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'No output directory found',
                'output_directory': 'Not set'
            }), 404
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'Error: {str(e)}'
        }), 500

@app.route('/api/agent-status-files/<path:path>')
def agent_status_files(path):
    """Serve files from output directory (for mermaid images)"""
    if not AGENT_VISUALIZER_AVAILABLE:
        return jsonify({'error': 'Agent status visualizer not available'}), 404
    
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        if not user_session:
            return jsonify({'error': 'Authentication failed. Please provide a valid API key.'}), 401
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Get directory from query parameter (selected directory)
        dir_name = request.args.get('dir')
        
        # Try to find the output directory
        output_dir = None
        if dir_name:
            # Use the selected directory from query parameter
            # Ensure dir_name doesn't already contain user directory path
            # If it does, extract just the directory name
            if os.path.sep in dir_name or '/' in dir_name:
                # dir_name might contain user directory, extract just the basename
                dir_name = os.path.basename(dir_name)
            output_dir = os.path.join(user_base_dir, dir_name)
            if not os.path.exists(output_dir):
                return jsonify({'error': f'Directory not found: {dir_name} (searched in: {user_base_dir})'}), 404
        elif user_session.current_output_dir:
            # Ensure current_output_dir doesn't already contain user directory path
            current_dir = user_session.current_output_dir
            if os.path.sep in current_dir or '/' in current_dir:
                current_dir = os.path.basename(current_dir)
            output_dir = os.path.join(user_base_dir, current_dir)
        elif user_session.last_output_dir:
            # Ensure last_output_dir doesn't already contain user directory path
            last_dir = user_session.last_output_dir
            if os.path.sep in last_dir or '/' in last_dir:
                last_dir = os.path.basename(last_dir)
            output_dir = os.path.join(user_base_dir, last_dir)
        else:
            latest_dir = find_latest_output_dir(user_base_dir)
            if latest_dir:
                output_dir = latest_dir
        
        if not output_dir:
            return jsonify({'error': 'Output directory not set'}), 404
        
        # Construct full path
        file_path = os.path.join(output_dir, path)
        
        # Security check: ensure path is within OUTPUT_DIR
        real_output_dir = os.path.realpath(output_dir)
        real_file_path = os.path.realpath(file_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'error': 'Invalid path'}), 403
        
        if not os.path.exists(file_path):
            return jsonify({'error': 'File not found'}), 404
        
        return send_from_directory(output_dir, path)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/upload/<path:dir_name>', methods=['POST'])
def upload_files(dir_name):
    """Upload files to workspace of specified directory"""
    try:
        i18n = get_i18n_texts()
        
        # Get API key from form data, query parameters or headers
        api_key = request.form.get('api_key') or request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        if 'files' not in request.files:
            return jsonify({'success': False, 'error': i18n['no_files_selected']})
        
        files = request.files.getlist('files')
        if not files or all(f.filename == '' for f in files):
            return jsonify({'success': False, 'error': i18n['no_valid_files']})
        
        # Security check: normalize path and prevent path traversal
        # Don't use secure_filename as it destroys Chinese characters
        normalized_dir_name = os.path.normpath(dir_name)
        if '..' in normalized_dir_name or normalized_dir_name.startswith('/'):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        # Target directory path
        target_dir = os.path.join(user_base_dir, normalized_dir_name)
        
        # Security check: ensure directory is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_target_dir = os.path.realpath(target_dir)
        if not real_target_dir.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        if not os.path.exists(target_dir):
            return jsonify({'success': False, 'error': i18n['target_directory_not_exist']})
        
        # workspace directory path
        workspace_dir = os.path.join(target_dir, 'workspace')
        os.makedirs(workspace_dir, exist_ok=True)
        
        uploaded_files = []
        for file in files:
            if file.filename:
                # Custom secure filename handling, preserve Chinese characters
                safe_filename = sanitize_filename(file.filename)
                if not safe_filename:
                    continue
                
                # If file already exists, add timestamp
                if os.path.exists(os.path.join(workspace_dir, safe_filename)):
                    name, ext = os.path.splitext(safe_filename)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    safe_filename = f"{name}_{timestamp}{ext}"
                
                file_path = os.path.join(workspace_dir, safe_filename)
                
                file.save(file_path)
                uploaded_files.append(safe_filename)
        
        return jsonify({
            'success': True,
            'message': i18n['upload_success'].format(len(uploaded_files)),
            'files': uploaded_files
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def sanitize_filename(filename, is_directory=False):
    """
    Custom filename sanitization function, preserve Chinese characters but remove dangerous characters
    """
    if not filename:
        return None
    
    # Remove path separators and other dangerous characters, but preserve Chinese characters
    # Allow: letters, numbers, Chinese characters, dots, underscores, hyphens, spaces, parentheses
    filename = re.sub(r'[<>:"/\\|?*]', '', filename)
    
    # Remove leading and trailing spaces and dots
    filename = filename.strip(' .')
    
    # If filename is empty, return None
    if not filename:
        return None
    
    # For directory names, allow starting with dots (like .git, etc.)
    # Limit filename length
    if len(filename) > 255:
        filename = filename[:255]
    
    return filename

@app.route('/api/rename-directory/<path:old_name>', methods=['PUT'])
def rename_directory(old_name):
    """Rename output directory"""
    try:
        i18n = get_i18n_texts()
        
        # Get API key from form data, query parameters or headers
        api_key = request.json.get('api_key') if request.json else None
        if not api_key:
            api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        data = request.get_json()
        new_name = data.get('new_name', '').strip()
        
        if not new_name:
            return jsonify({'success': False, 'error': i18n['new_name_empty']})
        
        # Check if it's currently executing directory for any user with same API key
        # (This is a simplification - in practice we might want to check all sessions with same API key)
        if hasattr(user_session, 'current_output_dir') and old_name == user_session.current_output_dir:
            return jsonify({'success': False, 'error': 'Cannot rename directory currently in use'})
        
        # Use custom secure filename handling, preserve more characters
        new_name_safe = sanitize_filename(new_name, is_directory=True)
        if not new_name_safe:
            return jsonify({'success': False, 'error': 'Invalid directory name'})
        
        # Security check: normalize old path and prevent path traversal
        # Don't use secure_filename as it destroys Chinese characters
        normalized_old_name = os.path.normpath(old_name)
        if '..' in normalized_old_name or normalized_old_name.startswith('/'):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        # Build complete path
        old_path = os.path.join(user_base_dir, normalized_old_name)
        new_path = os.path.join(user_base_dir, new_name_safe)
        
        # Debug info
        
        # If processed paths are the same, it means the new name is invalid
        if old_path == new_path:
            return jsonify({'success': False, 'error': 'New name is the same as original or contains invalid characters'})
        
        # Security check: ensure paths are within expected directory
        real_old_path = os.path.realpath(old_path)
        real_new_path = os.path.realpath(new_path)
        expected_parent = os.path.realpath(user_base_dir)
        
        if not real_old_path.startswith(expected_parent) or not real_new_path.startswith(expected_parent):
            return jsonify({'success': False, 'error': 'Paths are not safe'})
        
        # Check if original directory exists
        if not os.path.exists(old_path):
            return jsonify({'success': False, 'error': 'Original directory does not exist'})
        
        # Check if new directory exists
        if os.path.exists(new_path):
            return jsonify({'success': False, 'error': 'Target directory already exists'})
        
        
        # Rename directory
        os.rename(old_path, new_path)
        
        # Update user session related states
        if hasattr(user_session, 'selected_output_dir') and user_session.selected_output_dir == old_name:
            user_session.selected_output_dir = new_name_safe
        if hasattr(user_session, 'last_output_dir') and user_session.last_output_dir == old_name:
            user_session.last_output_dir = new_name_safe
        
        
        return jsonify({
            'success': True, 
            'message': f'Directory renamed successfully: {old_name} -> {new_name_safe}',
            'old_name': old_name,
            'new_name': new_name_safe
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/delete-directory/<path:dir_name>', methods=['DELETE'])
def delete_directory(dir_name):
    """Delete specified output directory"""
    try:
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Security check: normalize path and prevent path traversal
        # Don't use secure_filename as it destroys Chinese characters
        normalized_dir_name = os.path.normpath(dir_name)
        if '..' in normalized_dir_name or normalized_dir_name.startswith('/'):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        # Construct target directory path (preserve Chinese characters)
        target_dir = os.path.join(user_base_dir, normalized_dir_name)
        
        # Security check: ensure directory is within user's output directory
        real_output_dir = os.path.realpath(user_base_dir)
        real_target_dir = os.path.realpath(target_dir)
        if not real_target_dir.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied: Invalid directory path'})
        
        # Check if directory exists
        if not os.path.exists(target_dir):
            return jsonify({'success': False, 'error': f'Directory not found: {dir_name}'})
        
        # Check if directory contains workspace subdirectory (ensure it's a workspace directory)
        workspace_path = os.path.join(target_dir, 'workspace')
        if not os.path.exists(workspace_path) or not os.path.isdir(workspace_path):
            return jsonify({'success': False, 'error': 'Only directories with workspace subdirectory can be deleted'})
        
        # Check if it's currently executing directory for any user with same API key
        if hasattr(user_session, 'current_output_dir') and user_session.current_output_dir == dir_name:
            return jsonify({'success': False, 'error': 'Cannot delete currently executing directory'})
        
        
        # Delete directory and all its contents
        shutil.rmtree(target_dir)
        
        # Clean user session related states
        if hasattr(user_session, 'last_output_dir') and user_session.last_output_dir == dir_name:
            user_session.last_output_dir = None
        if hasattr(user_session, 'selected_output_dir') and user_session.selected_output_dir == dir_name:
            user_session.selected_output_dir = None
        
        
        return jsonify({
            'success': True, 
            'message': f'Directory "{dir_name}" has been successfully deleted'
        })
        
    except PermissionError as e:
        return jsonify({'success': False, 'error': f'Permission denied: {str(e)}'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/delete-file', methods=['DELETE'])
def delete_file():
    """Delete specified file from workspace"""
    try:
        # Get file path from request
        data = request.get_json()
        file_path = data.get('file_path') if data else request.args.get('file_path')
        
        if not file_path:
            return jsonify({'success': False, 'error': 'File path is required'})
        
        # Get API key from query parameters or headers
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key')
        if data:
            api_key = api_key or data.get('api_key')
        
        # Create a temporary session for API calls
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # Construct full file path
        full_file_path = os.path.join(user_base_dir, file_path)
        
        # Security check: ensure file is within user's directory
        real_user_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_file_path)
        if not real_file_path.startswith(real_user_dir):
            return jsonify({'success': False, 'error': 'Access denied: Invalid file path'})
        
        # Check if path exists
        if not os.path.exists(full_file_path):
            return jsonify({'success': False, 'error': f'Path not found: {file_path}'})
        
        if os.path.isfile(full_file_path):
            # Delete the file
            os.remove(full_file_path)
        elif os.path.isdir(full_file_path):
            # Delete the folder and all its contents
            shutil.rmtree(full_file_path)
        else:
            return jsonify({'success': False, 'error': f'Path is neither a file nor a directory: {file_path}'})
        
        
        return jsonify({
            'success': True, 
            'message': f'File "{os.path.basename(file_path)}" has been successfully deleted'
        })
        
    except PermissionError as e:
        return jsonify({'success': False, 'error': f'Permission denied: {str(e)}'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/routine-files', methods=['GET'])
def get_routine_files():
    """Get list of routine files from routine directory and workspace files starting with 'routine_'"""
    try:
        routine_files = []
        workspace_dir = os.getcwd()
        
        # æ ¹æ®URLå‚æ•°æˆ–è¯­è¨€é…ç½®é€‰æ‹©routineæ–‡ä»¶å¤¹
        lang_param = request.args.get('lang')
        if lang_param and lang_param in ('zh', 'en'):
            current_lang = lang_param
        else:
            current_lang = get_language()
        
        if current_lang == 'zh':
            routine_dir = os.path.join(workspace_dir, 'routine_zh')
        else:
            routine_dir = os.path.join(workspace_dir, 'routine')
        
        # 1. æ·»åŠ routineæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶
        if os.path.exists(routine_dir) and os.path.isdir(routine_dir):
            for filename in os.listdir(routine_dir):
                if os.path.isfile(os.path.join(routine_dir, filename)):
                    # Remove file extension
                    name_without_ext = os.path.splitext(filename)[0]
                    routine_files.append({
                        'name': name_without_ext,
                        'filename': filename,
                        'type': 'routine_folder'
                    })
        
        # 2. æ·»åŠ å½“å‰workspaceä¸‹routine_å¼€å¤´çš„æ–‡ä»¶
        for filename in os.listdir(workspace_dir):
            if filename.startswith('routine_') and os.path.isfile(os.path.join(workspace_dir, filename)):
                # Remove file extension and 'routine_' prefix
                name_without_ext = os.path.splitext(filename)[0]
                display_name = name_without_ext[8:] if name_without_ext.startswith('routine_') else name_without_ext
                routine_files.append({
                    'name': display_name,
                    'filename': filename,
                    'type': 'workspace_file'
                })
        
        # æŒ‰åç§°æ’åº
        routine_files.sort(key=lambda x: x['name'])
        
        return jsonify({
            'success': True,
            'files': routine_files
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'files': []
        }), 500

@app.route('/api/validate-config', methods=['POST'])
def validate_config():
    """Validate GUI configuration (without returning sensitive information)"""
    try:
        from src.config_loader import get_gui_config, validate_gui_config
        
        data = request.get_json()
        model_config = data.get('config')  # æ–°çš„ç»“æ„ï¼šå®Œæ•´çš„é…ç½®å¯¹è±¡
        
        if not model_config:
            i18n = get_i18n_texts()
            return jsonify({
                'success': False,
                'error': i18n['config_missing']
            })
        
        config_value = model_config.get('value')
        model_name = model_config.get('model')
        max_tokens = model_config.get('max_tokens', 8192)
        
        # éªŒè¯max_tokensæ˜¯æœ‰æ•ˆçš„æ•°å­—
        try:
            max_tokens = int(max_tokens) if max_tokens else 8192
            if max_tokens <= 0:
                max_tokens = 8192
        except (ValueError, TypeError):
            max_tokens = 8192
        
        # å¦‚æœæ˜¯å†…ç½®é…ç½®ï¼ˆä¸æ˜¯ 'custom'ï¼‰ï¼Œä»æœåŠ¡å™¨ç«¯è¯»å–å¹¶éªŒè¯
        if config_value and config_value != 'custom':
            gui_config = get_gui_config()
            config_model = gui_config.get('model', 'glm-4.5')
            
            # éªŒè¯æ¨¡å‹åç§°æ˜¯å¦å­˜åœ¨
            if not model_name:
                # å¦‚æœå‰ç«¯æ²¡æœ‰æä¾›æ¨¡å‹åç§°ï¼Œä½¿ç”¨æœåŠ¡å™¨ç«¯çš„æ¨¡å‹åç§°
                model_name = config_model
            
            if config_value == config_model:
                # è¯»å–GUIé…ç½®å¹¶éªŒè¯
                is_valid, error_message = validate_gui_config(gui_config)
                
                if not is_valid:
                    return jsonify({
                        'success': False,
                        'error': error_message
                    })
            
            # éªŒè¯æ¨¡å‹åç§°æ˜¯å¦å­˜åœ¨
            if not model_name:
                i18n = get_i18n_texts()
                return jsonify({
                    'success': False,
                    'error': i18n['config_incomplete']
                })
            
            # å¯¹äºå†…ç½®é…ç½®ï¼Œåªè¿”å›éæ•æ„Ÿä¿¡æ¯
            return jsonify({
                'success': True,
                'config': {
                    # ä¸è¿”å› api_key å’Œ api_baseï¼Œè¿™äº›æ•æ„Ÿä¿¡æ¯åªåœ¨å‘èµ·ä»»åŠ¡æ—¶ä»æœåŠ¡å™¨ç«¯è¯»å–
                    'model': model_name,
                    'max_tokens': max_tokens
                }
            })
        else:
            # è‡ªå®šä¹‰é…ç½®ï¼šéªŒè¯ç”¨æˆ·è¾“å…¥çš„é…ç½®
            api_key = model_config.get('api_key')
            api_base = model_config.get('api_base')
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            if not api_key or not api_base or not model_name:
                i18n = get_i18n_texts()
                return jsonify({
                    'success': False,
                    'error': i18n['config_incomplete']
                })
            
            # å¯¹äºè‡ªå®šä¹‰é…ç½®ï¼Œåªè¿”å›éæ•æ„Ÿä¿¡æ¯ï¼ˆå‰ç«¯å·²ç»æœ‰å®Œæ•´é…ç½®ï¼‰
            return jsonify({
                'success': True,
                'config': {
                    'model': model_name,
                    'max_tokens': max_tokens
                }
            })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Configuration validation failed: {str(e)}'
        })

@app.route('/api/save-file', methods=['POST'])
def save_file():
    """Save file content back to disk (universal file save endpoint)."""
    try:
        data = request.get_json() or {}
        rel_path = data.get('file_path')
        content = data.get('content', '')
        if not rel_path:
            return jsonify({'success': False, 'error': 'File path is required'})

        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)

        full_path = os.path.join(user_base_dir, rel_path)
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})

        # Ensure parent dir exists
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        # Save content
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # Auto-convert SVG to PNG if the saved file is an SVG
        if rel_path.lower().endswith('.svg') and SVG_TO_PNG_CONVERTER_AVAILABLE:
            try:
                from pathlib import Path
                svg_path = Path(full_path)
                png_path = svg_path.with_suffix('.png')
                
                converter = EnhancedSVGToPNGConverter()
                success, message = converter.convert(svg_path, png_path, enhance_chinese=True, dpi=300)
                
                if success:
                    print(f"âœ… SVGè‡ªåŠ¨è½¬æ¢ä¸ºPNGæˆåŠŸ: {png_path.name}")
                else:
                    print(f"âš ï¸ SVGè½¬PNGå¤±è´¥: {message}")
            except Exception as e:
                # è½¬æ¢å¤±è´¥ä¸å½±å“SVGä¿å­˜æˆåŠŸ
                print(f"âš ï¸ SVGè½¬PNGå‡ºé”™: {e}")
        
        return jsonify({'success': True, 'path': rel_path})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/save-markdown', methods=['POST'])
def save_markdown():
    """Save modified Markdown content back to disk."""
    try:
        data = request.get_json() or {}
        rel_path = data.get('path')
        content = data.get('content', '')
        if not rel_path:
            return jsonify({'success': False, 'error': 'File path is required'})

        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)

        full_path = os.path.join(user_base_dir, rel_path)
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})

        # Ensure parent dir exists
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        # Save content
        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(content)
        return jsonify({'success': True, 'path': rel_path})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/render-markdown', methods=['POST'])
def render_markdown():
    """Render Markdown content to HTML for preview."""
    try:
        data = request.get_json() or {}
        content = data.get('content', '')
        
        if not content:
            return jsonify({'success': False, 'error': 'Content is required'})
        
        # ä½¿ç”¨ç°æœ‰çš„markdownå¤„ç†é€»è¾‘
        import markdown
        from markdown.extensions import codehilite, tables, toc, fenced_code
        
        # é…ç½®markdownæ‰©å±•
        extensions = [
            'markdown.extensions.tables',
            'markdown.extensions.fenced_code',
            'markdown.extensions.codehilite',
            'markdown.extensions.toc',
            'markdown.extensions.attr_list',
            'markdown.extensions.def_list',
            'markdown.extensions.footnotes',
            'markdown.extensions.md_in_html'
        ]
        
        # åˆ›å»ºmarkdownå®ä¾‹
        md = markdown.Markdown(
            extensions=extensions,
            extension_configs={
                'codehilite': {
                    'css_class': 'highlight',
                    'use_pygments': True
                },
                'toc': {
                    'permalink': True
                }
            }
        )
        
        # è½¬æ¢ä¸ºHTML
        html = md.convert(content)
        
        return jsonify({'success': True, 'html': html})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/reparse-markdown-diagrams', methods=['POST'])
def reparse_markdown_diagrams():
    """é‡æ–°è§£æMarkdownæ–‡ä»¶ä¸­çš„Mermaidå›¾è¡¨å’ŒSVGä»£ç å—"""
    try:
        data = request.get_json() or {}
        rel_path = data.get('path')
        
        if not rel_path:
            return jsonify({'success': False, 'error': 'File path is required'})
        
        # è·å–ç”¨æˆ·ä¼šè¯
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)
        
        # è·å–å®Œæ•´è·¯å¾„
        full_path = os.path.join(user_base_dir, rel_path)
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)
        
        # å®‰å…¨æ£€æŸ¥
        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})
        
        if not os.path.exists(real_file_path):
            return jsonify({'success': False, 'error': 'File not found'})
        
        if not rel_path.lower().endswith('.md'):
            return jsonify({'success': False, 'error': 'Only markdown files are supported'})
        
        # ä½¿ç”¨FileSystemToolsçš„process_markdown_diagramsæ–¹æ³•
        from src.tools.file_system_tools import FileSystemTools
        
        fs_tools = FileSystemTools(workspace_root=user_base_dir)
        result = fs_tools.process_markdown_diagrams(rel_path)
        
        if result.get('status') == 'success':
            return jsonify({
                'success': True,
                'message': result.get('message', 'Processing completed'),
                'details': {
                    'mermaid': result.get('mermaid_processing', {}),
                    'svg': result.get('svg_processing', {})
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('message', 'Processing failed'),
                'details': result
            })
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/gui-configs', methods=['GET'])
def get_gui_configs():
    """Get available GUI model configurations (without sensitive information)"""
    try:
        from src.config_loader import get_gui_config
        
        # è¯»å–GUIé…ç½®
        gui_config = get_gui_config()
        
        # è¿”å›å›ºå®šçš„ä¸¤ä¸ªé€‰é¡¹ï¼šä»é…ç½®è¯»å–çš„æ¨¡å‹ å’Œè‡ªå®šä¹‰
        # æ³¨æ„ï¼šä¸è¿”å› api_key å’Œ api_baseï¼Œè¿™äº›æ•æ„Ÿä¿¡æ¯åªåœ¨å‘èµ·ä»»åŠ¡æ—¶ä»æœåŠ¡å™¨ç«¯è¯»å–
        i18n = get_i18n_texts()
        model_name = gui_config.get('model', 'glm-4.5')
        configs = [
            {
                'value': model_name,
                'label': model_name,
                # ä¸è¿”å› api_key å’Œ api_baseï¼Œä¿æŠ¤æ•æ„Ÿä¿¡æ¯
                'model': gui_config.get('model', ''),
                'max_tokens': gui_config.get('max_tokens', 8192),
                'display_name': model_name
            },
            {
                'value': 'custom',
                'label': i18n['custom_label'],
                'model': '',
                'max_tokens': 8192,
                'display_name': i18n['custom_label']
            }
        ]
        
        return jsonify({
            'success': True,
            'configs': configs
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })


@app.route('/api/save-to-config', methods=['POST'])
def save_to_config():
    """Save custom model configuration to config.txt"""
    try:
        data = request.json
        api_key = data.get('api_key', '').strip()
        api_base = data.get('api_base', '').strip()
        model = data.get('model', '').strip()
        max_tokens = data.get('max_tokens', 8192)
        
        # Validate required fields
        if not api_key or not api_base or not model:
            return jsonify({
                'success': False,
                'error': 'All fields are required'
            })
        
        # Path to config.txt
        config_path = os.path.join(os.getcwd(), 'config', 'config.txt')
        
        if not os.path.exists(config_path):
            return jsonify({
                'success': False,
                'error': 'config.txt file not found'
            })
        
        # Read the current config file
        with open(config_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # Update the first uncommented configuration section
        updated_lines = []
        found_first_config = False
        lines_updated = 0
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            
            # Skip empty lines and comments
            if not stripped or stripped.startswith('#'):
                updated_lines.append(line)
                continue
            
            # Check if this line contains a config key-value pair
            if '=' in line and not found_first_config:
                key = line.split('=')[0].strip()
                
                # Update the first configuration block (top-most uncommented configs)
                if key == 'api_key' and lines_updated == 0:
                    updated_lines.append(f'api_key={api_key}\n')
                    lines_updated += 1
                elif key == 'api_base' and lines_updated == 1:
                    updated_lines.append(f'api_base={api_base}\n')
                    lines_updated += 1
                elif key == 'model' and lines_updated == 2:
                    updated_lines.append(f'model={model}\n')
                    lines_updated += 1
                elif key == 'max_tokens' and lines_updated == 3:
                    updated_lines.append(f'max_tokens={max_tokens}\n')
                    lines_updated += 1
                    found_first_config = True  # We've updated all needed fields
                else:
                    updated_lines.append(line)
            else:
                updated_lines.append(line)
        
        # Write back to config.txt
        with open(config_path, 'w', encoding='utf-8') as f:
            f.writelines(updated_lines)
        
        # Clear config cache so changes take effect immediately
        from src.config_loader import clear_config_cache
        clear_config_cache()
        
        return jsonify({
            'success': True,
            'message': 'Configuration saved to config.txt successfully'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })


@app.route('/api/optimize-svg', methods=['POST'])
def optimize_svg():
    """Optimize SVG file using either traditional or LLM-based optimization"""
    try:
        data = request.get_json() or {}
        file_path = data.get('file_path')
        use_llm = data.get('use_llm', False)
        api_key = request.args.get('api_key') or request.headers.get('X-API-Key') or data.get('api_key')

        if not file_path:
            return jsonify({'success': False, 'error': 'File path is required'})

        # Validate file path and permissions
        temp_session_id = create_temp_session_id(request, api_key)
        user_session = gui_instance.get_user_session(temp_session_id, api_key)
        user_base_dir = user_session.get_user_directory(gui_instance.base_data_dir)

        full_path = os.path.join(user_base_dir, file_path)
        real_output_dir = os.path.realpath(user_base_dir)
        real_file_path = os.path.realpath(full_path)

        if not real_file_path.startswith(real_output_dir):
            return jsonify({'success': False, 'error': 'Access denied'})

        if not os.path.exists(full_path):
            return jsonify({'success': False, 'error': 'File not found'})

        # Check if it's an SVG file
        if not full_path.lower().endswith('.svg'):
            return jsonify({'success': False, 'error': 'File must be an SVG file'})

        # Read original SVG content
        with open(full_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        optimization_report = None
        optimized_content = original_content

        if use_llm and LLM_SVG_OPTIMIZER_AVAILABLE:
            # Use LLM-based optimization
            try:
                optimizer = create_llm_optimizer_from_env()
                optimized_content, report = optimizer.optimize_svg_with_llm(original_content)

                optimization_report = {
                    'method': 'LLM',
                    'llm_provider': getattr(optimizer, 'provider', 'unknown'),
                    'llm_model': getattr(optimizer, 'model', 'unknown'),
                    'original_issues_count': len(report.get('original_issues', [])),
                    'changes_made': report.get('changes_made', []),
                    'issues_fixed': report.get('issues_fixed', [])
                }
            except Exception as llm_error:
                use_llm = False

        if not use_llm and SVG_OPTIMIZER_AVAILABLE:
            # Use traditional optimization
            try:
                optimizer = AdvancedSVGOptimizer(OptimizationLevel.STANDARD)
                optimized_content, report = optimizer.optimize_svg_with_report(original_content)

                optimization_report = {
                    'method': 'Traditional',
                    'original_issues_count': len(report.original_issues),
                    'fixed_issues_count': len(report.fixed_issues),
                    'remaining_issues_count': len(report.remaining_issues)
                }
            except Exception as trad_error:
                return jsonify({'success': False, 'error': f'Optimization failed: {str(trad_error)}'})

        # Create backup if content changed
        if optimized_content != original_content:
            backup_path = full_path + '.optimized_backup'
            try:
                with open(backup_path, 'w', encoding='utf-8') as f:
                    f.write(original_content)
            except Exception as backup_error:
                pass

            # Save optimized content
            with open(full_path, 'w', encoding='utf-8') as f:
                f.write(optimized_content)

        # Generate success message
        if optimized_content != original_content:
            message = f"SVGæ–‡ä»¶å·²æˆåŠŸä¼˜åŒ–ï¼"
            if optimization_report:
                if use_llm and optimization_report.get('method') == 'LLM':
                    message += f"\\n\\nğŸ¤– AIä¼˜åŒ–å®Œæˆ"
                    message += f"\\nâ€¢ ä½¿ç”¨æ¨¡å‹: {optimization_report.get('llm_provider', 'unknown')} - {optimization_report.get('llm_model', 'unknown')}"
                    message += f"\\nâ€¢ æ£€æµ‹åˆ°é—®é¢˜: {optimization_report.get('original_issues_count', 0)}"
                    if optimization_report.get('changes_made'):
                        message += f"\\nâ€¢ ä¸»è¦æ”¹è¿›: {len(optimization_report['changes_made'])} é¡¹"
                    if optimization_report.get('issues_fixed'):
                        message += f"\\nâ€¢ ä¿®å¤é—®é¢˜: {len(optimization_report['issues_fixed'])} ä¸ª"
                else:
                    message += f"\\n\\nä¼ ç»Ÿä¼˜åŒ–å®Œæˆ"
                    message += f"\\nâ€¢ æ£€æµ‹åˆ°é—®é¢˜: {optimization_report.get('original_issues_count', 0)}"
                    message += f"\\nâ€¢ å·²ä¿®å¤é—®é¢˜: {optimization_report.get('fixed_issues_count', 0)}"
                    message += f"\\nâ€¢ å‰©ä½™é—®é¢˜: {optimization_report.get('remaining_issues_count', 0)}"
        else:
            message = "SVGæ–‡ä»¶å·²ç»æ˜¯æœ€ä½³çŠ¶æ€ï¼Œæ— éœ€ä¼˜åŒ–"

        return jsonify({
            'success': True,
            'message': message,
            'optimization_report': optimization_report,
            'used_llm': use_llm
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'SVG optimization failed: {str(e)}'
        })


def get_mcp_servers_config():
    """Get MCP servers configuration from mcp_servers_GUI.json for GUI

    Returns:
        dict: MCP servers configuration, or empty dict if failed
    """
    try:
        # Path to the example MCP config file
        example_config_path = os.path.join(os.getcwd(), 'config', 'mcp_servers_GUI.json')

        # Check if example config exists
        if not os.path.exists(example_config_path):
            return {}

        # Load the example configuration
        with open(example_config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # Return the mcpServers section
        return config.get('mcpServers', {})

    except Exception as e:
        return {}


def generate_custom_mcp_config(selected_servers, out_dir):
    """Generate a custom MCP configuration file based on selected servers.

    Args:
        selected_servers: List of selected MCP server names
        out_dir: Output directory for the task

    Returns:
        str: Path to the generated MCP configuration file, or None if failed
    """
    try:
        # Path to the example MCP config file
        example_config_path = os.path.join(os.getcwd(), 'config', 'mcp_servers_GUI.json')

        # Check if example config exists
        if not os.path.exists(example_config_path):
            return None

        # Load the example configuration
        with open(example_config_path, 'r', encoding='utf-8') as f:
            example_config = json.load(f)

        # Create custom config with only selected servers
        custom_config = {"mcpServers": {}}

        # Add selected servers to custom config
        for server_name in selected_servers:
            if server_name in example_config.get('mcpServers', {}):
                custom_config['mcpServers'][server_name] = example_config['mcpServers'][server_name]
            else:
                pass

        # Generate filename with timestamp to avoid conflicts
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        config_filename = f"mcp_servers_custom_{timestamp}.json"
        custom_config_path = os.path.join(out_dir, config_filename)

        # Write custom configuration to file
        with open(custom_config_path, 'w', encoding='utf-8') as f:
            json.dump(custom_config, f, indent=2, ensure_ascii=False)

        return custom_config_path

    except Exception as e:
        return None


if __name__ == '__main__':
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='AGIAgent GUI Server')
    parser.add_argument('--port', '-p', type=int, default=5002, 
                       help='Port specified to use')
    args = parser.parse_args()
    
    # ä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
    port = args.port if args.port else int(os.environ.get('PORT', 5002))
    
    print(f"ğŸš€ Starting AGIAgent GUI Server on port {port}")
    socketio.run(app, host='0.0.0.0', port=port, debug=False, allow_unsafe_werkzeug=True) 
    print(f"ğŸš€ Wait for 5 seconds and open the browser with url 127.0.0.1:{port}")
