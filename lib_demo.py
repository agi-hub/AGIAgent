#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Copyright (c) 2025 AGI Agent Research Group.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

AGI Agent Python Library Usage Examples

This file demonstrates how to use AGI Agent as a Python library instead of 
command-line tool. The library provides an OpenAI-like chat interface.
"""

# Import the AGI Agent client
from src.main import AGIAgentClient, create_client

def example_basic_usage():
    """Basic usage example"""
    print("=== Basic Usage Example ===")
    
    # Initialize the client (will automatically read from config/config.txt)
    client = AGIAgentClient(
        # api_key and model will be read from config/config.txt automatically
        # You can also specify them explicitly: api_key="your_api_key", model="claude-sonnet-4-0"
        debug_mode=False,  # Enable debug logging
        single_task_mode=True  # Use single task mode (recommended)
    )
    
    # Send a chat message (similar to OpenAI API)
    response = client.chat(
        messages=[
            {"role": "user", "content": "Create a simple Python calculator that can add, subtract, multiply and divide"}
        ],
        dir="output_project_01",  # Output directory
        loops=10  # Maximum execution rounds
    )
    
    # Check the result
    if response["success"]:
        print(f"âœ… Task completed successfully!")
        print(f"ğŸ“ Output directory: {response['output_dir']}")
        print(f"ğŸ’» Workspace directory: {response['workspace_dir']}")
        print(f"â±ï¸ Execution time: {response['execution_time']:.2f} seconds")
    else:
        print(f"âŒ Task failed: {response['message']}")
        print(f"ğŸ“ Error details: {response['details']}")

def example_with_continue_mode():
    """Example using continue mode to build upon previous work"""
    print("\n=== Continue Mode Example ===")
    
    client = AGIAgentClient(
        # Will read from config/config.txt automatically
    )
    
    # First task: Create basic web app
    print("Step 1: Creating basic web app...")
    response1 = client.chat(
        messages=[
            {"role": "user", "content": "Create a simple Flask web application with a homepage"}
        ],
        dir="my_web_app"
    )
    
    if response1["success"]:
        print("âœ… Basic web app created!")
        
        # Second task: Add features to the existing app
        print("Step 2: Adding features to existing app...")
        response2 = client.chat(
            messages=[
                {"role": "user", "content": "Add a contact form and an about page to the existing Flask app"}
            ],
            dir="my_web_app",  # Same directory
            continue_mode=True  # Continue from previous work
        )
        
        if response2["success"]:
            print("âœ… Features added successfully!")
            print(f"ğŸ“ Final project: {response2['output_dir']}")
        else:
            print(f"âŒ Failed to add features: {response2['message']}")
    else:
        print(f"âŒ Failed to create basic app: {response1['message']}")

def example_with_custom_config():
    """Example with custom configuration"""
    print("\n=== Custom Configuration Example ===")
    
    # Using the convenience function (will read api_key and model from config/config.txt)
    client = create_client(
        # api_key and model will be read from config/config.txt automatically
        # You can override with: model="claude-3-haiku-20240307"  # Faster, cheaper model
        debug_mode=True,  # Enable detailed logging
        detailed_summary=True,  # Generate detailed reports
        interactive_mode=False,  # Non-interactive execution
        MCP_config_file="config/custom_mcp_servers.json",  # Custom MCP configuration
        prompts_folder="custom_prompts"  # Custom prompts folder
    )
    
    # Check current configuration
    config = client.get_config()
    print(f"Client configuration: {config}")
    
    # Get supported models
    models = client.get_models()
    print(f"Supported models: {models}")
    
    # Execute task
    response = client.chat(
        messages=[
            {"role": "user", "content": "Write a Python script that analyzes CSV files and generates charts"}
        ],
        dir="data_analysis_tool"
    )
    
    print(f"Task result: {'Success' if response['success'] else 'Failed'}")

def example_with_custom_mcp_and_prompts():
    """Example using custom MCP configuration and prompts folder"""
    print("\n=== Custom MCP and Prompts Example ===")
    
    client = AGIAgentClient(
        # api_key and model will be read from config/config.txt automatically
        debug_mode=False,
        MCP_config_file="config/specialized_mcp_servers.json",  # Use specialized MCP tools
        prompts_folder="specialized_prompts"  # Use specialized prompts for different domains
    )
    
    # This allows you to:
    # 1. Use different MCP server configurations for different projects
    # 2. Use different prompt templates and tool interfaces
    # 3. Create domain-specific AGIAgent instances (e.g., for data science, web development, etc.)
    
    response = client.chat(
        messages=[
            {"role": "user", "content": "Create a machine learning pipeline for time series forecasting"}
        ],
        dir="ml_pipeline_project"
    )
    
    if response["success"]:
        print("âœ… ML pipeline created with specialized tools and prompts!")
        print(f"ğŸ“ Output: {response['output_dir']}")
    else:
        print(f"âŒ Failed: {response['message']}")

def example_batch_processing():
    """Example of processing multiple tasks in batch"""
    print("\n=== Batch Processing Example ===")
    
    client = AGIAgentClient(
        # Will read from config/config.txt automatically
    )
    
    tasks = [
        "Create a Python TODO list application",
        "Write a simple weather app using an API"
    ]
    
    results = []
    for i, task in enumerate(tasks, 1):
        print(f"Processing task {i}/{len(tasks)}: {task}")
        
        response = client.chat(
            messages=[{"role": "user", "content": task}],
            dir=f"batch_task_{i}"
        )
        
        results.append({
            "task": task,
            "success": response["success"],
            "output_dir": response["output_dir"] if response["success"] else None,
            "error": response["message"] if not response["success"] else None
        })
        
        print(f"Task {i} {'âœ… completed' if response['success'] else 'âŒ failed'}")
    
    # Summary
    successful = sum(1 for r in results if r["success"])
    print(f"\nğŸ“Š Batch processing complete: {successful}/{len(tasks)} tasks successful")
    
    for i, result in enumerate(results, 1):
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} Task {i}: {result['task'][:50]}...")

def example_thy_test_project():
    """thy test project example"""
    print("=== Thy Test Project Example ===")
    
    # Initialize the client (will automatically read from config/config.txt)
    client = AGIAgentClient(
        # api_key and model will be read from config/config.txt automatically
        # You can also specify them explicitly: api_key="your_api_key", model="claude-sonnet-4-0"
        debug_mode=False,  # Enable debug logging
        single_task_mode=True  # Use single task mode (recommended)
    )
    
    # Send a chat message (similar to OpenAI API)
    """
    response = client.chat(
        messages=[
            {"role": "user", "content": "å¸®æˆ‘çˆ¬å–æ¸…åå¤§å­¦æ‹›è˜ç½‘çš„æ‹›è˜ä¿¡æ¯ï¼Œå¦‚æœè®¿é—®ä¸åˆ°ï¼Œå°±ä½¿ç”¨é€‚é…å™¨æˆ–å…¶ä»–ä»»ä½•æ–¹å¼å®ç°çˆ¬å–ï¼Œç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£"}
            ],
        dir="output_thy_test_project07",  # Output directory
        loops=100  # Maximum execution rounds
    )
    """

    
    response = client.chat(
        messages=[
            {"role": "user", "content": "å¸®æˆ‘åšä¸€ä¸ªåªèƒ½å®¢æœé¡¹ç›®ï¼Œè¦æ±‚å…¨æ ˆå®Œæˆï¼Œå…¨éƒ¨è¿›è¡Œæµ‹è¯•ï¼Œæ‰€æœ‰åŠŸèƒ½è¦å®Œæ•´ï¼Œè¦å‰ç«¯ç•Œé¢ç¾è§‚ï¼Œåæ®µé€»è¾‘æ¸…æ™°ï¼Œä½¿ç”¨RAGå’ŒGRAPGRAGï¼Œè¿˜è¦ä½¿ç”¨dockerï¼Œè¦å®ç°ä¸€ä¸ªåºå¤§çš„é¡¹ç›®ã€‚"}
            ],
        dir="output_thy_test_project33",  # Output directory
        loops=100  # Maximum execution rounds
    )
    

    """
    response = client.chat(
        messages=[
            {"role": "user", "content": "ä½ éœ€è¦ä»é›¶å¼€å§‹è®¾è®¡å¹¶å®ç°ä¸€ä¸ªä¼ä¸šçº§ã€å¤šç§Ÿæˆ·ã€å®æ—¶åä½œçš„çŸ¥è¯†åº“ä¸å·¥ä½œæµè‡ªåŠ¨åŒ–å¹³å°ï¼Œç³»ç»Ÿè§„æ¨¡éœ€è¾¾åˆ°æ•°ä¸‡è¡Œä»£ç ä»¥ä¸Šã€‚è¯¥å¹³å°éœ€åŒæ—¶èåˆ Notion å¼å—ç¼–è¾‘æ–‡æ¡£ç³»ç»Ÿã€ç»“æ„åŒ–æ•°æ®åº“ï¼ˆè¡¨æ ¼/çœ‹æ¿/æ—¥å†ï¼‰ã€å®æ—¶å¤šäººåä½œç¼–è¾‘ã€ä¼ä¸šçº§æƒé™ä¸å®¡è®¡ã€å…¨æ–‡æœç´¢ã€å¯è§†åŒ–å·¥ä½œæµå¼•æ“ã€è·¨ç³»ç»Ÿé›†æˆèƒ½åŠ›ã€‚ç³»ç»Ÿå¿…é¡»æ”¯æŒå¤šç§Ÿæˆ·éš”ç¦»ï¼ˆæ•°æ®/æƒé™/é…é¢/å¯†é’¥ï¼‰ã€å¤æ‚ç»„ç»‡ç»“æ„ï¼ˆå…¬å¸-éƒ¨é—¨-é¡¹ç›®ï¼‰ã€ç»†ç²’åº¦æƒé™æ§åˆ¶ï¼ˆç²¾ç¡®åˆ°é¡µé¢ã€Blockã€æ•°æ®åº“å­—æ®µï¼‰ï¼Œå¹¶å…·å¤‡å®Œæ•´çš„å®¡è®¡æ—¥å¿—ä¸åˆè§„èƒ½åŠ›ã€‚æ–‡æ¡£ç¼–è¾‘å™¨éœ€åŸºäº Block æ¨¡å‹ï¼Œæ”¯æŒå¯Œæ–‡æœ¬ã€è¡¨æ ¼ã€æ•°æ®åº“ã€è¯„è®ºã€ä»»åŠ¡ã€å¼•ç”¨ã€æ¨¡æ¿ï¼Œå¹¶å®ç°å®æ—¶å¤šäººåä½œï¼ˆWebSocket + CRDT æˆ– OTï¼‰ï¼Œæ”¯æŒç¦»çº¿ç¼–è¾‘ã€å†²çªåˆå¹¶ã€æ“ä½œå›æ”¾ä¸ç‰ˆæœ¬å›æ»šã€‚ç³»ç»Ÿéœ€å†…ç½® ç»“æ„åŒ–æ•°æ®åº“èƒ½åŠ›ï¼ˆå­—æ®µã€è§†å›¾ã€è¿‡æ»¤ã€æ’åºã€Relation/Rollup/Formulaï¼‰ï¼Œå¹¶ç¡®ä¿åœ¨å¤§è§„æ¨¡æ•°æ®ä¸‹ä»å¯è¿›è¡Œå¢é‡è®¡ç®—ä¸æƒé™è£å‰ªã€‚ä½ è¿˜éœ€è¦å®ç°ä¸€ä¸ªå¯è§†åŒ–å·¥ä½œæµå¼•æ“ï¼Œæ”¯æŒæ•°æ®è§¦å‘ã€æ¡ä»¶åˆ†æ”¯ã€äººå·¥å®¡æ‰¹ã€å¤–éƒ¨ API è°ƒç”¨ã€å¹‚ç­‰ä¸è¡¥å¿æœºåˆ¶ï¼Œå¹¶èƒ½å¯¹æ¯ä¸ªæµç¨‹å®ä¾‹è¿›è¡Œå®Œæ•´è¿½è¸ªä¸é‡è¯•ã€‚å¹³å°éœ€æä¾› ä¼ä¸šçº§å…¨æ–‡æœç´¢ï¼ˆæ–‡æ¡£ã€æ•°æ®åº“ã€é™„ä»¶ï¼‰ï¼Œæœç´¢ç»“æœå¿…é¡»ä¸¥æ ¼éµå®ˆæƒé™è£å‰ªï¼Œæ”¯æŒå¤æ‚æŸ¥è¯¢è¯­æ³•ï¼Œå¹¶åœ¨æœç´¢æœåŠ¡æ•…éšœåå¯è‡ªåŠ¨æ¢å¤ç´¢å¼•ä¸€è‡´æ€§ã€‚åœ¨éåŠŸèƒ½å±‚é¢ï¼Œç³»ç»Ÿéœ€æ»¡è¶³é«˜å¹¶å‘ã€é«˜å¯ç”¨ã€å¯æ‰©å±•ã€å¯è§‚æµ‹ã€å®‰å…¨ä¸åˆè§„è¦æ±‚ï¼ŒåŒ…æ‹¬ï¼šäº‹ä»¶é©±åŠ¨æ¶æ„ã€å¹‚ç­‰è®¾è®¡ã€é™æµç†”æ–­ã€æ—¥å¿—/æŒ‡æ ‡/é“¾è·¯è¿½è¸ªã€æ•°æ®åŠ å¯†ã€å®¡è®¡ä¸å¯æŠµèµ–ã€‚ä½ éœ€è¦è¾“å‡ºå®Œæ•´çš„éœ€æ±‚æ‹†è§£ã€ç³»ç»Ÿæ¶æ„è®¾è®¡ã€æ•°æ®æ¨¡å‹ã€æ ¸å¿ƒç®—æ³•è®¾è®¡ã€æœåŠ¡æ¥å£å®šä¹‰ã€å‰åç«¯å®ç°æ–¹æ¡ˆã€æµ‹è¯•ç­–ç•¥ã€éƒ¨ç½²ä¸æ‰©å±•æ–¹æ¡ˆï¼Œå¹¶ç¡®ä¿ç³»ç»Ÿåœ¨çœŸå®å¤æ‚åœºæ™¯ï¼ˆå¤šäººåä½œã€æƒé™å·®å¼‚ã€æµç¨‹å¤±è´¥è¡¥å¿ã€æœç´¢å»¶è¿Ÿæ¢å¤ï¼‰ä¸‹ä»èƒ½æ­£ç¡®è¿è¡Œã€‚"}
            ],
        dir="output_thy_test_project",  # Output directory
        loops=100  # Maximum execution rounds
    )
    """

if __name__ == "__main__":
    print("AGI Agent Python Library Examples")
    print("=" * 50)
    
    # Note: Before running these examples, make sure to:
    # 1. Set your API key and model in config/config.txt
    # 2. Install required dependencies
    # 3. Have the src/ directory with the AGIAgent source code
    
    print("â„¹ï¸  Note: These examples will automatically read API key and model from config/config.txt")
    print("   Make sure your config/config.txt file contains valid API_KEY and MODEL settings.")
    print()
    
    # Uncomment the examples you want to run:
    
    # example_basic_usage()
    # example_with_continue_mode()
    # example_with_custom_config()
    # example_with_custom_mcp_and_prompts()
    # example_batch_processing()
    example_thy_test_project()
    
    print("Examples ready to run! Uncomment the function calls above to test.") 